# -*- coding: utf-8 -*-
"""
run_actions_interpretability_demo.py

åŠŸèƒ½
----
1) è¯»å–ä¸€ç»„â€œ11åŠ¨ä½œâ€è§†é¢‘ï¼ˆä¸¤ç§æ¨¡å¼ï¼šä»æ•°æ®åº“è¯»å– / ä»æ–‡ä»¶å¤¹è¯»å–ï¼‰
2) è°ƒç”¨ actions/ ä¸‹å¯¹åº”çš„ 11 ä¸ªåŠ¨ä½œç±»åšå‡ ä½•åˆ†æï¼ˆä¸å†™æ•°æ®åº“ï¼‰
3) æŠŠâ€œå¯è§£é‡Šæ€§ + å¯è§†åŒ–â€ç»“æœè¾“å‡ºåˆ°æ–‡ä»¶å¤¹ï¼Œæ–¹ä¾¿ä½ äººå·¥æ£€æŸ¥ç®—æ³•æ˜¯å¦æ­£ç¡®

è¿è¡Œæ–¹å¼
--------
- ç›´æ¥åœ¨ PyCharm é‡Œç‚¹å‡» Run æœ¬æ–‡ä»¶ï¼ˆä¸éœ€è¦å‘½ä»¤è¡Œå‚æ•°ï¼‰
- å…ˆåœ¨ä¸‹é¢ã€é…ç½®åŒºã€‘æŠŠ DB_PATH / MODEL_PATH / OUTPUT_DIR æ”¹æˆä½ è‡ªå·±çš„è·¯å¾„å³å¯

è¾“å‡ºç»“æ„ï¼ˆç¤ºä¾‹ï¼‰
----------------
OUTPUT_DIR/
  <session_id or examination_id>/
    overview.html                  # ä¸€é¡µæ€»è§ˆï¼ˆæµè§ˆå™¨æ‰“å¼€ï¼‰
    diagnosis_flow.md              # â€œè¯Šæ–­æµç¨‹å€’æ¨ï¼šéœ€è¦å“ªäº›æŒ‡æ ‡â€
    summary.csv                    # æ¯ä¸ªåŠ¨ä½œçš„å…³é”®æŒ‡æ ‡æ‘˜è¦ï¼ˆExcel ç›´æ¥çœ‹ï¼‰
    _meta.json                     # æœ¬æ¬¡ session/exam çš„å…ƒä¿¡æ¯
    all_actions_summary.json       # æ‰€æœ‰åŠ¨ä½œçš„æ±‡æ€» JSON
    actions/
      NeutralFace/
        peak_raw.jpg
        peak_vis.jpg
        indicators.json
        dynamic_features.json
        interpretability.json
        metrics.md                # æŒ‡æ ‡â€œäººè¯è§£é‡Š + æ­£è´Ÿå·/æ¯”ä¾‹è¯´æ˜â€
        plot_*.png                # è‹¥æœ‰æ›²çº¿åˆ™è‡ªåŠ¨ç”Ÿæˆ
      ...

æ³¨æ„
----
- æœ¬è„šæœ¬åªè¯»æ•°æ®åº“ï¼Œä¸å†™ video_features / interpretability ç­‰ä»»ä½•åˆ—ã€‚
- ä¸ºäº†å¯è§£é‡Šæ€§ï¼Œä¼šä¿å­˜æ›²çº¿ä¸å³°å€¼å¸§ï¼Œå¯ç”¨äºä½ é€ä¸ªåŠ¨ä½œæ ¸å¯¹ã€‚
"""

from __future__ import annotations
import time
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, as_completed
import os
import sys
import json
import csv
import math
import sqlite3
from pathlib import Path
from dataclasses import asdict, is_dataclass
from typing import Dict, Any, List, Optional, Tuple

import numpy as np
import cv2

# matplotlib ç”¨äºæ›²çº¿å›¾ï¼ˆæ—  GUI ç¯å¢ƒä¹Ÿèƒ½ä¿å­˜ï¼‰
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt


# =============================================================================
# è®© â€œimport facialPalsy.xxxâ€ åœ¨ PyCharm å„ç§ working directory ä¸‹éƒ½ç¨³
# =============================================================================
_THIS_DIR = Path(__file__).resolve().parent          # .../facialPalsy
_PROJECT_ROOT = _THIS_DIR.parent                    # .../medicalProject
if str(_PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(_PROJECT_ROOT))


# =============================================================================
# é…ç½®åŒºï¼ˆä½ åªéœ€è¦æ”¹è¿™é‡Œï¼‰
# =============================================================================
# å¹¶è¡Œï¼šNeutralFace ä¹‹åï¼Œå…¶ä½™åŠ¨ä½œæ˜¯å¦å¤šè¿›ç¨‹å¹¶è¡Œ
PARALLEL_AFTER_NEUTRAL = True

NUM_WORKERS = 8

# è¿è¡Œæ¨¡å¼ï¼š "db" ä» SQLite æ•°æ®åº“è¯»å–ï¼›"folder" ä»æ–‡ä»¶å¤¹è¯»å–ï¼ˆé€‚åˆ phone_videosï¼‰
MODE = "db"  # "db" or "folder"

# â€”â€” DB æ¨¡å¼é…ç½® â€”â€” #
DB_PATH = str(_THIS_DIR / "facialPalsy.db")  # é»˜è®¤ï¼šfacialPalsy/facialPalsy.db

# æŒ‡å®šåªåˆ†ææŸä¸€ä¸ª examination_idï¼ˆNone = è‡ªåŠ¨æŒ‰æ—¶é—´å€’åºå– MAX_EXAMS ä¸ªï¼‰
TARGET_EXAMINATION_ID: Optional[str] = None

# æœ€å¤šå¤„ç†å¤šå°‘ä¸ª examinationï¼ˆNone=ä¸é™åˆ¶ï¼›å»ºè®®å…ˆ 5~10 åšå¯è§£é‡Šæ€§æ£€æŸ¥ï¼‰
MAX_EXAMS: Optional[int] = None

# â€”â€” FOLDER æ¨¡å¼é…ç½® â€”â€” #
# INPUT_VIDEO_ROOT ä¸‹æ¯ä¸ªå­æ–‡ä»¶å¤¹è§†ä¸ºä¸€ä¸ªâ€œsessionâ€ï¼Œé‡Œé¢æ”¾åŠ¨ä½œè§†é¢‘ï¼šNeutralFace.mp4 ç­‰
INPUT_VIDEO_ROOT = "/Users/cuijinglei/Documents/facialPalsy/phone_videos"

# â€”â€” é€šç”¨é…ç½® â€”â€” #
# MediaPipe FaceLandmarker æ¨¡å‹è·¯å¾„
MODEL_PATH = r"/Users/cuijinglei/PycharmProjects/medicalProject/models/face_landmarker.task"

# è¾“å‡ºç›®å½•
OUTPUT_DIR = r"/Users/cuijinglei/Documents/facialPalsy/HGFA/actions_interpretability_outputs"

# æ˜¯å¦ç¼©å°ä¿å­˜çš„å³°å€¼å¸§ï¼ˆHTML æ‰“å¼€æ›´å¿«ï¼‰
SAVE_THUMBNAIL = True
THUMB_MAX_W = 960

# å¦‚æœè§†é¢‘ç‰¹åˆ«é•¿ï¼Œä½ å¯ä»¥é™åˆ¶æœ€å¤§æŠ½å¸§æ•°ï¼ˆNone=ä¸é™åˆ¶ï¼‰
MAX_FRAMES_PER_VIDEO: Optional[int] = None  # ä¾‹å¦‚ 300


# =============================================================================
# å¯¼å…¥é¡¹ç›®å†…æ¨¡å—ï¼ˆä¸ video_pipeline.py åŒé£æ ¼ï¼‰
# =============================================================================
from facialPalsy.core.landmark_extractor import LandmarkExtractor
from facialPalsy.core.constants import ActionNames

from facialPalsy.actions.neutral_face import NeutralFaceAction
from facialPalsy.actions.spontaneous_eye_blink import SpontaneousEyeBlinkAction
from facialPalsy.actions.voluntary_eye_blink import VoluntaryEyeBlinkAction
from facialPalsy.actions.close_eye_softly import CloseEyeSoftlyAction
from facialPalsy.actions.close_eye_hardly import CloseEyeHardlyAction
from facialPalsy.actions.raise_eyebrow import RaiseEyebrowAction
from facialPalsy.actions.smile import SmileAction
from facialPalsy.actions.shrug_nose import ShrugNoseAction
from facialPalsy.actions.show_teeth import ShowTeethAction
from facialPalsy.actions.blow_cheek import BlowCheekAction
from facialPalsy.actions.lip_pucker import LipPuckerAction


# =============================================================================
# å·¥å…·å‡½æ•°
# =============================================================================
def ensure_dir(p: Path) -> None:
    p.mkdir(parents=True, exist_ok=True)


def _jsonable(x: Any) -> Any:
    """æŠŠ numpy / dataclass / Path ç­‰å¯¹è±¡é€’å½’è½¬æˆå¯ JSON åºåˆ—åŒ–å½¢å¼ã€‚"""
    if x is None:
        return None
    if isinstance(x, (str, int, float, bool)):
        if isinstance(x, float) and (math.isnan(x) or math.isinf(x)):
            return str(x)
        return x
    if isinstance(x, Path):
        return str(x)
    if isinstance(x, np.ndarray):
        return x.tolist()
    if isinstance(x, (np.float32, np.float64, np.float16)):
        v = float(x)
        if math.isnan(v) or math.isinf(v):
            return str(v)
        return v
    if isinstance(x, (np.int32, np.int64, np.int16, np.uint8)):
        return int(x)
    if is_dataclass(x):
        return _jsonable(asdict(x))
    if isinstance(x, dict):
        return {str(k): _jsonable(v) for k, v in x.items()}
    if isinstance(x, (list, tuple)):
        return [_jsonable(v) for v in x]
    return str(x)


def write_json(path: Path, obj: Any) -> None:
    with path.open("w", encoding="utf-8") as f:
        json.dump(_jsonable(obj), f, ensure_ascii=False, indent=2)


def imwrite(path: Path, bgr: np.ndarray) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    ok = cv2.imwrite(str(path), bgr)
    if not ok:
        raise RuntimeError(f"cv2.imwrite failed: {path}")


def resize_keep_aspect(img: np.ndarray, max_w: int) -> np.ndarray:
    h, w = img.shape[:2]
    if w <= max_w:
        return img
    scale = max_w / float(w)
    new_w = int(w * scale)
    new_h = int(h * scale)
    return cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)


def plot_two_curves(
    save_path: Path,
    y1: np.ndarray,
    y2: np.ndarray,
    label1: str,
    label2: str,
    title: str,
    ylabel: str,
    vline_idx: Optional[int] = None,
    spans: Optional[List[Tuple[int, int]]] = None
) -> None:
    x = np.arange(len(y1))
    plt.figure()
    plt.plot(x, y1, label=label1)
    plt.plot(x, y2, label=label2)
    if vline_idx is not None:
        plt.axvline(vline_idx, linestyle="--")
    if spans:
        for (s, e) in spans:
            plt.axvspan(s, e, alpha=0.2)
    plt.title(title)
    plt.xlabel("Frame Index")
    plt.ylabel(ylabel)
    plt.legend()
    plt.tight_layout()
    save_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(str(save_path), dpi=150)
    plt.close()


def plot_one_curve(
    save_path: Path,
    y: np.ndarray,
    label: str,
    title: str,
    ylabel: str,
    vline_idx: Optional[int] = None,
) -> None:
    x = np.arange(len(y))
    plt.figure()
    plt.plot(x, y, label=label)
    if vline_idx is not None:
        plt.axvline(vline_idx, linestyle="--")
    plt.title(title)
    plt.xlabel("Frame Index")
    plt.ylabel(ylabel)
    plt.legend()
    plt.tight_layout()
    save_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(str(save_path), dpi=150)
    plt.close()


def metric_sign_hint(key: str) -> str:
    """
    ç»Ÿä¸€è§£é‡Šâ€œæ­£è´Ÿå·/æ¯”ä¾‹â€çš„è¯»æ³•ï¼š
    - *_ratioï¼š>1 å·¦>å³ï¼Œ<1 å·¦<å³ï¼Œâ‰ˆ1 å¯¹ç§°
    - *_asymmetryï¼šé€šå¸¸ >=0ï¼Œè¶Šæ¥è¿‘ 0 è¶Šå¯¹ç§°
    - *_diffï¼ˆä¾‹å¦‚ oral_angle_diff = left - rightï¼‰ï¼šå¯èƒ½æœ‰æ­£è´Ÿï¼Œæ­£=å·¦>å³ï¼Œè´Ÿ=å³>å·¦
    """
    k = key.lower()
    if "ratio" in k:
        return "ï¼ˆæ¯”ä¾‹ï¼š>1 å·¦>å³ï¼Œ<1 å·¦<å³ï¼Œâ‰ˆ1 å¯¹ç§°ï¼‰"
    if "asym" in k:
        return "ï¼ˆä¸å¯¹ç§°ï¼šè¶Šæ¥è¿‘ 0 è¶Šå¯¹ç§°ï¼‰"
    if k.endswith("diff") or "angle_diff" in k:
        return "ï¼ˆæ–¹å‘å·®ï¼šæ­£=å·¦>å³ï¼Œè´Ÿ=å³>å·¦ï¼‰"
    return ""


def pick_highlights(action_name: str, indicators: Dict[str, float], dynamic: Dict[str, float], interp: Dict[str, Any]) -> Dict[str, Any]:
    """ç»™ overview.html / summary.csv ç”¨çš„â€œå…³é”®æŒ‡æ ‡â€æŒ‘é€‰ï¼ˆå°½é‡å°‘ä½†å¤Ÿç”¨ï¼‰ã€‚"""
    h: Dict[str, Any] = {}
    if "function_pct" in indicators:
        h["function_pct"] = indicators["function_pct"]

    # é€šç”¨ï¼šå·¦å³æ¯”ä¾‹/å·®å¼‚/è”åŠ¨
    for k in [
        "closure_ratio", "eye_asymmetry", "both_complete_closure",
        "left_complete_closure", "right_complete_closure",
        "lift_ratio", "lift_asymmetry",
        "oral_height_diff", "oral_angle_diff", "nlf_change_ratio",
        "cheek_asymmetry", "nostril_asymmetry",
        "mouth_aspect_ratio", "mouth_width_change", "face_width_change",
        "left_eye_synkinesis", "right_eye_synkinesis",
    ]:
        if k in indicators:
            h[k] = indicators[k]

    if "motion_asymmetry" in dynamic:
        h["motion_asymmetry"] = dynamic["motion_asymmetry"]

    # NeutralFaceï¼šé™æ€å¯¹ç§° + Sunnybrook è¡¨Aç¤ºä¾‹
    if action_name == ActionNames.NEUTRAL_FACE:
        for k in ["eye_area_ratio", "nlf_length_ratio", "face_symmetry_score"]:
            if k in indicators:
                h[k] = indicators[k]
        if isinstance(interp.get("sunnybrook_static"), dict):
            h["sunnybrook_static"] = interp["sunnybrook_static"]

    # çœ¨çœ¼ï¼šç»Ÿè®¡å’Œä¸€å¥è¯å‘ç°
    if isinstance(interp.get("blink_analysis"), dict):
        h["blink_analysis"] = interp["blink_analysis"]
    if isinstance(interp.get("key_findings"), list):
        h["key_findings"] = interp["key_findings"]

    return h


def write_metrics_md(path: Path, indicators: Dict[str, Any], dynamic: Dict[str, Any], interp: Dict[str, Any]) -> None:
    """æŠŠæŒ‡æ ‡åšæˆâ€œäººèƒ½è¯»æ‡‚â€çš„åˆ—è¡¨ï¼Œæ–¹ä¾¿ä½ è‚‰çœ¼æ ¸å¯¹ã€‚"""
    lines = []
    lines.append("# æŒ‡æ ‡è§£é‡Šï¼ˆä¾¿äºæ ¸å¯¹ï¼‰\n")

    if indicators:
        lines.append("## indicatorsï¼ˆåŠ¨ä½œå…³é”®å‡ ä½•æŒ‡æ ‡ï¼‰\n")
        for k in sorted(indicators.keys()):
            v = indicators[k]
            lines.append(f"- `{k}` = {v} {metric_sign_hint(k)}")
        lines.append("")

    if dynamic:
        lines.append("## dynamic_featuresï¼ˆåŠ¨ä½œçš„è¿åŠ¨å­¦ç‰¹å¾ï¼‰\n")
        for k in sorted(dynamic.keys()):
            v = dynamic[k]
            lines.append(f"- `{k}` = {v} {metric_sign_hint(k)}")
        lines.append("")

    if interp:
        lines.append("## interpretabilityï¼ˆæ›²çº¿/äº‹ä»¶/å…³é”®å‘ç°ï¼‰\n")
        # åªæŠŠâ€œå¯è¯»â€çš„å†…å®¹åˆ—å‡ºæ¥ï¼Œæ›²çº¿æœ¬èº«æ”¾ plot_*.png
        for k in sorted(interp.keys()):
            if isinstance(interp[k], (list, dict, str, int, float, bool)) and k not in [
                "left_ear_curve", "right_ear_curve",
                "left_openness_curve", "right_openness_curve",
                "left_brow_curve", "right_brow_curve",
                "mouth_width_curve",
            ]:
                lines.append(f"- `{k}` = {json.dumps(_jsonable(interp[k]), ensure_ascii=False)}")
        lines.append("")

    path.write_text("\n".join(lines), encoding="utf-8")


# =============================================================================
# 11 åŠ¨ä½œé¡ºåº + å®ä¾‹
# =============================================================================
ACTION_ORDER = [
    ActionNames.NEUTRAL_FACE,
    ActionNames.SPONTANEOUS_EYE_BLINK,
    ActionNames.VOLUNTARY_EYE_BLINK,
    ActionNames.CLOSE_EYE_SOFTLY,
    ActionNames.CLOSE_EYE_HARDLY,
    ActionNames.RAISE_EYEBROW,
    ActionNames.SMILE,
    ActionNames.SHRUG_NOSE,
    ActionNames.SHOW_TEETH,
    ActionNames.BLOW_CHEEK,
    ActionNames.LIP_PUCKER,
]

ACTION_INSTANCES = {
    ActionNames.NEUTRAL_FACE: NeutralFaceAction(),
    ActionNames.SPONTANEOUS_EYE_BLINK: SpontaneousEyeBlinkAction(),
    ActionNames.VOLUNTARY_EYE_BLINK: VoluntaryEyeBlinkAction(),
    ActionNames.CLOSE_EYE_SOFTLY: CloseEyeSoftlyAction(),
    ActionNames.CLOSE_EYE_HARDLY: CloseEyeHardlyAction(),
    ActionNames.RAISE_EYEBROW: RaiseEyebrowAction(),
    ActionNames.SMILE: SmileAction(),
    ActionNames.SHRUG_NOSE: ShrugNoseAction(),
    ActionNames.SHOW_TEETH: ShowTeethAction(),
    ActionNames.BLOW_CHEEK: BlowCheekAction(),
    ActionNames.LIP_PUCKER: LipPuckerAction(),
}
ACTION_CLASS_MAP = {
    ActionNames.NEUTRAL_FACE: NeutralFaceAction,
    ActionNames.SPONTANEOUS_EYE_BLINK: SpontaneousEyeBlinkAction,
    ActionNames.VOLUNTARY_EYE_BLINK: VoluntaryEyeBlinkAction,
    ActionNames.CLOSE_EYE_SOFTLY: CloseEyeSoftlyAction,
    ActionNames.CLOSE_EYE_HARDLY: CloseEyeHardlyAction,
    ActionNames.RAISE_EYEBROW: RaiseEyebrowAction,
    ActionNames.SMILE: SmileAction,
    ActionNames.SHRUG_NOSE: ShrugNoseAction,
    ActionNames.SHOW_TEETH: ShowTeethAction,
    ActionNames.BLOW_CHEEK: BlowCheekAction,
    ActionNames.LIP_PUCKER: LipPuckerAction,
}


# =============================================================================
# æ ¸å¿ƒï¼šè¯»è§†é¢‘ â†’ landmarks/frames â†’ åŠ¨ä½œåˆ†æ â†’ è½ç›˜
# =============================================================================
def extract_landmarks_and_frames(
    extractor: LandmarkExtractor,
    video_path: str,
    start_frame: int = 0,
    end_frame: Optional[int] = None,
    max_frames: Optional[int] = None
) -> Tuple[List[Any], List[np.ndarray], Dict[str, Any]]:
    info = extractor.get_video_info(video_path) or {}
    total = info.get("total_frames", None)

    s = int(start_frame or 0)
    if end_frame is None:
        e = (total - 1) if isinstance(total, int) and total > 0 else None
    else:
        e = int(end_frame)

    if e is not None and max_frames is not None and max_frames > 0:
        e = min(e, s + int(max_frames) - 1)

    landmarks_seq, frames_seq = extractor.extract_sequence(video_path, start_frame=s, end_frame=e)
    if landmarks_seq is None or frames_seq is None:
        return [], [], info
    return landmarks_seq, frames_seq, info


def run_one_action(
    action_name: str,
    extractor: LandmarkExtractor,
    video_path: str,
    out_action_dir: Path,
    start_frame: int = 0,
    end_frame: Optional[int] = None,
    fps_hint: Optional[float] = None,
    neutral_indicators: Optional[Dict[str, float]] = None
) -> Optional[Dict[str, Any]]:
    action = ACTION_CLASS_MAP[action_name]()  # æ¯æ¬¡åˆ›å»ºä¸€ä¸ªå®ä¾‹ï¼ˆæ— çŠ¶æ€ï¼Œå®‰å…¨ï¼‰

    landmarks_seq, frames_seq, info = extract_landmarks_and_frames(
        extractor,
        video_path=video_path,
        start_frame=start_frame,
        end_frame=end_frame,
        max_frames=MAX_FRAMES_PER_VIDEO
    )
    if not landmarks_seq or not frames_seq:
        print(f"  âŒ {action_name}: è¯»å–å¤±è´¥æˆ–æ— å¸§ {video_path}")
        return None

    w = int(info.get("width", frames_seq[0].shape[1]))
    h = int(info.get("height", frames_seq[0].shape[0]))
    fps = float(fps_hint or info.get("fps") or 30.0)

    result = action.process(
        landmarks_seq=landmarks_seq,
        frames_seq=frames_seq,
        w=w,
        h=h,
        fps=fps,
        neutral_indicators=neutral_indicators
    )
    if result is None:
        print(f"  âŒ {action_name}: process() è¿”å› Noneï¼ˆå¯èƒ½å…³é”®ç‚¹å…¨ç¼ºå¤±ï¼‰")
        return None

    peak_idx = int(result.peak_frame_idx)
    peak_lm = landmarks_seq[peak_idx] if 0 <= peak_idx < len(landmarks_seq) else None
    peak_raw = result.peak_frame

    ensure_dir(out_action_dir)

    # ä¿å­˜å³°å€¼å¸§ raw / vis
    raw_path = out_action_dir / "peak_raw.jpg"
    vis_path = out_action_dir / "peak_vis.jpg"

    raw_img = peak_raw
    if SAVE_THUMBNAIL:
        raw_img = resize_keep_aspect(raw_img, THUMB_MAX_W)
    imwrite(raw_path, raw_img)

    if peak_lm is not None:
        vis_img = action.visualize_peak_frame(
            frame=peak_raw, landmarks=peak_lm, indicators=result.indicators, w=w, h=h
        )
    else:
        vis_img = peak_raw.copy()

    if SAVE_THUMBNAIL:
        vis_img = resize_keep_aspect(vis_img, THUMB_MAX_W)
    imwrite(vis_path, vis_img)

    # ä¿å­˜ JSON
    write_json(out_action_dir / "indicators.json", result.indicators)
    write_json(out_action_dir / "dynamic_features.json", result.dynamic_features)
    write_json(out_action_dir / "interpretability.json", result.interpretability)

    # é¢å¤–ï¼šæŒ‡æ ‡â€œäººè¯è§£é‡Šâ€
    write_metrics_md(out_action_dir / "metrics.md", result.indicators, result.dynamic_features, result.interpretability)

    # è‡ªåŠ¨ç”Ÿæˆæ›²çº¿å›¾ï¼ˆæŒ‰ interpretability é‡Œçš„å¸¸è§ keyï¼‰
    interp = result.interpretability or {}

    if "left_ear_curve" in interp and "right_ear_curve" in interp:
        l = np.asarray(interp["left_ear_curve"])
        r = np.asarray(interp["right_ear_curve"])
        spans = None
        if isinstance(interp.get("left_blink_events"), list):
            spans = []
            for e in interp["left_blink_events"]:
                try:
                    spans.append((int(e["start"]), int(e["end"])))
                except Exception:
                    pass
        plot_two_curves(
            save_path=out_action_dir / "plot_ear.png",
            y1=l, y2=r,
            label1="Left EAR", label2="Right EAR",
            title=f"{action_name} - EAR Curve",
            ylabel="EAR",
            vline_idx=peak_idx,
            spans=spans
        )

    if "left_openness_curve" in interp and "right_openness_curve" in interp:
        l = np.asarray(interp["left_openness_curve"])
        r = np.asarray(interp["right_openness_curve"])
        plot_two_curves(
            save_path=out_action_dir / "plot_openness.png",
            y1=l, y2=r,
            label1="Left Openness", label2="Right Openness",
            title=f"{action_name} - Openness Curve (baseline=Neutral)",
            ylabel="Openness (ratio)",
            vline_idx=peak_idx
        )

    if "left_brow_curve" in interp and "right_brow_curve" in interp:
        l = np.asarray(interp["left_brow_curve"])
        r = np.asarray(interp["right_brow_curve"])
        plot_two_curves(
            save_path=out_action_dir / "plot_brow.png",
            y1=l, y2=r,
            label1="Left Brow Height (norm)", label2="Right Brow Height (norm)",
            title=f"{action_name} - Brow Height Curve",
            ylabel="Brow Height (norm)",
            vline_idx=peak_idx
        )

    if "mouth_width_curve" in interp:
        y = np.asarray(interp["mouth_width_curve"])
        plot_one_curve(
            save_path=out_action_dir / "plot_mouth_width.png",
            y=y,
            label="Mouth Width (px)",
            title=f"{action_name} - Mouth Width Curve",
            ylabel="Pixels",
            vline_idx=peak_idx
        )

    # æ±‡æ€»ç»™ overview / summary.csv
    highlights = pick_highlights(action_name, result.indicators, result.dynamic_features, result.interpretability)
    payload = {
        "action_name": action_name,
        "video_path": video_path,
        "start_frame": int(start_frame or 0),
        "end_frame": int(end_frame) if end_frame is not None else None,
        "fps": fps,
        "w": w,
        "h": h,
        "peak_frame_idx": peak_idx,
        "unit_length_icd": float(result.unit_length),
        "highlights": highlights,
        "files": {
            "peak_raw": "peak_raw.jpg",
            "peak_vis": "peak_vis.jpg",
        }
    }
    write_json(out_action_dir / "summary.json", payload)
    return payload


_WORKER_EXTRACTOR = None

def _worker_init(model_path: str):
    """æ¯ä¸ªè¿›ç¨‹å¯åŠ¨æ—¶åˆå§‹åŒ–ä¸€æ¬¡ MediaPipe Landmarker"""
    global _WORKER_EXTRACTOR
    _WORKER_EXTRACTOR = LandmarkExtractor(model_path)
    _WORKER_EXTRACTOR.__enter__()  # create landmarker

def _worker_run_one_action(task: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    """å­è¿›ç¨‹æ‰§è¡Œå•ä¸ªåŠ¨ä½œï¼ˆå„è‡ªè¯»è§†é¢‘ã€æå…³é”®ç‚¹ã€åˆ†æã€è½ç›˜ï¼‰"""
    global _WORKER_EXTRACTOR

    return run_one_action(
        action_name=task["action_name"],
        extractor=_WORKER_EXTRACTOR,
        video_path=task["video_path"],
        out_action_dir=Path(task["out_action_dir"]),
        start_frame=task.get("start_frame", 0),
        end_frame=task.get("end_frame", None),
        fps_hint=task.get("fps_hint", None),
        neutral_indicators=task.get("neutral_indicators", None),
    )


# =============================================================================
# DB æ¨¡å¼ï¼šè¯»å– examinations + video_files
# =============================================================================
def db_fetch_examinations(db_path: str, target_exam_id: Optional[str], limit: Optional[int]) -> List[Dict[str, Any]]:
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    if target_exam_id:
        cursor.execute("""
            SELECT examination_id, patient_id, capture_datetime, has_labels, has_videos
            FROM examinations
            WHERE examination_id = ?
        """, (target_exam_id,))
    else:
        cursor.execute("""
            SELECT examination_id, patient_id, capture_datetime, has_labels, has_videos
            FROM examinations
            WHERE has_videos = 1 AND is_valid = 1
            ORDER BY capture_datetime DESC
        """)

    rows = cursor.fetchall()
    conn.close()

    exams = []
    for r in rows:
        exams.append({
            "examination_id": r[0],
            "patient_id": r[1],
            "capture_datetime": r[2],
            "has_labels": r[3],
            "has_videos": r[4],
        })

    if limit is not None:
        exams = exams[: int(limit)]
    return exams


def db_fetch_videos_for_exam(db_path: str, examination_id: str) -> Dict[str, Dict[str, Any]]:
    """
    è¿”å› {action_name_en: video_info}
    å¦‚æœä¸€ä¸ªåŠ¨ä½œæœ‰å¤šä¸ªè§†é¢‘ï¼šå– video_file_index æœ€å°çš„ä¸€æ¡
    """
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    cursor.execute("""
        SELECT
            v.video_id, v.action_id, v.file_path, v.start_frame, v.end_frame, v.fps, v.video_file_index,
            at.action_name_en, at.action_name_cn
        FROM video_files v
        LEFT JOIN action_types at ON v.action_id = at.action_id
        WHERE v.examination_id = ? AND v.file_exists = 1
        ORDER BY at.display_order ASC, v.video_file_index ASC
    """, (examination_id,))
    rows = cursor.fetchall()
    conn.close()

    grouped: Dict[str, List[Dict[str, Any]]] = {}
    for (video_id, action_id, file_path, start_frame, end_frame, fps, video_file_index, action_en, action_cn) in rows:
        if not action_en:
            continue
        action_en = str(action_en).strip()
        grouped.setdefault(action_en, []).append({
            "video_id": int(video_id),
            "action_id": int(action_id),
            "action_name_en": action_en,
            "action_name_cn": action_cn,
            "file_path": file_path,
            "start_frame": int(start_frame) if start_frame is not None else 0,
            "end_frame": int(end_frame) if end_frame is not None else None,
            "fps": float(fps) if fps is not None else None,
            "video_file_index": int(video_file_index) if video_file_index is not None else 0,
        })

    selected: Dict[str, Dict[str, Any]] = {}
    for action_en, candidates in grouped.items():
        candidates_sorted = sorted(candidates, key=lambda x: x.get("video_file_index", 0))
        selected[action_en] = candidates_sorted[0]
        selected[action_en]["all_candidates"] = candidates_sorted

    return selected


def db_fetch_labels(db_path: str, examination_id: str) -> Dict[str, Any]:
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    cursor.execute("""
        SELECT has_palsy, palsy_side, hb_grade, sunnybrook_score
        FROM examination_labels
        WHERE examination_id = ?
    """, (examination_id,))
    row = cursor.fetchone()
    conn.close()
    if not row:
        return {}
    return {
        "has_palsy": row[0],
        "palsy_side": row[1],
        "hb_grade": row[2],
        "sunnybrook_score": row[3],
    }


# =============================================================================
# FOLDER æ¨¡å¼ï¼šè¯»å– phone_videos/xxx/*.mp4
# =============================================================================
def folder_list_sessions(root_dir: str) -> List[Path]:
    root = Path(root_dir)
    if not root.exists():
        return []
    return sorted([p for p in root.iterdir() if p.is_dir()])


def folder_find_action_video(session_dir: Path, action_name: str) -> Optional[Path]:
    for ext in [".mp4", ".MP4", ".mov", ".MOV"]:
        p = session_dir / f"{action_name}{ext}"
        if p.exists():
            return p
    return None


# =============================================================================
# æŠ¥å‘Šç”Ÿæˆï¼šsummary.csv / diagnosis_flow.md / overview.html
# =============================================================================
def write_summary_csv(path: Path, action_summaries: List[Dict[str, Any]]) -> None:
    keys = set()
    for a in action_summaries:
        for k in (a.get("highlights") or {}).keys():
            keys.add(k)
    keys = sorted(keys)

    with path.open("w", encoding="utf-8", newline="") as f:
        w = csv.writer(f)
        w.writerow(["action_name"] + keys)
        for a in action_summaries:
            row = [a.get("action_name", "")]
            h = a.get("highlights") or {}
            for k in keys:
                row.append(_jsonable(h.get(k, "")))
            w.writerow(row)


def write_diagnosis_flow_md(path: Path, meta: Dict[str, Any], action_summaries: List[Dict[str, Any]]) -> None:
    by_name = {a["action_name"]: a for a in action_summaries}

    lines: List[str] = []
    lines.append("# é¢ç˜«è¯Šæ–­æµç¨‹å€’æ¨ï¼šæœ¬æ¬¡åˆ†æç”¨åˆ°å“ªäº›æŒ‡æ ‡\n")
    lines.append(f"- session/examination_id: `{meta.get('id','')}`")
    if meta.get("patient_id"):
        lines.append(f"- patient_id: `{meta.get('patient_id')}`")
    if meta.get("capture_datetime"):
        lines.append(f"- capture_datetime: `{meta.get('capture_datetime')}`")
    if meta.get("labels"):
        lines.append(f"- labels: `{json.dumps(_jsonable(meta.get('labels')), ensure_ascii=False)}`")
    lines.append("")

    lines.append("## 0) ç»Ÿä¸€å•ä½ï¼ˆå½’ä¸€åŒ–ï¼‰\n")
    lines.append("- æ‰€æœ‰å…³é”®è·ç¦»/é¢ç§¯ä»¥ **ä¸¤çœ¼å†…çœ¦è·ç¦» ICD** ä½œä¸ºå•ä½é•¿åº¦å½’ä¸€åŒ–ï¼ˆä½ çš„ actions ä»£ç é‡Œå°±æ˜¯è¿™æ ·åšçš„ï¼‰ã€‚\n")

    lines.append("## 1) é™æ¯ NeutralFaceï¼šå…ˆç¡®å®šâ€œåŸºçº¿ + é™æ€ä¸å¯¹ç§°â€\n")
    if ActionNames.NEUTRAL_FACE in by_name:
        h = by_name[ActionNames.NEUTRAL_FACE].get("highlights", {})
        lines.append("- ä½ åº”è¯¥å…ˆçœ‹ï¼š`actions/NeutralFace/peak_vis.jpg` æ˜¯å¦ç”»å¯¹åŒºåŸŸï¼›å†çœ‹æ›²çº¿ `plot_ear.png` å³°å€¼å¸§æ˜¯å¦è½åœ¨æå€¼å¤„ã€‚")
        for k, v in h.items():
            lines.append(f"  - `{k}` = {v} {metric_sign_hint(k)}")
        lines.append("- `sunnybrook_static`ï¼šneutral_face.py é‡Œç»™å‡ºè¡¨Aï¼ˆé™æ€ï¼‰é˜ˆå€¼åŒ–ç¤ºä¾‹ï¼ˆ0=æ­£å¸¸ï¼‰ã€‚\n")
    else:
        lines.append("- âš ï¸ ç¼ºå¤± NeutralFaceï¼šåç»­å˜åŒ–é‡/è”åŠ¨çš„â€œåŸºçº¿â€ä¼šä¸å¯é ã€‚\n")

    lines.append("## 2) çœ¼éƒ¨åŠŸèƒ½ï¼šçœ¨çœ¼ + è½»é—­çœ¼ + ç”¨åŠ›é—­çœ¼\n")
    for an in [ActionNames.SPONTANEOUS_EYE_BLINK, ActionNames.VOLUNTARY_EYE_BLINK,
               ActionNames.CLOSE_EYE_SOFTLY, ActionNames.CLOSE_EYE_HARDLY]:
        if an in by_name:
            h = by_name[an].get("highlights", {})
            lines.append(f"### {an}")
            lines.append("- å»ºè®®ä½ æŒ‰é¡ºåºçœ‹ï¼š`peak_vis.jpg` â†’ `plot_ear.png / plot_openness.png` â†’ `metrics.md`")
            for k, v in h.items():
                lines.append(f"  - `{k}` = {v} {metric_sign_hint(k)}")
            lines.append("")
        else:
            lines.append(f"- âš ï¸ ç¼ºå¤±è§†é¢‘ï¼š{an}")
    lines.append("")

    lines.append("## 3) é¢è‚Œ RaiseEyebrowï¼šæŠ¬çœ‰åŠŸèƒ½ + çœ¼éƒ¨è”åŠ¨ï¼ˆsynkinesisï¼‰\n")
    if ActionNames.RAISE_EYEBROW in by_name:
        h = by_name[ActionNames.RAISE_EYEBROW].get("highlights", {})
        lines.append("- é‡ç‚¹ï¼š`left/right_brow_lift`ã€`lift_ratio`ã€`function_pct`ï¼›è”åŠ¨çœ‹ `left/right_eye_synkinesis`ï¼ˆè¶Šå¤§è¶Šå¼‚å¸¸ï¼‰ã€‚")
        for k, v in h.items():
            lines.append(f"  - `{k}` = {v} {metric_sign_hint(k)}")
    else:
        lines.append("- âš ï¸ ç¼ºå¤±è§†é¢‘ï¼šRaiseEyebrow")
    lines.append("")

    lines.append("## 4) å£å‘¨åŠŸèƒ½ï¼šSmile / ShowTeeth / LipPucker / BlowCheek / ShrugNose\n")
    for an in [ActionNames.SMILE, ActionNames.SHOW_TEETH, ActionNames.LIP_PUCKER, ActionNames.BLOW_CHEEK, ActionNames.SHRUG_NOSE]:
        if an in by_name:
            h = by_name[an].get("highlights", {})
            lines.append(f"### {an}")
            lines.append("- é‡ç‚¹ï¼š`function_pct` + ä¸è¯¥åŠ¨ä½œç›¸å…³çš„ ratio/diff/asymmetryï¼ˆçœ‹ metrics.md æ›´æ¸…æ™°ï¼‰ã€‚")
            for k, v in h.items():
                lines.append(f"  - `{k}` = {v} {metric_sign_hint(k)}")
            lines.append("")
        else:
            lines.append(f"- âš ï¸ ç¼ºå¤±è§†é¢‘ï¼š{an}")

    lines.append("\n## 5) ä½ äººå·¥æ ¸å¯¹ç®—æ³•æ˜¯å¦æ­£ç¡®ï¼šä¸€å¥—â€œå›ºå®šæ£€æŸ¥é¡ºåºâ€\n")
    lines.append("1) æ¯ä¸ªåŠ¨ä½œå…ˆçœ‹ `peak_vis.jpg`ï¼šç”»çš„åŒºåŸŸå¯¹ä¸å¯¹ï¼ˆçœ¼è½®å»“/çœ‰çº¿/å£è§’/é¼»ç¿¼/é¢Šéƒ¨ï¼‰ã€‚")
    lines.append("2) å†çœ‹ `plot_*.png`ï¼šå³°å€¼å¸§æ˜¯å¦è½åœ¨æ›²çº¿æå€¼ï¼ˆæœ€å¤§/æœ€å°ï¼‰å¤„ï¼›å·¦å³æ›²çº¿è¶‹åŠ¿æ˜¯å¦åˆç†ã€‚")
    lines.append("3) æœ€åçœ‹ `metrics.md`ï¼šratio/diff çš„æ­£è´Ÿå·å’Œæ–¹å‘æ˜¯å¦ç¬¦åˆä½ è‚‰çœ¼è§‚å¯Ÿã€‚")

    path.write_text("\n".join(lines), encoding="utf-8")


def write_overview_html(path: Path, meta: Dict[str, Any], action_summaries: List[Dict[str, Any]]) -> None:
    rows_html = []
    for a in action_summaries:
        action_name = a["action_name"]
        rel_dir = f"actions/{action_name}"
        highlights = a.get("highlights") or {}

        li = []
        for k, v in highlights.items():
            li.append(f"<li><code>{k}</code>: {json.dumps(_jsonable(v), ensure_ascii=False)}</li>")
        ul = "<ul>" + "".join(li) + "</ul>" if li else ""

        rows_html.append(f"""
        <tr>
          <td><code>{action_name}</code></td>
          <td>{ul}</td>
          <td>
            <a href="{rel_dir}/peak_vis.jpg" target="_blank">peak_vis</a> |
            <a href="{rel_dir}/plot_ear.png" target="_blank">plot_ear</a> |
            <a href="{rel_dir}/plot_openness.png" target="_blank">plot_open</a> |
            <a href="{rel_dir}/metrics.md" target="_blank">metrics.md</a> |
            <a href="{rel_dir}/summary.json" target="_blank">summary.json</a>
          </td>
        </tr>
        """)

    html = f"""<!doctype html>
<html lang="zh">
<head>
  <meta charset="utf-8"/>
  <title>11 Actions Interpretability - {meta.get('id','')}</title>
  <style>
    body {{ font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica,Arial; margin: 24px; }}
    h1 {{ margin: 0 0 8px 0; }}
    .meta {{ color:#444; margin-bottom:16px; }}
    table {{ border-collapse: collapse; width: 100%; }}
    th, td {{ border: 1px solid #ddd; padding: 10px; vertical-align: top; }}
    th {{ background: #f6f6f6; text-align:left; }}
    code {{ background:#f2f2f2; padding:2px 4px; border-radius:4px; }}
    ul {{ margin: 6px 0 0 18px; }}
  </style>
</head>
<body>
  <h1>11åŠ¨ä½œå¯è§£é‡Šæ€§æ€»è§ˆ</h1>
  <div class="meta">
    <div><b>session/exam id</b>: <code>{meta.get('id','')}</code></div>
    {f"<div><b>patient</b>: <code>{meta.get('patient_id')}</code></div>" if meta.get('patient_id') else ""}
    {f"<div><b>capture_datetime</b>: <code>{meta.get('capture_datetime')}</code></div>" if meta.get('capture_datetime') else ""}
    {f"<div><b>labels</b>: <code>{json.dumps(_jsonable(meta.get('labels')), ensure_ascii=False)}</code></div>" if meta.get('labels') else ""}
    <div style="margin-top:8px;">
      <a href="diagnosis_flow.md" target="_blank">diagnosis_flow.mdï¼ˆæµç¨‹+æŒ‡æ ‡è§£é‡Šï¼‰</a> |
      <a href="summary.csv" target="_blank">summary.csvï¼ˆè¡¨æ ¼æ‘˜è¦ï¼‰</a>
    </div>
  </div>

  <table>
    <thead>
      <tr><th style="width:160px;">Action</th><th>Highlightsï¼ˆå…³é”®æŒ‡æ ‡ï¼‰</th><th style="width:360px;">Files</th></tr>
    </thead>
    <tbody>
      {''.join(rows_html)}
    </tbody>
  </table>
</body>
</html>
"""
    path.write_text(html, encoding="utf-8")


# =============================================================================
# ä¸»æµç¨‹ï¼šè·‘ä¸€ä¸ª session/examï¼ˆå…ˆ NeutralFace å†å…¶å®ƒåŠ¨ä½œï¼‰
# =============================================================================
def analyze_one_session(
    session_id: str,
    videos: Dict[str, Dict[str, Any]],
    session_out_dir: Path,
    extractor: LandmarkExtractor,
    meta: Dict[str, Any]
) -> None:
    ensure_dir(session_out_dir)
    ensure_dir(session_out_dir / "actions")

    summaries: List[Dict[str, Any]] = []

    # -----------------------
    # 1) NeutralFace å…ˆè·‘ï¼ˆä¸²è¡Œï¼‰
    # -----------------------
    neutral_indicators = None
    if ActionNames.NEUTRAL_FACE in videos:
        v = videos[ActionNames.NEUTRAL_FACE]
        video_path = v["file_path"]
        if video_path and os.path.exists(video_path):
            out_action_dir = session_out_dir / "actions" / ActionNames.NEUTRAL_FACE
            print(f"  â–¶ NeutralFace (baseline): {Path(video_path).name}")

            t0 = time.time()
            payload = run_one_action(
                action_name=ActionNames.NEUTRAL_FACE,
                extractor=extractor,
                video_path=video_path,
                out_action_dir=out_action_dir,
                start_frame=v.get("start_frame", 0) or 0,
                end_frame=v.get("end_frame", None),
                fps_hint=v.get("fps", None),
                neutral_indicators=None
            )
            print(f"  âœ… NeutralFace done: {time.time()-t0:.2f}s")

            if payload is not None:
                summaries.append(payload)
                neutral_indicators = json.load((out_action_dir / "indicators.json").open("r", encoding="utf-8"))
        else:
            print(f"  âš ï¸ NeutralFace æ–‡ä»¶ä¸å­˜åœ¨ï¼š{video_path}")
    else:
        print("  âš ï¸ ç¼ºå¤± NeutralFaceï¼šåç»­åŠ¨ä½œå°†æ²¡æœ‰ baselineï¼ˆä¸æ¨èï¼‰")

    # -----------------------
    # 2) å…¶å®ƒåŠ¨ä½œï¼šå¹¶è¡Œï¼ˆå¤š CPUï¼‰
    # -----------------------
    other_actions = [a for a in ACTION_ORDER if a != ActionNames.NEUTRAL_FACE and a in videos]

    tasks = []
    for action_name in other_actions:
        v = videos[action_name]
        video_path = v["file_path"]
        if not video_path or not os.path.exists(video_path):
            print(f"  âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {action_name}: {video_path}")
            continue

        out_action_dir = session_out_dir / "actions" / action_name
        tasks.append({
            "action_name": action_name,
            "video_path": video_path,
            "out_action_dir": str(out_action_dir),
            "start_frame": v.get("start_frame", 0) or 0,
            "end_frame": v.get("end_frame", None),
            "fps_hint": v.get("fps", None),
            "neutral_indicators": neutral_indicators
        })

    if PARALLEL_AFTER_NEUTRAL and len(tasks) > 1:
        print(f"  ğŸš€ å¹¶è¡Œåˆ†æå…¶å®ƒåŠ¨ä½œï¼š{len(tasks)} ä¸ªä»»åŠ¡ | workers={NUM_WORKERS}")
        t_all = time.time()

        with ProcessPoolExecutor(
            max_workers=NUM_WORKERS,
            initializer=_worker_init,
            initargs=(MODEL_PATH,)
        ) as ex:
            futures = [ex.submit(_worker_run_one_action, t) for t in tasks]
            for fu in as_completed(futures):
                res = fu.result()
                if res is not None:
                    summaries.append(res)

        print(f"  âœ… å…¶å®ƒåŠ¨ä½œå¹¶è¡Œå®Œæˆï¼š{time.time()-t_all:.2f}s")

    else:
        # é€€å›ä¸²è¡Œ
        for t in tasks:
            print(f"  â–¶ {t['action_name']}: {Path(t['video_path']).name}")
            res = run_one_action(
                action_name=t["action_name"],
                extractor=extractor,
                video_path=t["video_path"],
                out_action_dir=Path(t["out_action_dir"]),
                start_frame=t["start_frame"],
                end_frame=t["end_frame"],
                fps_hint=t["fps_hint"],
                neutral_indicators=neutral_indicators
            )
            if res is not None:
                summaries.append(res)

    # -----------------------
    # 3) è¾“å‡ºæ±‡æ€»ï¼ˆä¿æŒåŠ¨ä½œé¡ºåºï¼‰
    # -----------------------
    order_index = {name: i for i, name in enumerate(ACTION_ORDER)}
    summaries.sort(key=lambda x: order_index.get(x.get("action_name", ""), 999))

    meta = dict(meta)
    meta["id"] = session_id
    write_json(session_out_dir / "_meta.json", meta)
    write_json(session_out_dir / "all_actions_summary.json", summaries)
    write_summary_csv(session_out_dir / "summary.csv", summaries)
    write_diagnosis_flow_md(session_out_dir / "diagnosis_flow.md", meta, summaries)
    write_overview_html(session_out_dir / "overview.html", meta, summaries)

# =============================================================================
# ä¸¤ç§å…¥å£ï¼šDB / Folder
# =============================================================================
def main_db():
    if not os.path.exists(DB_PATH):
        raise FileNotFoundError(f"DB_PATH ä¸å­˜åœ¨ï¼š{DB_PATH}")

    exams = db_fetch_examinations(DB_PATH, TARGET_EXAMINATION_ID, MAX_EXAMS)
    if not exams:
        print("âš ï¸ æ•°æ®åº“é‡Œæ²¡æœ‰å¯å¤„ç†çš„ examinationsï¼ˆhas_videos=1, is_valid=1ï¼‰")
        return

    out_root = Path(OUTPUT_DIR)
    ensure_dir(out_root)

    print("=" * 80)
    print(f"MODE=db | DB_PATH={DB_PATH}")
    print(f"MODEL_PATH={MODEL_PATH}")
    print(f"OUTPUT_DIR={out_root}")
    print(f"å°†å¤„ç† examinations: {len(exams)}")
    print("=" * 80)

    with LandmarkExtractor(MODEL_PATH) as extractor:
        for i, e in enumerate(exams, 1):
            exam_id = e["examination_id"]
            print(f"\n[{i}/{len(exams)}] exam_id={exam_id} patient={e.get('patient_id')}")

            videos_all = db_fetch_videos_for_exam(DB_PATH, exam_id)
            vids: Dict[str, Dict[str, Any]] = {an: videos_all[an] for an in ACTION_ORDER if an in videos_all}

            labels = db_fetch_labels(DB_PATH, exam_id)
            meta = {
                "source": "db",
                "db_path": DB_PATH,
                "patient_id": e.get("patient_id"),
                "capture_datetime": e.get("capture_datetime"),
                "labels": labels,
            }

            analyze_one_session(
                session_id=exam_id,
                videos=vids,
                session_out_dir=out_root / exam_id,
                extractor=extractor,
                meta=meta
            )


def main_folder():
    root = Path(INPUT_VIDEO_ROOT)
    if not root.exists():
        raise FileNotFoundError(f"INPUT_VIDEO_ROOT ä¸å­˜åœ¨ï¼š{root}")

    sessions = folder_list_sessions(str(root))
    if not sessions:
        print(f"âš ï¸ INPUT_VIDEO_ROOT ä¸‹æ²¡æœ‰å­æ–‡ä»¶å¤¹ï¼š{root}")
        return

    out_root = Path(OUTPUT_DIR)
    ensure_dir(out_root)

    print("=" * 80)
    print(f"MODE=folder | INPUT_VIDEO_ROOT={root}")
    print(f"MODEL_PATH={MODEL_PATH}")
    print(f"OUTPUT_DIR={out_root}")
    print(f"å°†å¤„ç† sessions: {len(sessions)}")
    print("=" * 80)

    with LandmarkExtractor(MODEL_PATH) as extractor:
        for i, sd in enumerate(sessions, 1):
            session_id = sd.name
            print(f"\n[{i}/{len(sessions)}] session={session_id}")

            vids: Dict[str, Dict[str, Any]] = {}
            for an in ACTION_ORDER:
                vp = folder_find_action_video(sd, an)
                if vp is None:
                    continue
                vids[an] = {"file_path": str(vp), "start_frame": 0, "end_frame": None, "fps": None}

            meta = {"source": "folder", "input_dir": str(sd)}
            analyze_one_session(
                session_id=session_id,
                videos=vids,
                session_out_dir=out_root / session_id,
                extractor=extractor,
                meta=meta
            )


if __name__ == "__main__":
    mp.set_start_method("spawn", force=True)
    if not os.path.exists(MODEL_PATH):
        raise FileNotFoundError(
            f"MODEL_PATH ä¸å­˜åœ¨ï¼š{MODEL_PATH}\n"
            f"è¯·æŠŠ face_landmarker.task æ”¾åˆ°è¯¥è·¯å¾„ï¼Œæˆ–ä¿®æ”¹æœ¬æ–‡ä»¶é¡¶éƒ¨çš„ MODEL_PATHã€‚"
        )

    if MODE.lower() == "db":
        main_db()
    elif MODE.lower() == "folder":
        main_folder()
    else:
        raise ValueError("MODE åªèƒ½æ˜¯ 'db' æˆ– 'folder'")
