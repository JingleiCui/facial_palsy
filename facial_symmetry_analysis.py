# -*- coding: utf-8 -*-
"""
facial_symmetry_analysis.py

é¢éƒ¨å¯¹ç§°æ€§åˆ†æ - å‚è€ƒè®ºæ–‡ "Machine Learning Methods to Track Dynamic Facial Function in Facial Palsy"
ï¼ˆå®ç°æ€è·¯ï¼šå·¦å³å¯¹ç§°ç‚¹å¯¹ -> æ—¶åºPearsonç›¸å…³ + å¸§çº§|Î”y|ä¸å¯¹ç§°è¯„åˆ† + å¯è§†åŒ– + é©¬æ°è·ç¦»ï¼‰

æœ¬ç‰ˆæœ¬æ”¹åŠ¨ï¼ˆç›¸å¯¹ä½ å½“å‰çš„ facial_symmetry_analysis.pyï¼‰ï¼š
1) batch_process_database æ”¯æŒå¤šè¿›ç¨‹ï¼ˆProcessPoolExecutorï¼‰ï¼Œæå‡æ‰¹é‡é€Ÿåº¦
2) åœ¨è§†é¢‘ç‰‡æ®µå†…å¯¹æ¯ä¸€å¸§ç´¯è®¡æ‰€æœ‰ç‚¹å¯¹çš„ |Î”y|ï¼Œé€‰æ‹©â€œæœ€ä¸å¯¹ç§°å¸§â€ä½œä¸ºï¼š
   - overlay å åŠ çš„åº•å›¾
   - ç´¢å¼•æ£€æŸ¥å›¾ï¼ˆindex_checkï¼‰çš„åº•å›¾
   è€Œä¸æ˜¯â€œç¬¬ä¸€å¸§æ£€æµ‹åˆ°äººè„¸çš„å¸§â€
3) overlay çƒ­åŠ›å›¾é»˜è®¤ä½¿ç”¨â€œæœ€ä¸å¯¹ç§°å¸§â€çš„æ¯å¯¹ç‚¹ |Î”y|ï¼ˆæ›´ç›´è§‚ï¼‰
4) rolling Pearson è®¡ç®—å‘é‡åŒ–ï¼ˆcumsum ç‰ˆæœ¬ï¼‰ï¼Œé¿å… O(T*F*w) çš„ä¸‰é‡å¾ªç¯

å»ºè®®ï¼ˆMacBook Pro M3 Maxï¼‰ï¼š
- num_workers å…ˆä» 6~10 è¯•èµ·ï¼ˆè¿‡å¤šä¼šå› ä¸ºè§†é¢‘è§£ç /IO/å†…éƒ¨çº¿ç¨‹è€Œå˜æ…¢ï¼‰
"""

import os
import re
import json
import csv
import sqlite3
import multiprocessing as mp
from pathlib import Path
from dataclasses import dataclass
from typing import Dict, List, Tuple, Optional

import cv2
import numpy as np
import mediapipe as mp_mediapipe
from mediapipe.tasks import python
from mediapipe.tasks.python import vision

from scipy import stats
from scipy.spatial.distance import mahalanobis
from concurrent.futures import ProcessPoolExecutor, as_completed

import matplotlib
matplotlib.use("Agg")  # å¤šè¿›ç¨‹/æ— GUIæ›´ç¨³
import matplotlib.pyplot as plt

# ä¸­æ–‡å­—ä½“/è´Ÿå·
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial Unicode MS', 'PingFang SC']
matplotlib.rcParams['axes.unicode_minus'] = False


# ==================== MediaPipe 478ç‚¹ä¸­çš„å¯¹ç§°ç‰¹å¾ç‚¹å®šä¹‰ ====================

SYMMETRY_INDEX_CONFIG = [
    {
        "region": "eyebrow",
        "pairs": {
            "left":  [336, 296, 334, 293, 300, 276, 283, 282, 295, 285],
            "right": [107,  66, 105,  63,  70,  46,  53,  52,  65,  55],
        }
    },
    {
        "region": "eye",
        "pairs": {
            "left":  [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398],
            "right": [133, 155, 154, 153, 145, 144, 163,   7,  33, 246, 161, 160, 159, 158, 157, 173],
        }
    },
    {
        "region": "pupil",
        "pairs": {"left": [473], "right": [468]}
    },
    {
        "region": "iris",
        "pairs": {"left": [474, 475, 476, 477], "right": [471, 470, 469, 472]}
    },
    {
        "region": "upper_lip",
        "pairs": {
            "left":  [267, 269, 270, 409, 291, 308, 415, 310, 311, 312],
            "right": [ 37,  39,  40, 185,  61,  78, 191,  80,  81,  82],
        }
    },
    {
        "region": "lower_lip",
        "pairs": {
            "left":  [317, 402, 318, 324, 308, 291, 375, 321, 405, 314],
            "right": [ 87, 178,  88,  95,  78,  61, 146,  91, 181,  84],
        }
    },
    {
        "region": "nose",
        "pairs": {
            "left": [250, 458, 459, 309, 392, 289, 305, 460, 294, 358, 279, 429, 420, 456],
            "right": [20, 238, 239,  79, 166,  59,  75, 240,  64, 129,  49, 209, 198, 236],
        }

    },
    {
        "region": "face_contour",
        "pairs": {
            "left":  [338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377],
            "right": [109,  67, 103,  54,  21, 162, 127, 234,  93, 132,  58, 172, 136, 150, 149, 176, 148],
        },
    },
]

EYE_INNER_CANTHUS_LEFT = 362
EYE_INNER_CANTHUS_RIGHT = 133

def build_pairs_and_names(cfg_list: list):
    """
    cfg_list: SYMMETRY_INDEX_CONFIGï¼ˆlistç»“æ„ï¼‰
    return:
      pairs: [(li, ri), ...]
      names: ["eyebrow_01", "eyebrow_02", ..., "eye_01", ...]
      region_feature_indices: {"eyebrow":[0,1,...], "eye":[...], ...}
    """
    pairs = []
    names = []
    region_feature_indices = {}

    for item in cfg_list:
        region = item["region"]
        lr = item["pairs"]
        L = lr["left"]
        R = lr["right"]

        if len(L) != len(R):
            raise ValueError(f"[{region}] left/right é•¿åº¦ä¸ä¸€è‡´: {len(L)} vs {len(R)}")

        region_feature_indices.setdefault(region, [])

        for i, (li, ri) in enumerate(zip(L, R), start=1):
            pairs.append((int(li), int(ri)))
            names.append(f"{region}_{i:02d}")
            region_feature_indices[region].append(len(pairs) - 1)

    return pairs, names, region_feature_indices


@dataclass
class SymmetryFeatures:
    """å¯¹ç§°æ€§ç‰¹å¾æ•°æ®ç»“æ„"""
    pearson_coefficients: np.ndarray              # [F]
    landmark_names: List[str]                     # len=F
    y_coords_left: np.ndarray                     # [T, F]
    y_coords_right: np.ndarray                    # [T, F]
    frame_count: int                              # T


def _safe_name(s: str) -> str:
    s = str(s) if s is not None else ""
    return re.sub(r"[^0-9A-Za-z._-]+", "_", s)[:160]


class FacialSymmetryAnalyzer:
    """é¢éƒ¨å¯¹ç§°æ€§åˆ†æå™¨"""

    def __init__(
        self,
        db_path: str,
        model_path: str = '/Users/cuijinglei/PycharmProjects/medicalProject/models/face_landmarker.task',
        verbose: bool = True,
    ):
        self.db_path = db_path
        self.model_path = model_path
        self.verbose = bool(verbose)

        # ç”Ÿæˆç‚¹å¯¹ + åç§°
        self.feature_pairs, self.feature_names, self.region_feature_indices = build_pairs_and_names(
            SYMMETRY_INDEX_CONFIG
        )
        self.n_features = len(self.feature_pairs)

        # debugï¼šæœ€ä¸å¯¹ç§°å¸§
        self._debug_frame: Optional[np.ndarray] = None
        self._debug_landmarks = None
        self._debug_frame_abs_index: Optional[int] = None  # åŸè§†é¢‘ä¸­çš„ç»å¯¹å¸§å·
        self._debug_asym_score: Optional[float] = None     # sum(|Î”y|)
        self._debug_pair_absdy: Optional[np.ndarray] = None  # [F] æœ€ä¸å¯¹ç§°å¸§æ¯å¯¹ç‚¹ |Î”y|

        if self.verbose:
            print("âœ… åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
            print(f"   - å¯¹ç§°ç‚¹å¯¹æ•°: {self.n_features}")
            print(f"   - æ•°æ®åº“: {db_path}")
            print(f"   - Landmarkeræ¨¡å‹: {model_path}")

    def _create_landmarker(self):
        base_options = python.BaseOptions(model_asset_path=self.model_path)
        options = vision.FaceLandmarkerOptions(
            base_options=base_options,
            running_mode=vision.RunningMode.VIDEO,
            num_faces=1,
            output_face_blendshapes=False,
            output_facial_transformation_matrixes=False,
        )
        return vision.FaceLandmarker.create_from_options(options)

    def extract_landmarks_from_video(
        self,
        video_path: str,
        start_frame: Optional[int] = None,
        end_frame: Optional[int] = None,
        fps: Optional[float] = None,
    ) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
        """
        Returns:
            left_coords:  [T, F, 3]
            right_coords: [T, F, 3]
        """
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")

        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 0
        start_frame = 0 if start_frame is None else int(start_frame)
        end_frame = total_frames if end_frame is None else int(end_frame)
        if total_frames > 0:
            start_frame = max(0, min(start_frame, total_frames - 1))
            end_frame = max(0, min(end_frame, total_frames))

        if start_frame > 0:
            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)

        # æ¯ä¸ªè§†é¢‘åˆ›å»ºä¸€ä¸ªå…¨æ–°çš„ landmarkerï¼ˆVIDEOæ¨¡å¼ï¼‰ï¼Œé¿å…è·¨è§†é¢‘timestampå›é€€
        landmarker = self._create_landmarker()

        coords_list = []

        # reset debug
        self._debug_frame = None
        self._debug_landmarks = None
        self._debug_frame_abs_index = None
        self._debug_asym_score = None
        self._debug_pair_absdy = None

        processed_idx = 0
        last_ts = -1
        frame_abs_idx = start_frame

        try:
            while cap.isOpened() and frame_abs_idx < end_frame:
                ret, frame = cap.read()
                if not ret:
                    break

                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                mp_image = mp_mediapipe.Image(image_format=mp_mediapipe.ImageFormat.SRGB, data=rgb_frame)

                # ç‰‡æ®µå†…æ—¶é—´æˆ³ï¼šä»0å¼€å§‹é€’å¢ï¼Œå¹¶å¼ºåˆ¶å•è°ƒé€’å¢
                if fps and fps > 0:
                    timestamp_ms = int(processed_idx * 1000.0 / float(fps))
                else:
                    timestamp_ms = processed_idx * 33  # é»˜è®¤30fps

                if timestamp_ms <= last_ts:
                    timestamp_ms = last_ts + 1
                last_ts = timestamp_ms
                processed_idx += 1

                result = landmarker.detect_for_video(mp_image, timestamp_ms)
                if result.face_landmarks:
                    face_landmarks = result.face_landmarks[0]

                    # ç»„è£…åæ ‡
                    coords = []
                    pair_absdy = np.empty((self.n_features,), dtype=np.float32)
                    for j, (left_idx, right_idx) in enumerate(self.feature_pairs):
                        left_lm = face_landmarks[left_idx]
                        right_lm = face_landmarks[right_idx]
                        coords.append([[left_lm.x, left_lm.y, left_lm.z],
                                       [right_lm.x, right_lm.y, right_lm.z]])
                        pair_absdy[j] = abs(float(left_lm.y) - float(right_lm.y))

                    coords_list.append(coords)

                    # ===== é€‰æ‹©â€œæœ€ä¸å¯¹ç§°å¸§â€ï¼šscore = sum(|Î”y|) =====
                    asym_score = float(pair_absdy.sum())
                    if (self._debug_asym_score is None) or (asym_score > self._debug_asym_score):
                        self._debug_asym_score = asym_score
                        self._debug_frame = frame.copy()
                        self._debug_landmarks = face_landmarks
                        self._debug_frame_abs_index = int(frame_abs_idx)
                        self._debug_pair_absdy = pair_absdy.copy()

                frame_abs_idx += 1

        finally:
            cap.release()
            try:
                landmarker.close()
            except Exception:
                pass

        if not coords_list:
            return None, None

        coords_array = np.array(coords_list, dtype=np.float32)  # [T, F, 2, 3]
        left_coords = coords_array[:, :, 0, :]
        right_coords = coords_array[:, :, 1, :]
        return left_coords, right_coords

    def save_index_check_image(self, frame_bgr, face_landmarks, output_path):
        """æŠŠç‚¹å¯¹è¿çº¿ã€ç‚¹ç´¢å¼•ç”»åœ¨é€‰ä¸­çš„debugå¸§ä¸Šï¼ˆç°åœ¨æ˜¯â€œæœ€ä¸å¯¹ç§°å¸§â€ï¼‰ï¼Œå¹¶åŠ ä¸€æ¡é¢ä¸­çº¿"""
        if frame_bgr is None or face_landmarks is None:
            return

        h, w = frame_bgr.shape[:2]
        vis = frame_bgr.copy()

        # 1) å…ˆç”»æ‰€æœ‰ç‚¹å¯¹ + ç¼–å· + è¿çº¿ï¼ˆå’Œä¹‹å‰ä¸€æ ·ï¼‰
        for (li, ri) in self.feature_pairs:
            l = face_landmarks[li]
            r = face_landmarks[ri]

            lx, ly = int(l.x * w), int(l.y * h)
            rx, ry = int(r.x * w), int(r.y * h)

            # è¿æ¥å·¦å³ç‚¹
            cv2.line(vis, (lx, ly), (rx, ry), (0, 255, 0), 1)

            # å·¦ç‚¹çº¢è‰² + ç´¢å¼•
            cv2.circle(vis, (lx, ly), 2, (0, 0, 255), -1)
            cv2.putText(
                vis, str(li), (lx + 2, ly - 2),
                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1
            )

            # å³ç‚¹è“è‰² + ç´¢å¼•
            cv2.circle(vis, (rx, ry), 2, (255, 0, 0), -1)
            cv2.putText(
                vis, str(ri), (rx + 2, ry - 2),
                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255, 0, 0), 1
            )

        # 2) ç”»â€œé¢ä¸­çº¿â€ï¼šç”¨çœ¼å†…çœ¦ä¸­å‚çº¿ + face_contour çš„æœ€é«˜/æœ€ä½ç‚¹
        try:
            lm_l = face_landmarks[EYE_INNER_CANTHUS_LEFT]
            lm_r = face_landmarks[EYE_INNER_CANTHUS_RIGHT]

            lx, ly = lm_l.x * w, lm_l.y * h
            rx, ry = lm_r.x * w, lm_r.y * h

            # ä¸­ç‚¹ Mï¼ˆå¤§è‡´åœ¨ä¸¤çœ¼ä¹‹é—´ï¼‰
            mx, my = (lx + rx) / 2.0, (ly + ry) / 2.0

            # çœ¼å†…çœ¦è¿çº¿æ–¹å‘ d = (dx, dy)ï¼Œé¢ä¸­çº¿æ–¹å‘å–æ³•å‘é‡ n = (-dy, dx)
            dx, dy = (rx - lx), (ry - ly)
            if abs(dx) + abs(dy) < 1e-6:
                raise ValueError("çœ¼å†…çœ¦ä¸¤ç‚¹å¤ªæ¥è¿‘ï¼Œæ— æ³•è®¡ç®—é¢ä¸­çº¿æ–¹å‘")

            M = np.array([mx, my], dtype=np.float32)
            n = np.array([-dy, dx], dtype=np.float32)  # ä¸­å‚çº¿æ–¹å‘
            denom = float(np.dot(n, n)) + 1e-6  # é˜²æ­¢é™¤é›¶

            # -------- 2.2 ç”¨ face_contour ä¸­çš„ç¬¬ä¸€å¯¹ / æœ€åä¸€å¯¹ä½œä¸ºæœ€é«˜/æœ€ä½ç‚¹ --------
            # çº¦å®šï¼šfeature_pairs ä¸­ face_contour çš„ç¬¬ä¸€å¯¹æ˜¯æœ€é«˜ç‚¹ï¼Œæœ€åä¸€å¯¹æ˜¯æœ€ä½ç‚¹
            top_li, top_ri = self.feature_pairs[0]
            bot_li, bot_ri = self.feature_pairs[-1]

            top_lm_l = face_landmarks[top_li]
            top_lm_r = face_landmarks[top_ri]
            bot_lm_l = face_landmarks[bot_li]
            bot_lm_r = face_landmarks[bot_ri]

            # é¡¶éƒ¨/åº•éƒ¨â€œå·¦å³ä¸­ç‚¹â€ï¼Œå…ˆå¤§è‡´å–åœ¨è„¸çš„ä¸­é—´
            top_mid = np.array([
                (top_lm_l.x * w + top_lm_r.x * w) / 2.0,
                (top_lm_l.y * h + top_lm_r.y * h) / 2.0
            ], dtype=np.float32)
            bot_mid = np.array([
                (bot_lm_l.x * w + bot_lm_r.x * w) / 2.0,
                (bot_lm_l.y * h + bot_lm_r.y * h) / 2.0
            ], dtype=np.float32)

            # -------- 2.3 æŠŠ top_mid / bot_mid æŠ•å½±åˆ°â€œé¢ä¸­çº¿â€ä¸Š --------
            # æŠ•å½±å…¬å¼ï¼šP_proj = M + ((P - M)Â·n / (nÂ·n)) * n
            t_top = float(np.dot(top_mid - M, n)) / denom
            t_bot = float(np.dot(bot_mid - M, n)) / denom

            p_top = M + t_top * n
            p_bot = M + t_bot * n

            pt1 = (int(round(p_top[0])), int(round(p_top[1])))
            pt2 = (int(round(p_bot[0])), int(round(p_bot[1])))

            # -------- 2.4 ç”»é¢ä¸­çº¿ + ç«¯ç‚¹ --------
            # ç”¨é»„è‰²æ›´æ˜¾çœ¼
            cv2.line(vis, pt1, pt2, (0, 255, 255), 2)
            cv2.circle(vis, pt1, 4, (0, 255, 255), -1)
            cv2.circle(vis, pt2, 4, (0, 255, 255), -1)

        except Exception as e:
            # å‡ºé—®é¢˜æ—¶ä¸è¦å½±å“ä¸»æµç¨‹ï¼Œåªæ‰“ä¸€ä¸ªè°ƒè¯•ä¿¡æ¯
            print(f"[WARN] ç»˜åˆ¶é¢ä¸­çº¿å¤±è´¥: {e}")

        # 3) ä¿å­˜å›¾åƒ
        cv2.imwrite(str(output_path), vis)

    def calculate_pearson_coefficients(
        self,
        left_coords: np.ndarray,
        right_coords: np.ndarray,
        use_y_only: bool = True
    ) -> SymmetryFeatures:
        """
        è®¡ç®—å·¦å³å¯¹ç§°ç‚¹ y åæ ‡çš„ Pearson ç›¸å…³ç³»æ•°ï¼ˆæ¯ä¸ªç‚¹å¯¹ä¸€ä¸ª rï¼‰
        """
        if left_coords is None or right_coords is None:
            raise ValueError("æœªæ£€æµ‹åˆ°äººè„¸å…³é”®ç‚¹ï¼ˆleft/right coords ä¸º Noneï¼‰")

        n_frames, n_features, _ = left_coords.shape

        # yåæ ‡ï¼ˆç´¢å¼•1ï¼‰
        y_left = left_coords[:, :, 1]   # [T, F]
        y_right = right_coords[:, :, 1] # [T, F]

        pearson_coeffs = np.zeros((n_features,), dtype=np.float32)
        for i in range(n_features):
            a = y_left[:, i]
            b = y_right[:, i]
            # å¸¸æ•°åºåˆ—ä¼šè®© pearsonr æŠ¥é”™
            if np.std(a) < 1e-8 or np.std(b) < 1e-8:
                pearson_coeffs[i] = np.nan
            else:
                corr, _ = stats.pearsonr(a, b)
                pearson_coeffs[i] = float(corr)

        return SymmetryFeatures(
            pearson_coefficients=pearson_coeffs,
            landmark_names=list(self.feature_names),
            y_coords_left=y_left,
            y_coords_right=y_right,
            frame_count=n_frames
        )

    @staticmethod
    def _rolling_corr_cumsum(y_left: np.ndarray, y_right: np.ndarray, w: int) -> np.ndarray:
        """
        å‘é‡åŒ– rolling Pearsonï¼š
        y_left/y_right: [T, F]
        return: rolling_corr [T, F]ï¼Œå‰ w-1 è¡Œä¸º NaN
        """
        yL = y_left.astype(np.float64, copy=False)
        yR = y_right.astype(np.float64, copy=False)
        T, F = yL.shape
        w = int(max(3, w))
        if T < w:
            return np.full((T, F), np.nan, dtype=np.float32)

        def cumsum_pad(x):
            return np.vstack([np.zeros((1, F), dtype=np.float64), np.cumsum(x, axis=0)])

        cL = cumsum_pad(yL)
        cR = cumsum_pad(yR)
        cLL = cumsum_pad(yL * yL)
        cRR = cumsum_pad(yR * yR)
        cLR = cumsum_pad(yL * yR)

        sumL = cL[w:] - cL[:-w]
        sumR = cR[w:] - cR[:-w]
        sumLL = cLL[w:] - cLL[:-w]
        sumRR = cRR[w:] - cRR[:-w]
        sumLR = cLR[w:] - cLR[:-w]

        meanL = sumL / w
        meanR = sumR / w

        cov = (sumLR / w) - (meanL * meanR)
        varL = (sumLL / w) - (meanL * meanL)
        varR = (sumRR / w) - (meanR * meanR)

        denom = np.sqrt(np.maximum(varL, 0.0) * np.maximum(varR, 0.0))
        corr = np.divide(cov, denom, out=np.full_like(cov, np.nan), where=(denom > 1e-12))

        out = np.full((T, F), np.nan, dtype=np.float32)
        out[w - 1:] = corr.astype(np.float32)
        return out

    def compute_region_timeseries(
        self,
        features: SymmetryFeatures,
        rolling_window: int = 15
    ) -> Dict[str, Dict[str, np.ndarray]]:
        """
        1) abs_diff: æ¯å¸§çš„ |y_left - y_right|
        2) rolling_corr: æ»‘åŠ¨çª—å£ Pearsonï¼ˆå‘é‡åŒ–ç‰ˆæœ¬ï¼‰
        """
        y_left = features.y_coords_left  # [T, F]
        y_right = features.y_coords_right
        T, F = y_left.shape

        abs_diff = np.abs(y_left - y_right).astype(np.float32)  # [T, F]
        rolling_corr = self._rolling_corr_cumsum(y_left, y_right, rolling_window)  # [T, F]

        region_abs = {}
        region_corr = {}
        for region, idxs in self.region_feature_indices.items():
            idxs = list(idxs)
            region_abs[region] = abs_diff[:, idxs].mean(axis=1) if idxs else np.full((T,), np.nan, np.float32)
            region_corr[region] = np.nanmean(rolling_corr[:, idxs], axis=1) if idxs else np.full((T,), np.nan, np.float32)

        return {
            "abs_diff": region_abs,
            "rolling_corr": region_corr,
            "abs_diff_raw": abs_diff,
            "rolling_corr_raw": rolling_corr
        }

    def save_region_timeseries_plot(
        self,
        ts: Dict[str, Dict[str, np.ndarray]],
        fps: float,
        title: str,
        save_path_base: str
    ):
        """
        è¾“å‡ºä¸¤å¼ æ›²çº¿ï¼š
        - abs_diffï¼ˆè¶Šä½è¶Šå¯¹ç§°ï¼‰
        - rolling_corrï¼ˆè¶Šé«˜è¶Šå¯¹ç§°ï¼‰
        """
        region_abs = ts["abs_diff"]
        region_corr = ts["rolling_corr"]

        any_region = next(iter(region_abs.keys()))
        T = len(region_abs[any_region])

        if fps and fps > 0:
            t = np.arange(T) / float(fps)
            xlabel = "Time (s)"
        else:
            t = np.arange(T)
            xlabel = "Frame"

        os.makedirs(os.path.dirname(save_path_base), exist_ok=True)

        # abs_diff
        fig = plt.figure(figsize=(14, 6))
        ax = plt.gca()
        for region, y in region_abs.items():
            ax.plot(t, y, linewidth=1.6, label=region)
        ax.set_title(f"{title}\nRegion Asymmetry (abs(yL-yR), lower=better)")
        ax.set_xlabel(xlabel)
        ax.set_ylabel("abs(yL - yR)")
        ax.grid(True, alpha=0.25)
        ax.legend(ncol=2, fontsize=9)
        out1 = save_path_base.replace(".png", "_region_absdiff.png")
        fig.savefig(out1, dpi=160, bbox_inches="tight")
        plt.close(fig)

        # rolling corr
        fig = plt.figure(figsize=(14, 6))
        ax = plt.gca()
        for region, y in region_corr.items():
            ax.plot(t, y, linewidth=1.6, label=region)
        ax.set_title(f"{title}\nRegion Rolling Pearson (higher=better)")
        ax.set_xlabel(xlabel)
        ax.set_ylabel("Rolling Pearson r")
        ax.set_ylim(-1.05, 1.05)
        ax.grid(True, alpha=0.25)
        ax.legend(ncol=2, fontsize=9)
        out2 = save_path_base.replace(".png", "_region_rollingcorr.png")
        fig.savefig(out2, dpi=160, bbox_inches="tight")
        plt.close(fig)

        if self.verbose:
            print(f"  âœ“ Region time-series saved: {out1}")
            print(f"  âœ“ Region time-series saved: {out2}")

        return out1, out2

    @staticmethod
    def _fast_splat_heatmap(
        w: int,
        h: int,
        pts_xy: np.ndarray,    # [N,2] in pixel coords
        vals: np.ndarray,      # [N]
        canvas_res: int = 256,
        sigma: float = 8.0
    ) -> np.ndarray:
        """
        æ¯” griddata å¿«å¾ˆå¤šï¼šæŠŠç‚¹â€œæ’’â€åˆ°ä½åˆ†è¾¨ç‡ç”»å¸ƒ -> é«˜æ–¯æ¨¡ç³Š -> å½’ä¸€åŒ– -> colormap
        return: heat_bgr resized to (w,h)
        """
        canvas_res = int(max(64, canvas_res))
        sx = canvas_res / float(w)
        sy = canvas_res / float(h)

        acc = np.zeros((canvas_res, canvas_res), dtype=np.float32)
        cnt = np.zeros((canvas_res, canvas_res), dtype=np.float32)

        for (x, y), v in zip(pts_xy, vals):
            cx = int(np.clip(x * sx, 0, canvas_res - 1))
            cy = int(np.clip(y * sy, 0, canvas_res - 1))
            cv2.circle(acc, (cx, cy), 2, float(v), -1)
            cv2.circle(cnt, (cx, cy), 2, 1.0, -1)

        heat = acc / (cnt + 1e-6)
        heat = cv2.GaussianBlur(heat, (0, 0), sigmaX=sigma, sigmaY=sigma)

        vmin = float(np.min(heat))
        vmax = float(np.max(heat))
        heat = (heat - vmin) / (vmax - vmin + 1e-6)
        heat_u8 = np.clip(heat * 255.0, 0, 255).astype(np.uint8)

        heat_bgr_small = cv2.applyColorMap(heat_u8, cv2.COLORMAP_JET)
        heat_bgr = cv2.resize(heat_bgr_small, (w, h), interpolation=cv2.INTER_CUBIC)
        return heat_bgr

    def save_overlay_asymmetry_heatmap(
        self,
        frame_bgr: np.ndarray,
        face_landmarks,
        pair_values: np.ndarray,
        save_path: str,
        alpha: float = 0.45,
        canvas_res: int = 256
    ):
        """
        åœ¨åŸå›¾ä¸Šå åŠ çƒ­åŠ›å›¾ï¼š
        - pair_valuesï¼šæ¯å¯¹ç‚¹çš„åˆ†æ•°ï¼ˆæ¨èä¼ â€œæœ€ä¸å¯¹ç§°å¸§â€çš„ |Î”y|ï¼Œè¶Šå¤§è¶Šä¸å¯¹ç§°ï¼‰
        """
        if frame_bgr is None or face_landmarks is None:
            if self.verbose:
                print("  âš ï¸ overlay skipped: no debug frame/landmarks")
            return

        h, w = frame_bgr.shape[:2]

        pts = []
        vals = []
        for (li, ri), s in zip(self.feature_pairs, pair_values):
            for idx in (li, ri):
                lm = face_landmarks[idx]
                pts.append([lm.x * w, lm.y * h])
                vals.append(float(s))

        pts = np.asarray(pts, dtype=np.float32)
        vals = np.asarray(vals, dtype=np.float32)

        heat_bgr = self._fast_splat_heatmap(w=w, h=h, pts_xy=pts, vals=vals, canvas_res=canvas_res, sigma=8.0)
        overlay = cv2.addWeighted(frame_bgr, 1 - alpha, heat_bgr, alpha, 0)

        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        cv2.imwrite(save_path, overlay)
        if self.verbose:
            print(f"  âœ“ Overlay heatmap saved: {save_path}")

    def visualize_symmetry_heatmap(
        self,
        features: SymmetryFeatures,
        title: str,
        save_path: str,
    ):
        """ï¼ˆä¸ä½ åŸæ¥ä¸€è‡´ï¼‰PearsonæŸ±çŠ¶ + ç©ºé—´åˆ†å¸ƒ + ç»Ÿè®¡æ‘˜è¦"""
        fig = plt.figure(figsize=(16, 8))

        # 1) Pearson barh
        ax1 = plt.subplot(1, 3, 1)
        coeffs = features.pearson_coefficients
        colors = []
        for coef in coeffs:
            if np.isnan(coef):
                colors.append('gray')
            elif coef > 0.8:
                colors.append('darkblue')
            elif coef > 0.5:
                colors.append('lightblue')
            elif coef > 0:
                colors.append('yellow')
            else:
                colors.append('red')

        bars = ax1.barh(range(self.n_features), coeffs, color=colors)
        ax1.set_yticks(range(self.n_features))
        ax1.set_yticklabels(features.landmark_names, fontsize=9)
        ax1.set_xlabel('Pearson Correlation Coefficient', fontsize=11)
        ax1.set_title('å¯¹ç§°æ€§ç³»æ•°\n(è“è‰²=é«˜å¯¹ç§°, çº¢è‰²=ä¸å¯¹ç§°)', fontsize=10)
        ax1.axvline(x=0, color='black', linestyle='--', linewidth=0.8)
        ax1.axvline(x=0.8, color='green', linestyle='--', linewidth=0.8, alpha=0.5)
        ax1.set_xlim(-1, 1)
        ax1.grid(axis='x', alpha=0.3)

        for i, (bar, val) in enumerate(zip(bars, coeffs)):
            if np.isnan(val):
                label = "nan"
                xpos = 0.05
                ha = "left"
            else:
                label = f"{val:.3f}"
                xpos = (val + 0.05) if val > 0 else (val - 0.05)
                ha = "left" if val > 0 else "right"
            ax1.text(xpos, i, label, va='center', ha=ha, fontsize=8)

        # 2) ç®€åŒ–ç©ºé—´åˆ†å¸ƒï¼ˆæŒ‰å¹³å‡yæ’åºï¼‰
        ax2 = plt.subplot(1, 3, 2)
        avg_y = (features.y_coords_left.mean(axis=0) + features.y_coords_right.mean(axis=0)) / 2
        y_norm = (avg_y - avg_y.min()) / (avg_y.max() - avg_y.min() + 1e-6)

        x = np.linspace(-1, 1, self.n_features)
        y = y_norm

        scatter = ax2.scatter(x, y, c=np.nan_to_num(coeffs, nan=0.0),
                              s=500, cmap='RdYlBu', vmin=-1, vmax=1,
                              edgecolors='black', linewidth=1.5)
        for i, (xi, yi) in enumerate(zip(x, y)):
            ax2.annotate(f'{i + 1}', (xi, yi), ha='center', va='center',
                         fontsize=9, fontweight='bold')

        ax2.set_xlim(-1.2, 1.2)
        ax2.set_ylim(-0.1, 1.1)
        ax2.set_xlabel('å·¦ â† | â†’ å³', fontsize=11)
        ax2.set_ylabel('ä¸Š â† | â†’ ä¸‹', fontsize=11)
        ax2.set_title('é¢éƒ¨å¯¹ç§°æ€§ç©ºé—´åˆ†å¸ƒ', fontsize=11)
        ax2.set_aspect('equal')

        cbar = plt.colorbar(scatter, ax=ax2)
        cbar.set_label('Pearson Coefficient', fontsize=10)

        # 3) ç»Ÿè®¡æ‘˜è¦
        ax3 = plt.subplot(1, 3, 3)
        ax3.axis('off')

        valid = coeffs[np.isfinite(coeffs)]
        mean_corr = float(np.mean(valid)) if valid.size else float("nan")
        std_corr = float(np.std(valid)) if valid.size else float("nan")
        min_corr = float(np.min(valid)) if valid.size else float("nan")
        max_corr = float(np.max(valid)) if valid.size else float("nan")

        def mean_by_region(region: str) -> float:
            idxs = self.region_feature_indices.get(region, [])
            vals = coeffs[idxs] if idxs else np.array([], dtype=np.float32)
            vals = vals[np.isfinite(vals)]
            return float(np.mean(vals)) if vals.size else float("nan")

        eyebrow_corr = mean_by_region("eyebrow")
        eye_corr = mean_by_region("eye")
        upper_lip_corr = mean_by_region("upper_lip")
        lower_lip_corr = mean_by_region("lower_lip")
        nose_corr = mean_by_region("nose")

        high_sym = int(np.sum((coeffs > 0.8) & np.isfinite(coeffs)))
        medium_sym = int(np.sum((coeffs > 0.5) & (coeffs <= 0.8) & np.isfinite(coeffs)))
        low_sym = int(np.sum((coeffs <= 0.5) & np.isfinite(coeffs)))

        summary_text = f"""
Statistical Summary
{'=' * 30}

Overall Symmetry:
  Mean Correlation: {mean_corr:.3f} Â± {std_corr:.3f}
  Range: [{min_corr:.3f}, {max_corr:.3f}]

Regional Analysis:
  Eyebrow Region: {eyebrow_corr:.3f}
  Eye Region: {eye_corr:.3f}
  Upper Lip Region: {upper_lip_corr:.3f}
  Lower Lip Region: {lower_lip_corr:.3f}
  Nose Region: {nose_corr:.3f}

Symmetry Rating:
  High Symmetry (>0.8): {high_sym}/{self.n_features}
  Medium Symmetry (0.5-0.8): {medium_sym}/{self.n_features}
  Low Symmetry (â‰¤0.5): {low_sym}/{self.n_features}

Data Quality:
  Valid Frames: {features.frame_count}

Health Assessment:
  {'Normal Symmetry' if mean_corr > 0.8 else 'Asymmetry Detected' if mean_corr > 0.5 else 'Severe Asymmetry'}
"""
        ax3.text(0.1, 0.95, summary_text, transform=ax3.transAxes,
                 fontsize=10, va='top', fontfamily='monospace',
                 bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))

        plt.suptitle(title, fontsize=14, fontweight='bold', y=0.98)
        plt.tight_layout()
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close(fig)

        if self.verbose:
            print(f"  âœ“ Heatmap saved: {save_path}")

    def calculate_mahalanobis_distance(
        self,
        features: SymmetryFeatures,
        healthy_reference: Optional[Dict] = None
    ) -> float:
        """
        è®¡ç®—Mahalanobisè·ç¦»ï¼Œé‡åŒ–åç¦»å¥åº·äººç¾¤çš„ç¨‹åº¦
        æ³¨æ„ï¼šå¦‚æœæ²¡æœ‰çœŸå®å¥åº·å¯¹ç…§ï¼Œè¿™é‡Œåªæ˜¯å ä½é€»è¾‘ã€‚
        """
        if healthy_reference is None:
            healthy_mean = np.full(self.n_features, 0.95, dtype=np.float32)
            healthy_std = np.full(self.n_features, 0.05, dtype=np.float32)
            healthy_cov = np.diag(healthy_std ** 2).astype(np.float32)
        else:
            healthy_mean = np.asarray(healthy_reference['mean'], dtype=np.float32)
            healthy_cov = np.asarray(healthy_reference['cov'], dtype=np.float32)

        x = np.nan_to_num(features.pearson_coefficients, nan=np.nanmean(features.pearson_coefficients))
        try:
            md = mahalanobis(x, healthy_mean, np.linalg.inv(healthy_cov))
        except np.linalg.LinAlgError:
            if self.verbose:
                print("  âš ï¸ åæ–¹å·®çŸ©é˜µå¥‡å¼‚ï¼Œä½¿ç”¨æ¬§æ°è·ç¦»ä»£æ›¿")
            md = float(np.linalg.norm(x - healthy_mean))

        return float(md)

    def analyze_single_video(
        self,
        video_path: str,
        action_name: str,
        output_dir: str,
        start_frame: Optional[int] = None,
        end_frame: Optional[int] = None,
        fps: Optional[float] = None,
        patient_id: Optional[str] = None,
        examination_id: Optional[str] = None,
        video_id: Optional[int] = None,
    ) -> Dict:
        """
        åˆ†æå•ä¸ªè§†é¢‘çš„é¢éƒ¨å¯¹ç§°æ€§
        """
        if self.verbose:
            print(f"\n{'=' * 60}")
            print(f"åˆ†æè§†é¢‘: {Path(video_path).name}")
            print(f"åŠ¨ä½œ: {action_name}")
            print(f"{'=' * 60}")

        # 1. æå–ç‰¹å¾ç‚¹ï¼ˆåŒæ—¶ä¼šé€‰å‡ºâ€œæœ€ä¸å¯¹ç§°å¸§â€ï¼‰
        left_coords, right_coords = self.extract_landmarks_from_video(
            video_path, start_frame, end_frame, fps
        )
        if left_coords is None:
            raise ValueError("æœªæ£€æµ‹åˆ°äººè„¸å…³é”®ç‚¹ï¼ˆæ•´æ®µè§†é¢‘æ— æœ‰æ•ˆæ£€æµ‹ï¼‰")

        # 2. Pearson
        if self.verbose:
            print(f"\n  è®¡ç®—Pearsonç›¸å…³ç³»æ•°...")
        features = self.calculate_pearson_coefficients(left_coords, right_coords)
        if self.verbose:
            print(f"  âœ“ å®Œæˆ")

        # 3. Mahalanobis
        if self.verbose:
            print(f"\n  è®¡ç®—Mahalanobisè·ç¦»...")
        md = self.calculate_mahalanobis_distance(features)
        if self.verbose:
            print(f"  âœ“ é©¬æ°è·ç¦»: {md:.3f}")

        # 4. å¯è§†åŒ–
        if self.verbose:
            print(f"\n  ç”Ÿæˆå¯è§†åŒ–...")

        title = f"é¢éƒ¨å¯¹ç§°æ€§åˆ†æ: {action_name}"
        if patient_id:
            title += f" | æ‚£è€…: {patient_id}"
        if examination_id:
            title += f" | æ£€æŸ¥: {examination_id}"

        os.makedirs(output_dir, exist_ok=True)

        video_stem = Path(video_path).stem
        prefix = "_".join([p for p in [_safe_name(examination_id), _safe_name(action_name)] if p])

        save_path = os.path.join(output_dir, f"{prefix}_symmetry.png")
        self.visualize_symmetry_heatmap(features, title, save_path)

        # Regionæ—¶åº
        ts = self.compute_region_timeseries(features, rolling_window=15)
        abs_path, corr_path = self.save_region_timeseries_plot(
            ts=ts,
            fps=float(fps) if fps else 0.0,
            title=title,
            save_path_base=save_path
        )

        # Overlayï¼šé»˜è®¤ç”¨â€œæœ€ä¸å¯¹ç§°å¸§â€çš„æ¯å¯¹ç‚¹ |Î”y|
        overlay_path = save_path.replace(".png", "_heatmap.png")
        if self._debug_pair_absdy is None:
            # fallbackï¼šç”¨ 1 - pearson
            pair_values = 1.0 - np.clip(np.nan_to_num(features.pearson_coefficients, nan=0.0), -1.0, 1.0)
        else:
            pair_values = self._debug_pair_absdy

        self.save_overlay_asymmetry_heatmap(
            frame_bgr=self._debug_frame,
            face_landmarks=self._debug_landmarks,
            pair_values=pair_values,
            save_path=overlay_path,
            alpha=0.45,
            canvas_res=256
        )

        # ç´¢å¼•æ£€æŸ¥å›¾ï¼ˆä¹Ÿç”¨æœ€ä¸å¯¹ç§°å¸§ï¼‰
        index_img_path = os.path.join(output_dir, f"{prefix}_index_check.png")
        self.save_index_check_image(self._debug_frame, self._debug_landmarks, index_img_path)

        # 5. ä¿å­˜æ•°æ®
        result = {
            "video_path": video_path,
            "video_id": video_id,
            "action_name": action_name,
            "patient_id": patient_id,
            "examination_id": examination_id,
            "frame_count": int(features.frame_count),
            "pearson_coefficients": np.nan_to_num(features.pearson_coefficients, nan=float("nan")).tolist(),
            "mahalanobis_distance": float(md),
            "mean_correlation": float(np.nanmean(features.pearson_coefficients)),
            "std_correlation": float(np.nanstd(features.pearson_coefficients)),
            "visualization_path": save_path,
            "overlay_path": overlay_path,
            "index_check_path": index_img_path,
            "region_absdiff_path": abs_path,
            "region_rollingcorr_path": corr_path,
            "worst_frame_abs_index": self._debug_frame_abs_index,
            "worst_frame_asym_score_sum_absdy": self._debug_asym_score,
        }

        json_path = save_path.replace(".png", ".json")
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        if self.verbose:
            print(f"  âœ“ ç»“æœå·²ä¿å­˜: {json_path}")
            print(f"\n{'=' * 60}")
            print(f"âœ… åˆ†æå®Œæˆ!")
            print(f"   å¹³å‡å¯¹ç§°æ€§: {result['mean_correlation']:.3f}")
            print(f"   é©¬æ°è·ç¦»: {result['mahalanobis_distance']:.3f}")
            print(f"   æœ€ä¸å¯¹ç§°å¸§(abs idx): {result['worst_frame_abs_index']} | score(sum|Î”y|): {result['worst_frame_asym_score_sum_absdy']}")
            print(f"{'=' * 60}\n")

        return result

    def batch_process_database(
        self,
        output_dir: str,
        limit: Optional[int] = None,
        action_filter: Optional[List[str]] = None,
        use_multiprocessing: bool = True,
        num_workers: Optional[int] = None,
    ):
        """
        æ‰¹é‡å¤„ç†æ•°æ®åº“ä¸­çš„æ‰€æœ‰è§†é¢‘ï¼ˆå¯å¤šè¿›ç¨‹ï¼‰
        """
        os.makedirs(output_dir, exist_ok=True)

        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        query = """
            SELECT 
                vf.video_id,
                vf.examination_id,
                vf.action_id,
                vf.file_path,
                vf.start_frame,
                vf.end_frame,
                vf.fps,
                at.action_name_en,
                e.patient_id
            FROM video_files vf
            JOIN action_types at ON vf.action_id = at.action_id
            JOIN examinations e ON vf.examination_id = e.examination_id
            WHERE vf.file_exists = 1
        """

        if action_filter:
            placeholders = ",".join(["?"] * len(action_filter))
            query += f" AND at.action_name_en IN ({placeholders})"
            cursor.execute(query, action_filter)
        else:
            cursor.execute(query)

        videos = cursor.fetchall()
        conn.close()

        if limit:
            videos = videos[: int(limit)]

        print(f"\n{'=' * 60}")
        print("æ‰¹é‡å¤„ç†æ¨¡å¼")
        print(f"æ€»è§†é¢‘æ•°: {len(videos)}")
        print(f"è¾“å‡ºç›®å½•: {output_dir}")
        print(f"å¤šè¿›ç¨‹: {use_multiprocessing}")
        print(f"{'=' * 60}\n")

        # è¿‡æ»¤ä¸å­˜åœ¨çš„è§†é¢‘ï¼ˆå‡å°‘æ— æ•ˆä»»åŠ¡ï¼‰
        tasks = []
        for (video_id, exam_id, action_id, file_path, start_frame, end_frame, fps, action_name, patient_id) in videos:
            if not file_path or (not os.path.exists(file_path)):
                continue
            tasks.append({
                "db_path": self.db_path,
                "model_path": self.model_path,
                "video_id": int(video_id),
                "video_path": file_path,
                "action_name": action_name,
                "output_dir": output_dir,
                "start_frame": start_frame,
                "end_frame": end_frame,
                "fps": fps,
                "patient_id": patient_id,
                "examination_id": exam_id,
            })

        if not tasks:
            print("âš ï¸ æ²¡æœ‰å¯å¤„ç†çš„è§†é¢‘ä»»åŠ¡ï¼ˆè·¯å¾„ä¸å­˜åœ¨æˆ–è¢«è¿‡æ»¤ï¼‰")
            return []

        if num_workers is None:
            cpu = os.cpu_count() or 8
            num_workers = min(8, cpu)  # é»˜è®¤ä¸è¦æ‹‰æ»¡ï¼Œé¿å…IO/å†…éƒ¨çº¿ç¨‹åå™¬

        results = []
        errors = []

        # ========== å¤šè¿›ç¨‹å¹¶è¡Œ ==========
        if use_multiprocessing and num_workers > 1:
            # å°½é‡ç¡®ä¿ spawnï¼ˆmacOS é»˜è®¤å°±æ˜¯ spawnï¼‰
            try:
                if mp.get_start_method(allow_none=True) is None:
                    mp.set_start_method("spawn", force=True)
            except RuntimeError:
                pass

            print(f"ğŸš€ ä½¿ç”¨å¤šè¿›ç¨‹: num_workers={num_workers}, tasks={len(tasks)}")

            with ProcessPoolExecutor(max_workers=num_workers) as executor:
                futs = [executor.submit(_worker_analyze_one, task) for task in tasks]
                total = len(futs)
                done = 0

                for fut in as_completed(futs):
                    done += 1
                    try:
                        ok, payload = fut.result()
                        if ok:
                            results.append(payload)
                        else:
                            errors.append(payload)
                    except Exception as e:
                        errors.append({"error": str(e)})

                    if done % 10 == 0 or done == total:
                        print(f"è¿›åº¦: {done}/{total} | æˆåŠŸ: {len(results)} | å¤±è´¥: {len(errors)}")

        else:
            print(f"ğŸ§µ å•è¿›ç¨‹é¡ºåºå¤„ç†: tasks={len(tasks)}")
            old_verbose = self.verbose
            self.verbose = True  # å•è¿›ç¨‹å¯ä»¥ä¿æŒè¾“å‡º
            for i, task in enumerate(tasks, 1):
                print(f"[{i}/{len(tasks)}] {task['patient_id']} - {task['action_name']}")
                try:
                    r = self.analyze_single_video(
                        video_path=task["video_path"],
                        action_name=task["action_name"],
                        output_dir=task["output_dir"],
                        start_frame=task["start_frame"],
                        end_frame=task["end_frame"],
                        fps=task["fps"],
                        patient_id=task["patient_id"],
                        examination_id=task["examination_id"],
                        video_id=task["video_id"],
                    )
                    results.append(r)
                except Exception as e:
                    errors.append({"video_id": task["video_id"], "video_path": task["video_path"], "error": str(e)})
                    print(f"  âŒ é”™è¯¯: {e}")
            self.verbose = old_verbose

        # ä¿å­˜æ±‡æ€»
        summary = {
            "success": results,
            "errors": errors,
            "total_tasks": len(tasks),
            "success_count": len(results),
            "error_count": len(errors),
        }
        summary_path = os.path.join(output_dir, "batch_summary.json")
        with open(summary_path, "w", encoding="utf-8") as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)

        print(f"\n{'=' * 60}")
        print("âœ… æ‰¹é‡å¤„ç†å®Œæˆ!")
        print(f"   æˆåŠŸå¤„ç†: {len(results)}/{len(tasks)}")
        print(f"   å¤±è´¥: {len(errors)}")
        print(f"   æ±‡æ€»ç»“æœ: {summary_path}")
        print(f"{'=' * 60}\n")

        return results

    def compare_actions(
        self,
        video_paths: Dict[str, str],
        patient_id: str,
        output_path: str
    ):
        """æ¯”è¾ƒåŒä¸€æ‚£è€…ä¸åŒåŠ¨ä½œçš„å¯¹ç§°æ€§ï¼ˆä¿ç•™åŸæœ‰åŠŸèƒ½ï¼‰"""
        print(f"\n{'=' * 60}")
        print(f"åŠ¨ä½œå¯¹æ¯”åˆ†æ: {patient_id}")
        print(f"{'=' * 60}")

        features_dict = {}
        for action_name, video_path in video_paths.items():
            print(f"\nå¤„ç†åŠ¨ä½œ: {action_name}")
            left_coords, right_coords = self.extract_landmarks_from_video(video_path)
            features = self.calculate_pearson_coefficients(left_coords, right_coords)
            features_dict[action_name] = features

        n_actions = len(features_dict)
        fig, axes = plt.subplots(1, n_actions, figsize=(6 * n_actions, 6))
        if n_actions == 1:
            axes = [axes]

        for idx, (action_name, features) in enumerate(features_dict.items()):
            ax = axes[idx]
            coeffs = features.pearson_coefficients
            colors = []
            for coef in coeffs:
                if np.isnan(coef):
                    colors.append('gray')
                elif coef > 0.8:
                    colors.append('darkblue')
                elif coef > 0.5:
                    colors.append('lightblue')
                elif coef > 0:
                    colors.append('yellow')
                else:
                    colors.append('red')

            ax.barh(range(self.n_features), coeffs, color=colors)
            ax.set_yticks(range(self.n_features))
            ax.set_yticklabels(features.landmark_names, fontsize=8)
            ax.set_xlabel('Pearson Coefficient', fontsize=10)
            ax.set_title(f'{action_name}\nå¹³å‡: {np.nanmean(coeffs):.3f}',
                         fontsize=11, fontweight='bold')
            ax.axvline(x=0, color='black', linestyle='--', linewidth=0.8)
            ax.axvline(x=0.8, color='green', linestyle='--', linewidth=0.8, alpha=0.5)
            ax.set_xlim(-1, 1)
            ax.grid(axis='x', alpha=0.3)

        plt.suptitle(f'æ‚£è€… {patient_id} - ä¸åŒåŠ¨ä½œå¯¹ç§°æ€§å¯¹æ¯”',
                     fontsize=14, fontweight='bold', y=0.98)
        plt.tight_layout()

        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close(fig)

        print(f"\nâœ“ å¯¹æ¯”å›¾å·²ä¿å­˜: {output_path}")


# ==================== multiprocessing worker ====================

def _worker_analyze_one(task: Dict):
    """
    å­è¿›ç¨‹ workerï¼šä¸è¦ä¾èµ–ä¸»è¿›ç¨‹çš„ analyzerï¼ˆä¸å¯pickleï¼‰
    """
    try:
        analyzer = FacialSymmetryAnalyzer(
            db_path=task["db_path"],
            model_path=task["model_path"],
            verbose=False  # å­è¿›ç¨‹åˆ«åˆ·å±
        )
        res = analyzer.analyze_single_video(
            video_path=task["video_path"],
            action_name=task["action_name"],
            output_dir=task["output_dir"],
            start_frame=task["start_frame"],
            end_frame=task["end_frame"],
            fps=task["fps"],
            patient_id=task["patient_id"],
            examination_id=task["examination_id"],
            video_id=task.get("video_id"),
        )
        return True, res
    except Exception as e:
        return False, {
            "video_id": task.get("video_id"),
            "video_path": task.get("video_path"),
            "patient_id": task.get("patient_id"),
            "examination_id": task.get("examination_id"),
            "action_name": task.get("action_name"),
            "error": str(e),
        }


def main():
    analyzer = FacialSymmetryAnalyzer(
        db_path='/Users/cuijinglei/PycharmProjects/medicalProject/facialPalsy/facialPalsy.db'
    )

    analyzer.batch_process_database(
        output_dir='/Users/cuijinglei/Documents/facialPalsy/HGFA/symmetry_analysis',
        limit=None,
        action_filter=None,
        use_multiprocessing=True,
        num_workers=8,
    )


if __name__ == '__main__':
    main()
