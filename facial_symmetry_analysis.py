# -*- coding: utf-8 -*-
"""
facial_symmetry_analysis_optimized.py

é¢éƒ¨å¯¹ç§°æ€§åˆ†æ - ä¼˜åŒ–ç‰ˆæœ¬
ä¸»è¦æ”¹è¿›ï¼š
1. âœ… ä¿®å¤é¢ä¸­çº¿ç»˜åˆ¶ï¼šä½¿ç”¨face_contouråŒºåŸŸçš„ç¬¬ä¸€å¯¹/æœ€åä¸€å¯¹ç‚¹ï¼ˆéæ•´ä¸ªé…ç½®çš„ï¼‰
2. âœ… ä»£ç ç»“æ„ä¼˜åŒ–ï¼šåˆ†ç¦»èŒè´£ã€æå–å¸¸é‡ã€æ”¹è¿›å¯è¯»æ€§
3. âœ… æ€§èƒ½ä¼˜åŒ–ï¼šå‘é‡åŒ–è®¡ç®—ã€å‡å°‘é‡å¤æ“ä½œ
4. âœ… é”™è¯¯å¤„ç†å¢å¼ºï¼šæ›´å¥å£®çš„å¼‚å¸¸å¤„ç†
5. âœ… ç±»å‹æç¤ºå®Œå–„ï¼šæ›´å¥½çš„ä»£ç å¯ç»´æŠ¤æ€§
"""

import os
import re
import json
import sqlite3
from pathlib import Path
from dataclasses import dataclass
from typing import Dict, List, Tuple, Optional, Union
from enum import Enum

import cv2
import numpy as np
import mediapipe as mp_mediapipe
from mediapipe.tasks import python
from mediapipe.tasks.python import vision

from scipy import stats
from scipy.spatial.distance import mahalanobis
from concurrent.futures import ProcessPoolExecutor, as_completed

import matplotlib

matplotlib.use("Agg")
import matplotlib.pyplot as plt

# ä¸­æ–‡å­—ä½“/è´Ÿå·
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial Unicode MS', 'PingFang SC']
matplotlib.rcParams['axes.unicode_minus'] = False

# ==================== å¸¸é‡å®šä¹‰ ====================

# MediaPipe 478ç‚¹ä¸­çš„å¯¹ç§°ç‰¹å¾ç‚¹å®šä¹‰
SYMMETRY_INDEX_CONFIG = [
    {
        "region": "eyebrow",
        "pairs": {
            "left": [336, 296, 334, 293, 300, 276, 283, 282, 295, 285],
            "right": [107, 66, 105, 63, 70, 46, 53, 52, 65, 55],
        }
    },
    {
        "region": "eye",
        "pairs": {
            "left": [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398],
            "right": [133, 155, 154, 153, 145, 144, 163, 7, 33, 246, 161, 160, 159, 158, 157, 173],
        }
    },
    {
        "region": "pupil",
        "pairs": {"left": [473], "right": [468]}
    },
    {
        "region": "iris",
        "pairs": {"left": [474, 475, 476, 477], "right": [471, 470, 469, 472]}
    },
    {
        "region": "upper_lip",
        "pairs": {
            "left": [267, 269, 270, 409, 291, 308, 415, 310, 311, 312],
            "right": [37, 39, 40, 185, 61, 78, 191, 80, 81, 82],
        }
    },
    {
        "region": "lower_lip",
        "pairs": {
            "left": [317, 402, 318, 324, 308, 291, 375, 321, 405, 314],
            "right": [87, 178, 88, 95, 78, 61, 146, 91, 181, 84],
        }
    },
    {
        "region": "nose",
        "pairs": {
            "left": [250, 458, 459, 309, 392, 289, 305, 460, 294, 358, 279, 429, 420, 456],
            "right": [20, 238, 239, 79, 166, 59, 75, 240, 64, 129, 49, 209, 198, 236],
        }
    },
    {
        "region": "face_contour",
        "pairs": {
            "left": [338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377],
            "right": [109, 67, 103, 54, 21, 162, 127, 234, 93, 132, 58, 172, 136, 150, 149, 176, 148],
        },
    },
]

# çœ¼å†…çœ¦å…³é”®ç‚¹ç´¢å¼•
EYE_INNER_CANTHUS_LEFT = 362
EYE_INNER_CANTHUS_RIGHT = 133
NOSE_TIP = 4

# å¯è§†åŒ–é…ç½®
class VisConfig:
    """å¯è§†åŒ–ç›¸å…³é…ç½®"""
    # é¢œè‰²å®šä¹‰ (BGRæ ¼å¼)
    COLOR_LEFT_POINT = (0, 0, 255)  # çº¢è‰²
    COLOR_RIGHT_POINT = (255, 0, 0)  # è“è‰²
    COLOR_MIDLINE = (0, 255, 255)  # é»„è‰²
    COLOR_CONNECTION = (0, 255, 0)  # ç»¿è‰²

    # ç»˜åˆ¶å‚æ•°
    POINT_RADIUS = 2
    MIDLINE_THICKNESS = 2
    CONNECTION_THICKNESS = 1
    TEXT_FONT = cv2.FONT_HERSHEY_SIMPLEX
    TEXT_SIZE = 0.35
    TEXT_THICKNESS = 1

    # çƒ­åŠ›å›¾å‚æ•°
    HEATMAP_ALPHA = 0.45
    HEATMAP_CANVAS_RES = 256
    HEATMAP_SIGMA = 8.0


# Pearsonç³»æ•°é˜ˆå€¼
class PearsonThreshold:
    """Pearsonç›¸å…³ç³»æ•°é˜ˆå€¼"""
    HIGH = 0.8
    MEDIUM = 0.5
    LOW = 0.0


# ==================== æ•°æ®ç»“æ„ ====================

@dataclass
class SymmetryFeatures:
    """å¯¹ç§°æ€§ç‰¹å¾æ•°æ®ç»“æ„"""
    pearson_coefficients: np.ndarray  # [F] Pearsonç›¸å…³ç³»æ•°
    landmark_names: List[str]  # [F] ç‰¹å¾ç‚¹åç§°
    y_coords_left: np.ndarray  # [T, F] å·¦ä¾§yåæ ‡
    y_coords_right: np.ndarray  # [T, F] å³ä¾§yåæ ‡
    frame_count: int  # T æ€»å¸§æ•°


@dataclass
class MidlinePoints:
    """é¢ä¸­çº¿å…³é”®ç‚¹"""
    top: Tuple[int, int]  # é¡¶ç‚¹åæ ‡
    bottom: Tuple[int, int]  # åº•ç‚¹åæ ‡
    center: Tuple[float, float]  # ä¸­å¿ƒç‚¹åæ ‡


# ==================== è¾…åŠ©å‡½æ•° ====================

def _safe_name(s: Union[str, None]) -> str:
    """å®‰å…¨çš„æ–‡ä»¶åè½¬æ¢"""
    s = str(s) if s is not None else ""
    return re.sub(r"[^0-9A-Za-z._-]+", "_", s)[:160]


def build_pairs_and_names(cfg_list: List[Dict]) -> Tuple[List[Tuple[int, int]], List[str], Dict[str, List[int]]]:
    """
    ä»é…ç½®æ„å»ºç‚¹å¯¹ã€åç§°å’ŒåŒºåŸŸç´¢å¼•æ˜ å°„

    Args:
        cfg_list: SYMMETRY_INDEX_CONFIGé…ç½®åˆ—è¡¨

    Returns:
        pairs: [(left_idx, right_idx), ...] ç‚¹å¯¹åˆ—è¡¨
        names: ["eyebrow_01", "eyebrow_02", ...] ç‰¹å¾åç§°åˆ—è¡¨
        region_feature_indices: {"eyebrow":[0,1,...], ...} åŒºåŸŸåˆ°ç‰¹å¾ç´¢å¼•çš„æ˜ å°„
    """
    pairs = []
    names = []
    region_feature_indices = {}

    for item in cfg_list:
        region = item["region"]
        lr = item["pairs"]
        L = lr["left"]
        R = lr["right"]

        if len(L) != len(R):
            raise ValueError(f"[{region}] å·¦å³ç‚¹æ•°ä¸ä¸€è‡´: {len(L)} vs {len(R)}")

        region_feature_indices.setdefault(region, [])

        for i, (li, ri) in enumerate(zip(L, R), start=1):
            pairs.append((int(li), int(ri)))
            names.append(f"{region}_{i:02d}")
            region_feature_indices[region].append(len(pairs) - 1)

    return pairs, names, region_feature_indices


def compute_midline_geometry(
        face_landmarks,
        face_contour_indices: List[int],
        feature_pairs: List[Tuple[int, int]],
        image_width: int,
        image_height: int
) -> Optional[MidlinePoints]:
    """
    è®¡ç®—é¢ä¸­çº¿çš„å‡ ä½•ä½ç½®

    Args:
        face_landmarks: MediaPipeæ£€æµ‹åˆ°çš„é¢éƒ¨å…³é”®ç‚¹
        face_contour_indices: face_contouråŒºåŸŸçš„ç‰¹å¾ç´¢å¼•åˆ—è¡¨
        feature_pairs: æ‰€æœ‰ç‚¹å¯¹åˆ—è¡¨
        image_width: å›¾åƒå®½åº¦
        image_height: å›¾åƒé«˜åº¦

    Returns:
        MidlinePointså¯¹è±¡ï¼ŒåŒ…å«é¢ä¸­çº¿çš„é¡¶ç‚¹ã€åº•ç‚¹å’Œä¸­å¿ƒç‚¹ï¼›å¤±è´¥è¿”å›None
    """
    try:
        # 1. è·å–çœ¼å†…çœ¦ç‚¹ï¼Œè®¡ç®—ä¸­å¿ƒå’Œæ³•å‘é‡
        lm_left = face_landmarks[EYE_INNER_CANTHUS_LEFT]
        lm_right = face_landmarks[EYE_INNER_CANTHUS_RIGHT]

        lx, ly = lm_left.x * image_width, lm_left.y * image_height
        rx, ry = lm_right.x * image_width, lm_right.y * image_height

        # ä¸­ç‚¹
        center_x, center_y = (lx + rx) / 2.0, (ly + ry) / 2.0

        # çœ¼å†…çœ¦è¿çº¿æ–¹å‘å’Œæ³•å‘é‡ï¼ˆä¸­å‚çº¿æ–¹å‘ï¼‰
        dx, dy = (rx - lx), (ry - ly)
        if abs(dx) + abs(dy) < 1e-6:
            raise ValueError("çœ¼å†…çœ¦ä¸¤ç‚¹è¿‡äºæ¥è¿‘ï¼Œæ— æ³•è®¡ç®—é¢ä¸­çº¿")

        center = np.array([center_x, center_y], dtype=np.float32)
        normal = np.array([-dy, dx], dtype=np.float32)  # ä¸­å‚çº¿æ–¹å‘
        denom = float(np.dot(normal, normal)) + 1e-6

        # 2. è·å–face_contourçš„ç¬¬ä¸€å¯¹å’Œæœ€åä¸€å¯¹ç‚¹ï¼ˆè„¸çš„æœ€é«˜ç‚¹å’Œæœ€ä½ç‚¹ï¼‰
        if not face_contour_indices:
            raise ValueError("face_contouråŒºåŸŸç´¢å¼•ä¸ºç©º")

        # ç¬¬ä¸€å¯¹ç‚¹ï¼ˆæœ€é«˜ç‚¹ï¼‰
        top_feature_idx = face_contour_indices[0]
        top_left_idx, top_right_idx = feature_pairs[top_feature_idx]

        # æœ€åä¸€å¯¹ç‚¹ï¼ˆæœ€ä½ç‚¹ï¼‰
        bottom_feature_idx = face_contour_indices[-1]
        bottom_left_idx, bottom_right_idx = feature_pairs[bottom_feature_idx]

        # è·å–å…³é”®ç‚¹åæ ‡
        top_lm_l = face_landmarks[top_left_idx]
        top_lm_r = face_landmarks[top_right_idx]
        bot_lm_l = face_landmarks[bottom_left_idx]
        bot_lm_r = face_landmarks[bottom_right_idx]

        # è®¡ç®—é¡¶éƒ¨å’Œåº•éƒ¨ä¸­ç‚¹
        top_mid = np.array([
            (top_lm_l.x * image_width + top_lm_r.x * image_width) / 2.0,
            (top_lm_l.y * image_height + top_lm_r.y * image_height) / 2.0
        ], dtype=np.float32)

        bot_mid = np.array([
            (bot_lm_l.x * image_width + bot_lm_r.x * image_width) / 2.0,
            (bot_lm_l.y * image_height + bot_lm_r.y * image_height) / 2.0
        ], dtype=np.float32)

        # 3. æŠ•å½±åˆ°é¢ä¸­çº¿ä¸Š
        # æŠ•å½±å…¬å¼ï¼šP_proj = M + ((P - M)Â·n / (nÂ·n)) * n
        t_top = float(np.dot(top_mid - center, normal)) / denom
        t_bot = float(np.dot(bot_mid - center, normal)) / denom

        p_top = center + t_top * normal
        p_bot = center + t_bot * normal

        return MidlinePoints(
            top=(int(round(p_top[0])), int(round(p_top[1]))),
            bottom=(int(round(p_bot[0])), int(round(p_bot[1]))),
            center=(float(center_x), float(center_y))
        )

    except Exception as e:
        print(f"[WARN] è®¡ç®—é¢ä¸­çº¿å‡ ä½•å¤±è´¥: {e}")
        return None


# ==================== ä¸»ç±» ====================

class FacialSymmetryAnalyzer:
    """é¢éƒ¨å¯¹ç§°æ€§åˆ†æå™¨ - ä¼˜åŒ–ç‰ˆæœ¬"""

    def __init__(
            self,
            db_path: str,
            model_path: str = '/Users/cuijinglei/PycharmProjects/medicalProject/models/face_landmarker.task',
            verbose: bool = True,
    ):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        Args:
            db_path: æ•°æ®åº“è·¯å¾„
            model_path: MediaPipeæ¨¡å‹è·¯å¾„
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        """
        self.db_path = db_path
        self.model_path = model_path
        self.verbose = bool(verbose)

        # ç”Ÿæˆç‚¹å¯¹ã€åç§°å’ŒåŒºåŸŸç´¢å¼•æ˜ å°„
        self.feature_pairs, self.feature_names, self.region_feature_indices = (
            build_pairs_and_names(SYMMETRY_INDEX_CONFIG)
        )
        self.n_features = len(self.feature_pairs)

        # è°ƒè¯•ä¿¡æ¯ï¼šæœ€ä¸å¯¹ç§°å¸§
        self._debug_frame: Optional[np.ndarray] = None
        self._debug_landmarks = None
        self._debug_frame_abs_index: Optional[int] = None
        self._debug_asym_score: Optional[float] = None
        self._debug_pair_absdy: Optional[np.ndarray] = None

        if self.verbose:
            print("âœ… é¢éƒ¨å¯¹ç§°æ€§åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
            print(f"   - å¯¹ç§°ç‚¹å¯¹æ•°: {self.n_features}")
            print(f"   - åŒºåŸŸæ•°: {len(self.region_feature_indices)}")
            print(f"   - æ•°æ®åº“: {db_path}")
            print(f"   - Landmarkeræ¨¡å‹: {model_path}")

    def _create_landmarker(self) -> vision.FaceLandmarker:
        """åˆ›å»ºMediaPipe FaceLandmarkerå®ä¾‹"""
        base_options = python.BaseOptions(model_asset_path=self.model_path)
        options = vision.FaceLandmarkerOptions(
            base_options=base_options,
            running_mode=vision.RunningMode.VIDEO,
            num_faces=1,
            output_face_blendshapes=False,
            output_facial_transformation_matrixes=False,
        )
        return vision.FaceLandmarker.create_from_options(options)

    def _reset_debug_info(self):
        """é‡ç½®è°ƒè¯•ä¿¡æ¯"""
        self._debug_frame = None
        self._debug_landmarks = None
        self._debug_frame_abs_index = None
        self._debug_asym_score = None
        self._debug_pair_absdy = None

    def _update_most_asymmetric_frame(
            self,
            frame: np.ndarray,
            face_landmarks,
            frame_abs_idx: int,
            pair_absdy: np.ndarray
    ):
        """
        æ›´æ–°æœ€ä¸å¯¹ç§°å¸§ä¿¡æ¯

        Args:
            frame: å½“å‰å¸§å›¾åƒ
            face_landmarks: å½“å‰å¸§çš„é¢éƒ¨å…³é”®ç‚¹
            frame_abs_idx: å¸§çš„ç»å¯¹ç´¢å¼•
            pair_absdy: æ¯å¯¹ç‚¹çš„|Î”y|å€¼
        """
        asym_score = float(pair_absdy.sum())
        if (self._debug_asym_score is None) or (asym_score > self._debug_asym_score):
            self._debug_asym_score = asym_score
            self._debug_frame = frame.copy()
            self._debug_landmarks = face_landmarks
            self._debug_frame_abs_index = int(frame_abs_idx)
            self._debug_pair_absdy = pair_absdy.copy()

    def extract_landmarks_from_video(
            self,
            video_path: str,
            start_frame: Optional[int] = None,
            end_frame: Optional[int] = None,
            fps: Optional[float] = None,
    ) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
        """
        ä»è§†é¢‘ä¸­æå–é¢éƒ¨å…³é”®ç‚¹åæ ‡

        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            start_frame: èµ·å§‹å¸§ï¼ˆåŒ…å«ï¼‰
            end_frame: ç»“æŸå¸§ï¼ˆä¸åŒ…å«ï¼‰
            fps: è§†é¢‘å¸§ç‡ï¼ˆç”¨äºè®¡ç®—timestampï¼‰

        Returns:
            (left_coords, right_coords): å·¦å³å¯¹ç§°ç‚¹åæ ‡ï¼Œå½¢çŠ¶ [T, F, 3]
            å¦‚æœå¤±è´¥è¿”å› (None, None)
        """
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")

        # å¤„ç†å¸§èŒƒå›´
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 0
        start_frame = max(0, start_frame or 0)
        end_frame = min(total_frames, end_frame or total_frames)

        if start_frame >= end_frame:
            raise ValueError(f"æ— æ•ˆçš„å¸§èŒƒå›´: start={start_frame}, end={end_frame}")

        if start_frame > 0:
            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)

        # åˆ›å»ºlandmarkerï¼ˆæ¯ä¸ªè§†é¢‘ç‹¬ç«‹å®ä¾‹ï¼Œé¿å…timestampå†²çªï¼‰
        landmarker = self._create_landmarker()

        coords_list = []
        self._reset_debug_info()

        processed_idx = 0
        last_timestamp = -1
        frame_abs_idx = start_frame

        try:
            while cap.isOpened() and frame_abs_idx < end_frame:
                ret, frame = cap.read()
                if not ret:
                    break

                # è½¬æ¢ä¸ºRGB
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                mp_image = mp_mediapipe.Image(
                    image_format=mp_mediapipe.ImageFormat.SRGB,
                    data=rgb_frame
                )

                # è®¡ç®—å•è°ƒé€’å¢çš„timestamp
                if fps and fps > 0:
                    timestamp_ms = int(processed_idx * 1000.0 / float(fps))
                else:
                    timestamp_ms = processed_idx * 33  # é»˜è®¤30fps

                if timestamp_ms <= last_timestamp:
                    timestamp_ms = last_timestamp + 1
                last_timestamp = timestamp_ms
                processed_idx += 1

                # æ£€æµ‹é¢éƒ¨å…³é”®ç‚¹
                result = landmarker.detect_for_video(mp_image, timestamp_ms)

                if result.face_landmarks:
                    face_landmarks = result.face_landmarks[0]

                    # ç»„è£…åæ ‡å¹¶è®¡ç®—ä¸å¯¹ç§°æ€§
                    coords = []
                    pair_absdy = np.empty((self.n_features,), dtype=np.float32)

                    for j, (left_idx, right_idx) in enumerate(self.feature_pairs):
                        left_lm = face_landmarks[left_idx]
                        right_lm = face_landmarks[right_idx]

                        coords.append([
                            [left_lm.x, left_lm.y, left_lm.z],
                            [right_lm.x, right_lm.y, right_lm.z]
                        ])
                        pair_absdy[j] = abs(float(left_lm.y) - float(right_lm.y))

                    coords_list.append(coords)

                    # æ›´æ–°æœ€ä¸å¯¹ç§°å¸§
                    self._update_most_asymmetric_frame(
                        frame, face_landmarks, frame_abs_idx, pair_absdy
                    )

                frame_abs_idx += 1

        finally:
            cap.release()
            try:
                landmarker.close()
            except Exception:
                pass

        if not coords_list:
            return None, None

        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        coords_array = np.array(coords_list, dtype=np.float32)  # [T, F, 2, 3]
        left_coords = coords_array[:, :, 0, :]  # [T, F, 3]
        right_coords = coords_array[:, :, 1, :]  # [T, F, 3]

        return left_coords, right_coords

    def draw_landmark_pairs(
            self,
            image: np.ndarray,
            face_landmarks,
            image_width: int,
            image_height: int
    ) -> np.ndarray:
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶å¯¹ç§°ç‚¹å¯¹å’Œè¿çº¿

        Args:
            image: è¾“å…¥å›¾åƒ
            face_landmarks: MediaPipeé¢éƒ¨å…³é”®ç‚¹
            image_width: å›¾åƒå®½åº¦
            image_height: å›¾åƒé«˜åº¦

        Returns:
            ç»˜åˆ¶åçš„å›¾åƒ
        """
        vis = image.copy()

        for (left_idx, right_idx) in self.feature_pairs:
            left_lm = face_landmarks[left_idx]
            right_lm = face_landmarks[right_idx]

            # è½¬æ¢ä¸ºåƒç´ åæ ‡
            lx = int(left_lm.x * image_width)
            ly = int(left_lm.y * image_height)
            rx = int(right_lm.x * image_width)
            ry = int(right_lm.y * image_height)

            # ç»˜åˆ¶è¿æ¥çº¿
            cv2.line(
                vis, (lx, ly), (rx, ry),
                VisConfig.COLOR_CONNECTION,
                VisConfig.CONNECTION_THICKNESS
            )

            # ç»˜åˆ¶å·¦ä¾§ç‚¹ï¼ˆçº¢è‰²ï¼‰å’Œç´¢å¼•
            cv2.circle(
                vis, (lx, ly),
                VisConfig.POINT_RADIUS,
                VisConfig.COLOR_LEFT_POINT,
                -1
            )
            cv2.putText(
                vis, str(left_idx), (lx + 2, ly - 2),
                VisConfig.TEXT_FONT,
                VisConfig.TEXT_SIZE,
                VisConfig.COLOR_LEFT_POINT,
                VisConfig.TEXT_THICKNESS
            )

            # ç»˜åˆ¶å³ä¾§ç‚¹ï¼ˆè“è‰²ï¼‰å’Œç´¢å¼•
            cv2.circle(
                vis, (rx, ry),
                VisConfig.POINT_RADIUS,
                VisConfig.COLOR_RIGHT_POINT,
                -1
            )
            cv2.putText(
                vis, str(right_idx), (rx + 2, ry - 2),
                VisConfig.TEXT_FONT,
                VisConfig.TEXT_SIZE,
                VisConfig.COLOR_RIGHT_POINT,
                VisConfig.TEXT_THICKNESS
            )

        return vis

    def draw_midline(
            self,
            image: np.ndarray,
            midline: MidlinePoints
    ) -> np.ndarray:
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶é¢ä¸­çº¿

        Args:
            image: è¾“å…¥å›¾åƒ
            midline: é¢ä¸­çº¿å…³é”®ç‚¹

        Returns:
            ç»˜åˆ¶åçš„å›¾åƒ
        """
        vis = image.copy()

        # ç»˜åˆ¶é¢ä¸­çº¿
        cv2.line(
            vis,
            midline.top,
            midline.bottom,
            VisConfig.COLOR_MIDLINE,
            VisConfig.MIDLINE_THICKNESS
        )

        # ç»˜åˆ¶ç«¯ç‚¹æ ‡è®°
        cv2.circle(vis, midline.top, 4, VisConfig.COLOR_MIDLINE, -1)
        cv2.circle(vis, midline.bottom, 4, VisConfig.COLOR_MIDLINE, -1)

        return vis

    def save_index_check_image(
            self,
            frame_bgr: np.ndarray,
            face_landmarks,
            output_path: str
    ):
        """
        ä¿å­˜ç´¢å¼•æ£€æŸ¥å›¾ï¼ˆåŒ…å«ç‚¹å¯¹è¿çº¿ã€ç´¢å¼•æ ‡æ³¨å’Œé¢ä¸­çº¿ï¼‰

        Args:
            frame_bgr: BGRæ ¼å¼çš„å¸§å›¾åƒ
            face_landmarks: MediaPipeé¢éƒ¨å…³é”®ç‚¹
            output_path: è¾“å‡ºè·¯å¾„
        """
        if frame_bgr is None or face_landmarks is None:
            if self.verbose:
                print("  âš ï¸ è·³è¿‡index_checkå›¾åƒï¼šæ— æœ‰æ•ˆå¸§æˆ–å…³é”®ç‚¹")
            return

        h, w = frame_bgr.shape[:2]

        # 1. ç»˜åˆ¶æ‰€æœ‰ç‚¹å¯¹å’Œè¿çº¿
        vis = self.draw_landmark_pairs(frame_bgr, face_landmarks, w, h)

        # 2. è®¡ç®—å¹¶ç»˜åˆ¶é¢ä¸­çº¿
        face_contour_indices = self.region_feature_indices.get("face_contour", [])
        if face_contour_indices:
            midline = compute_midline_geometry(
                face_landmarks,
                face_contour_indices,
                self.feature_pairs,
                w, h
            )

            if midline:
                vis = self.draw_midline(vis, midline)
            else:
                if self.verbose:
                    print("  âš ï¸ é¢ä¸­çº¿è®¡ç®—å¤±è´¥ï¼Œè·³è¿‡ç»˜åˆ¶")
        else:
            if self.verbose:
                print("  âš ï¸ æœªæ‰¾åˆ°face_contouråŒºåŸŸï¼Œè·³è¿‡é¢ä¸­çº¿ç»˜åˆ¶")

        # 3. ä¿å­˜å›¾åƒ
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        cv2.imwrite(str(output_path), vis)

        if self.verbose:
            print(f"  âœ“ Index checkå›¾åƒå·²ä¿å­˜: {output_path}")

    def calculate_pearson_coefficients(
            self,
            left_coords: np.ndarray,
            right_coords: np.ndarray,
            use_y_only: bool = True
    ) -> SymmetryFeatures:
        """
        è®¡ç®—å·¦å³å¯¹ç§°ç‚¹yåæ ‡çš„Pearsonç›¸å…³ç³»æ•°

        Args:
            left_coords: å·¦ä¾§åæ ‡ [T, F, 3]
            right_coords: å³ä¾§åæ ‡ [T, F, 3]
            use_y_only: æ˜¯å¦åªä½¿ç”¨yåæ ‡

        Returns:
            SymmetryFeatureså¯¹è±¡
        """
        if left_coords is None or right_coords is None:
            raise ValueError("æœªæ£€æµ‹åˆ°äººè„¸å…³é”®ç‚¹")

        n_frames, n_features, _ = left_coords.shape

        # æå–yåæ ‡ï¼ˆç´¢å¼•1ï¼‰
        y_left = left_coords[:, :, 1]  # [T, F]
        y_right = right_coords[:, :, 1]  # [T, F]

        # è®¡ç®—æ¯å¯¹ç‚¹çš„Pearsonç›¸å…³ç³»æ•°
        pearson_coeffs = np.zeros((n_features,), dtype=np.float32)

        for i in range(n_features):
            a = y_left[:, i]
            b = y_right[:, i]

            # å¤„ç†å¸¸æ•°åºåˆ—
            if np.std(a) < 1e-8 or np.std(b) < 1e-8:
                pearson_coeffs[i] = np.nan
            else:
                try:
                    corr, _ = stats.pearsonr(a, b)
                    pearson_coeffs[i] = float(corr)
                except Exception:
                    pearson_coeffs[i] = np.nan

        return SymmetryFeatures(
            pearson_coefficients=pearson_coeffs,
            landmark_names=list(self.feature_names),
            y_coords_left=y_left,
            y_coords_right=y_right,
            frame_count=n_frames
        )

    @staticmethod
    def _rolling_corr_cumsum(
            y_left: np.ndarray,
            y_right: np.ndarray,
            window: int
    ) -> np.ndarray:
        """
        å‘é‡åŒ–è®¡ç®—æ»‘åŠ¨çª—å£Pearsonç›¸å…³ç³»æ•°

        Args:
            y_left: å·¦ä¾§yåæ ‡ [T, F]
            y_right: å³ä¾§yåæ ‡ [T, F]
            window: æ»‘åŠ¨çª—å£å¤§å°

        Returns:
            rolling_corr: [T, F] æ»‘åŠ¨çª—å£ç›¸å…³ç³»æ•°ï¼Œå‰window-1è¡Œä¸ºNaN
        """
        yL = y_left.astype(np.float64, copy=False)
        yR = y_right.astype(np.float64, copy=False)
        T, F = yL.shape

        window = int(max(3, window))
        if T < window:
            return np.full((T, F), np.nan, dtype=np.float32)

        def cumsum_pad(x):
            """åœ¨æ•°ç»„å‰æ·»åŠ é›¶è¡Œåè®¡ç®—ç´¯ç§¯å’Œ"""
            return np.vstack([np.zeros((1, F), dtype=np.float64), np.cumsum(x, axis=0)])

        # è®¡ç®—ç´¯ç§¯å’Œ
        cL = cumsum_pad(yL)
        cR = cumsum_pad(yR)
        cLL = cumsum_pad(yL * yL)
        cRR = cumsum_pad(yR * yR)
        cLR = cumsum_pad(yL * yR)

        # æ»‘åŠ¨çª—å£ç»Ÿè®¡é‡
        sumL = cL[window:] - cL[:-window]
        sumR = cR[window:] - cR[:-window]
        sumLL = cLL[window:] - cLL[:-window]
        sumRR = cRR[window:] - cRR[:-window]
        sumLR = cLR[window:] - cLR[:-window]

        # å‡å€¼
        meanL = sumL / window
        meanR = sumR / window

        # åæ–¹å·®å’Œæ–¹å·®
        cov = (sumLR / window) - (meanL * meanR)
        varL = (sumLL / window) - (meanL * meanL)
        varR = (sumRR / window) - (meanR * meanR)

        # Pearsonç›¸å…³ç³»æ•°
        denom = np.sqrt(np.maximum(varL, 0.0) * np.maximum(varR, 0.0))
        corr = np.divide(
            cov, denom,
            out=np.full_like(cov, np.nan),
            where=(denom > 1e-12)
        )

        # å¡«å……ç»“æœ
        out = np.full((T, F), np.nan, dtype=np.float32)
        out[window - 1:] = corr.astype(np.float32)

        return out

    def compute_region_timeseries(
            self,
            features: SymmetryFeatures,
            rolling_window: int = 15
    ) -> Dict[str, Dict[str, np.ndarray]]:
        """
        è®¡ç®—åŒºåŸŸçº§åˆ«çš„æ—¶é—´åºåˆ—æ•°æ®

        Args:
            features: å¯¹ç§°æ€§ç‰¹å¾
            rolling_window: æ»‘åŠ¨çª—å£å¤§å°

        Returns:
            åŒ…å«abs_diffå’Œrolling_corrçš„å­—å…¸
        """
        y_left = features.y_coords_left  # [T, F]
        y_right = features.y_coords_right
        T, F = y_left.shape

        # è®¡ç®—ç»å¯¹å·®å€¼å’Œæ»‘åŠ¨ç›¸å…³ç³»æ•°
        abs_diff = np.abs(y_left - y_right).astype(np.float32)  # [T, F]
        rolling_corr = self._rolling_corr_cumsum(y_left, y_right, rolling_window)  # [T, F]

        # æŒ‰åŒºåŸŸèšåˆ
        region_abs = {}
        region_corr = {}

        for region, idxs in self.region_feature_indices.items():
            idxs = list(idxs)
            if idxs:
                region_abs[region] = abs_diff[:, idxs].mean(axis=1)
                region_corr[region] = np.nanmean(rolling_corr[:, idxs], axis=1)
            else:
                region_abs[region] = np.full((T,), np.nan, np.float32)
                region_corr[region] = np.full((T,), np.nan, np.float32)

        return {
            "abs_diff": region_abs,
            "rolling_corr": region_corr,
            "abs_diff_raw": abs_diff,
            "rolling_corr_raw": rolling_corr
        }

    def save_region_timeseries_plot(
            self,
            ts: Dict[str, Dict[str, np.ndarray]],
            fps: float,
            title: str,
            save_path_base: str
    ) -> Tuple[str, str]:
        """
        ä¿å­˜åŒºåŸŸæ—¶é—´åºåˆ—å›¾

        Args:
            ts: compute_region_timeseriesçš„è¿”å›å€¼
            fps: è§†é¢‘å¸§ç‡
            title: å›¾è¡¨æ ‡é¢˜
            save_path_base: ä¿å­˜è·¯å¾„åŸºç¡€å

        Returns:
            (abs_diffå›¾è·¯å¾„, rolling_corrå›¾è·¯å¾„)
        """
        region_abs = ts["abs_diff"]
        region_corr = ts["rolling_corr"]

        # è·å–æ—¶é—´è½´
        any_region = next(iter(region_abs.keys()))
        T = len(region_abs[any_region])

        if fps and fps > 0:
            t = np.arange(T) / float(fps)
            xlabel = "Time (s)"
        else:
            t = np.arange(T)
            xlabel = "Frame"

        os.makedirs(os.path.dirname(save_path_base), exist_ok=True)

        # 1. ç»å¯¹å·®å€¼å›¾
        fig = plt.figure(figsize=(14, 6))
        ax = plt.gca()

        for region, y in region_abs.items():
            ax.plot(t, y, linewidth=1.6, label=region)

        ax.set_title(f"{title}\nRegion Asymmetry (abs(yL-yR), lower=better)")
        ax.set_xlabel(xlabel)
        ax.set_ylabel("abs(yL - yR)")
        ax.grid(True, alpha=0.25)
        ax.legend(ncol=2, fontsize=9)

        out1 = save_path_base.replace(".png", "_region_absdiff.png")
        fig.savefig(out1, dpi=160, bbox_inches="tight")
        plt.close(fig)

        # 2. æ»‘åŠ¨ç›¸å…³ç³»æ•°å›¾
        fig = plt.figure(figsize=(14, 6))
        ax = plt.gca()

        for region, y in region_corr.items():
            ax.plot(t, y, linewidth=1.6, label=region)

        ax.set_title(f"{title}\nRegion Rolling Pearson (higher=better)")
        ax.set_xlabel(xlabel)
        ax.set_ylabel("Rolling Pearson r")
        ax.set_ylim(-1.05, 1.05)
        ax.grid(True, alpha=0.25)
        ax.legend(ncol=2, fontsize=9)

        out2 = save_path_base.replace(".png", "_region_rollingcorr.png")
        fig.savefig(out2, dpi=160, bbox_inches="tight")
        plt.close(fig)

        if self.verbose:
            print(f"  âœ“ Region time-series saved: {out1}")
            print(f"  âœ“ Region time-series saved: {out2}")

        return out1, out2

    @staticmethod
    def _fast_splat_heatmap(
            w: int,
            h: int,
            pts_xy: np.ndarray,
            vals: np.ndarray,
            canvas_res: int = 256,
            sigma: float = 8.0
    ) -> np.ndarray:
        """
        å¿«é€Ÿç”Ÿæˆçƒ­åŠ›å›¾ï¼ˆæ¯”griddataå¿«å¾ˆå¤šï¼‰

        Args:
            w: ç›®æ ‡å›¾åƒå®½åº¦
            h: ç›®æ ‡å›¾åƒé«˜åº¦
            pts_xy: ç‚¹åæ ‡ [N, 2]ï¼Œåƒç´ åæ ‡ç³»
            vals: ç‚¹çš„å€¼ [N]
            canvas_res: ç”»å¸ƒåˆ†è¾¨ç‡
            sigma: é«˜æ–¯æ¨¡ç³Šæ ‡å‡†å·®

        Returns:
            heat_bgr: BGRæ ¼å¼çš„çƒ­åŠ›å›¾ï¼Œå¤§å°(h, w)
        """
        canvas_res = int(max(64, canvas_res))
        sx = canvas_res / float(w)
        sy = canvas_res / float(h)

        acc = np.zeros((canvas_res, canvas_res), dtype=np.float32)
        cnt = np.zeros((canvas_res, canvas_res), dtype=np.float32)

        # å°†ç‚¹"æ’’"åˆ°ç”»å¸ƒä¸Š
        for (x, y), v in zip(pts_xy, vals):
            cx = int(np.clip(x * sx, 0, canvas_res - 1))
            cy = int(np.clip(y * sy, 0, canvas_res - 1))
            cv2.circle(acc, (cx, cy), 2, float(v), -1)
            cv2.circle(cnt, (cx, cy), 2, 1.0, -1)

        # å½’ä¸€åŒ–å¹¶æ¨¡ç³Š
        heat = acc / (cnt + 1e-6)
        heat = cv2.GaussianBlur(heat, (0, 0), sigmaX=sigma, sigmaY=sigma)

        # å½’ä¸€åŒ–åˆ°[0, 255]
        vmin = float(np.min(heat))
        vmax = float(np.max(heat))
        heat = (heat - vmin) / (vmax - vmin + 1e-6)
        heat_u8 = np.clip(heat * 255.0, 0, 255).astype(np.uint8)

        # åº”ç”¨colormapå¹¶è°ƒæ•´å¤§å°
        heat_bgr_small = cv2.applyColorMap(heat_u8, cv2.COLORMAP_JET)
        heat_bgr = cv2.resize(heat_bgr_small, (w, h), interpolation=cv2.INTER_CUBIC)

        return heat_bgr

    def save_overlay_asymmetry_heatmap(
            self,
            frame_bgr: np.ndarray,
            face_landmarks,
            pair_values: np.ndarray,
            save_path: str,
            alpha: float = None,
            canvas_res: int = None
    ):
        """
        ä¿å­˜å åŠ ä¸å¯¹ç§°çƒ­åŠ›å›¾

        Args:
            frame_bgr: BGRæ ¼å¼çš„å¸§å›¾åƒ
            face_landmarks: MediaPipeé¢éƒ¨å…³é”®ç‚¹
            pair_values: æ¯å¯¹ç‚¹çš„åˆ†æ•°ï¼ˆé€šå¸¸ä¸º|Î”y|ï¼‰
            save_path: ä¿å­˜è·¯å¾„
            alpha: çƒ­åŠ›å›¾é€æ˜åº¦
            canvas_res: ç”»å¸ƒåˆ†è¾¨ç‡
        """
        if frame_bgr is None or face_landmarks is None:
            if self.verbose:
                print("  âš ï¸ è·³è¿‡overlayçƒ­åŠ›å›¾ï¼šæ— æœ‰æ•ˆå¸§æˆ–å…³é”®ç‚¹")
            return

        alpha = alpha or VisConfig.HEATMAP_ALPHA
        canvas_res = canvas_res or VisConfig.HEATMAP_CANVAS_RES

        h, w = frame_bgr.shape[:2]

        # æ”¶é›†ç‚¹åæ ‡å’Œå€¼
        pts = []
        vals = []

        for (li, ri), s in zip(self.feature_pairs, pair_values):
            for idx in (li, ri):
                lm = face_landmarks[idx]
                pts.append([lm.x * w, lm.y * h])
                vals.append(float(s))

        pts = np.asarray(pts, dtype=np.float32)
        vals = np.asarray(vals, dtype=np.float32)

        # ç”Ÿæˆçƒ­åŠ›å›¾å¹¶å åŠ 
        heat_bgr = self._fast_splat_heatmap(
            w=w, h=h, pts_xy=pts, vals=vals,
            canvas_res=canvas_res,
            sigma=VisConfig.HEATMAP_SIGMA
        )
        overlay = cv2.addWeighted(frame_bgr, 1 - alpha, heat_bgr, alpha, 0)

        # ä¿å­˜
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        cv2.imwrite(save_path, overlay)

        if self.verbose:
            print(f"  âœ“ Overlay heatmap saved: {save_path}")

    def visualize_symmetry_heatmap(
            self,
            features: SymmetryFeatures,
            title: str,
            save_path: str,
    ):
        """
        å¯è§†åŒ–å¯¹ç§°æ€§çƒ­åŠ›å›¾ï¼ˆPearsonç³»æ•°æŸ±çŠ¶å›¾ + ç©ºé—´åˆ†å¸ƒ + ç»Ÿè®¡æ‘˜è¦ï¼‰

        Args:
            features: å¯¹ç§°æ€§ç‰¹å¾
            title: å›¾è¡¨æ ‡é¢˜
            save_path: ä¿å­˜è·¯å¾„
        """
        fig = plt.figure(figsize=(16, 8))

        # 1) Pearsonç³»æ•°æŸ±çŠ¶å›¾
        ax1 = plt.subplot(1, 3, 1)
        coeffs = features.pearson_coefficients

        # é¢œè‰²æ˜ å°„
        colors = []
        for coef in coeffs:
            if np.isnan(coef):
                colors.append('gray')
            elif coef > PearsonThreshold.HIGH:
                colors.append('darkblue')
            elif coef > PearsonThreshold.MEDIUM:
                colors.append('lightblue')
            elif coef > PearsonThreshold.LOW:
                colors.append('yellow')
            else:
                colors.append('red')

        bars = ax1.barh(range(self.n_features), coeffs, color=colors)
        ax1.set_yticks(range(self.n_features))
        ax1.set_yticklabels(features.landmark_names, fontsize=9)
        ax1.set_xlabel('Pearson Correlation Coefficient', fontsize=11)
        ax1.set_title('å¯¹ç§°æ€§ç³»æ•°\n(è“è‰²=é«˜å¯¹ç§°, çº¢è‰²=ä¸å¯¹ç§°)', fontsize=10)
        ax1.axvline(x=0, color='black', linestyle='--', linewidth=0.8)
        ax1.axvline(x=PearsonThreshold.HIGH, color='green', linestyle='--', linewidth=0.8, alpha=0.5)
        ax1.set_xlim(-1, 1)
        ax1.grid(axis='x', alpha=0.3)

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, val) in enumerate(zip(bars, coeffs)):
            if np.isnan(val):
                label = "nan"
                xpos = 0.05
                ha = "left"
            else:
                label = f"{val:.3f}"
                xpos = (val + 0.05) if val > 0 else (val - 0.05)
                ha = "left" if val > 0 else "right"
            ax1.text(xpos, i, label, va='center', ha=ha, fontsize=8)

        # 2) ç©ºé—´åˆ†å¸ƒå›¾
        ax2 = plt.subplot(1, 3, 2)

        # æŒ‰å¹³å‡yåæ ‡æ’åº
        avg_y = (features.y_coords_left.mean(axis=0) + features.y_coords_right.mean(axis=0)) / 2
        y_norm = (avg_y - avg_y.min()) / (avg_y.max() - avg_y.min() + 1e-6)

        x = np.linspace(-1, 1, self.n_features)
        y = y_norm

        scatter = ax2.scatter(
            x, y,
            c=np.nan_to_num(coeffs, nan=0.0),
            s=500,
            cmap='RdYlBu',
            vmin=-1, vmax=1,
            edgecolors='black',
            linewidth=1.5
        )

        # æ·»åŠ ç´¢å¼•æ ‡ç­¾
        for i, (xi, yi) in enumerate(zip(x, y)):
            ax2.annotate(
                f'{i + 1}', (xi, yi),
                ha='center', va='center',
                fontsize=9, fontweight='bold'
            )

        ax2.set_xlim(-1.2, 1.2)
        ax2.set_ylim(-0.1, 1.1)
        ax2.set_xlabel('å·¦ â† | â†’ å³', fontsize=11)
        ax2.set_ylabel('ä¸Š â† | â†’ ä¸‹', fontsize=11)
        ax2.set_title('é¢éƒ¨å¯¹ç§°æ€§ç©ºé—´åˆ†å¸ƒ', fontsize=11)
        ax2.set_aspect('equal')

        cbar = plt.colorbar(scatter, ax=ax2)
        cbar.set_label('Pearson Coefficient', fontsize=10)

        # 3) ç»Ÿè®¡æ‘˜è¦
        ax3 = plt.subplot(1, 3, 3)
        ax3.axis('off')

        # è®¡ç®—ç»Ÿè®¡é‡
        valid = coeffs[np.isfinite(coeffs)]
        mean_corr = float(np.mean(valid)) if valid.size else float("nan")
        std_corr = float(np.std(valid)) if valid.size else float("nan")
        min_corr = float(np.min(valid)) if valid.size else float("nan")
        max_corr = float(np.max(valid)) if valid.size else float("nan")

        def mean_by_region(region: str) -> float:
            """è®¡ç®—åŒºåŸŸå¹³å‡Pearsonç³»æ•°"""
            idxs = self.region_feature_indices.get(region, [])
            vals = coeffs[idxs] if idxs else np.array([], dtype=np.float32)
            vals = vals[np.isfinite(vals)]
            return float(np.mean(vals)) if vals.size else float("nan")

        # æŒ‰åŒºåŸŸç»Ÿè®¡
        eyebrow_corr = mean_by_region("eyebrow")
        eye_corr = mean_by_region("eye")
        upper_lip_corr = mean_by_region("upper_lip")
        lower_lip_corr = mean_by_region("lower_lip")
        nose_corr = mean_by_region("nose")

        # æŒ‰é˜ˆå€¼åˆ†ç±»
        high_sym = int(np.sum((coeffs > PearsonThreshold.HIGH) & np.isfinite(coeffs)))
        medium_sym = int(np.sum(
            (coeffs > PearsonThreshold.MEDIUM) &
            (coeffs <= PearsonThreshold.HIGH) &
            np.isfinite(coeffs)
        ))
        low_sym = int(np.sum((coeffs <= PearsonThreshold.MEDIUM) & np.isfinite(coeffs)))

        # ç”Ÿæˆæ‘˜è¦æ–‡æœ¬
        summary_text = f"""
Statistical Summary
{'=' * 30}

Overall Symmetry:
  Mean Correlation: {mean_corr:.3f} Â± {std_corr:.3f}
  Min/Max: {min_corr:.3f} / {max_corr:.3f}
  Total Features: {self.n_features}

Region-wise Mean:
  Eyebrow: {eyebrow_corr:.3f}
  Eye: {eye_corr:.3f}
  Upper Lip: {upper_lip_corr:.3f}
  Lower Lip: {lower_lip_corr:.3f}
  Nose: {nose_corr:.3f}

Symmetry Distribution:
  High (r > 0.8): {high_sym}
  Medium (0.5 < r â‰¤ 0.8): {medium_sym}
  Low (r â‰¤ 0.5): {low_sym}

Frames Analyzed: {features.frame_count}
"""

        ax3.text(
            0.1, 0.95, summary_text,
            transform=ax3.transAxes,
            fontsize=11,
            verticalalignment='top',
            fontfamily='monospace',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3)
        )

        plt.suptitle(title, fontsize=14, fontweight='bold', y=0.98)
        plt.tight_layout()

        # ä¿å­˜
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close(fig)

        if self.verbose:
            print(f"  âœ“ Symmetry heatmap saved: {save_path}")

    def analyze_single_video(
            self,
            video_path: str,
            action_name: str,
            output_dir: str,
            start_frame: Optional[int] = None,
            end_frame: Optional[int] = None,
            fps: Optional[float] = None,
            patient_id: Optional[str] = None,
            examination_id: Optional[str] = None,
            video_id: Optional[int] = None,
    ) -> Dict:
        """
        åˆ†æå•ä¸ªè§†é¢‘ï¼ˆå®Œæ•´pipelineï¼‰

        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            action_name: åŠ¨ä½œåç§°
            output_dir: è¾“å‡ºç›®å½•ï¼ˆæ‰€æœ‰ç»“æœç»Ÿä¸€æ”¾åœ¨è¿™ä¸ªç›®å½•ä¸‹ï¼Œä¸å†ä¸ºæ¯ä¸ªè§†é¢‘åˆ›å»ºå­æ–‡ä»¶å¤¹ï¼‰
            start_frame: èµ·å§‹å¸§
            end_frame: ç»“æŸå¸§
            fps: å¸§ç‡
            patient_id: æ‚£è€…ID
            examination_id: æ£€æŸ¥ID
            video_id: è§†é¢‘ID

        Returns:
            ç»“æœå­—å…¸
        """
        if self.verbose:
            print(f"\n{'=' * 60}")
            print(f"åˆ†æè§†é¢‘: {patient_id or 'Unknown'} - {action_name}")
            print(f"{'=' * 60}")

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨ï¼ˆä¸å†åˆ›å»ºå­æ–‡ä»¶å¤¹ï¼‰
        os.makedirs(output_dir, exist_ok=True)

        # ç”¨â€œæ‚£è€…_æ£€æŸ¥_åŠ¨ä½œâ€ä½œä¸ºæ–‡ä»¶åå‰ç¼€ï¼Œé¿å…åŒä¸€ç›®å½•ä¸‹å†²çª
        safe_patient = _safe_name(patient_id)
        safe_exam = _safe_name(examination_id)
        safe_action = _safe_name(action_name)
        base_filename = f"{safe_patient}_{safe_exam}_{safe_action}" if (safe_patient or safe_exam) else safe_action

        # 1. æå–å…³é”®ç‚¹
        if self.verbose:
            print("  â†’ æå–é¢éƒ¨å…³é”®ç‚¹...")

        left_coords, right_coords = self.extract_landmarks_from_video(
            video_path,
            start_frame=start_frame,
            end_frame=end_frame,
            fps=fps
        )

        if left_coords is None or right_coords is None:
            error_msg = "æœªæ£€æµ‹åˆ°äººè„¸å…³é”®ç‚¹"
            if self.verbose:
                print(f"  âŒ {error_msg}")
            return {
                "video_path": video_path,
                "action_name": action_name,
                "patient_id": patient_id,
                "examination_id": examination_id,
                "video_id": video_id,
                "status": "failed",
                "error": error_msg
            }

        # 2. è®¡ç®—Pearsonç³»æ•°
        if self.verbose:
            print("  â†’ è®¡ç®—Pearsonç›¸å…³ç³»æ•°...")

        features = self.calculate_pearson_coefficients(left_coords, right_coords)

        # 3. è®¡ç®—åŒºåŸŸæ—¶é—´åºåˆ—
        if self.verbose:
            print("  â†’ è®¡ç®—åŒºåŸŸæ—¶é—´åºåˆ—...")

        ts = self.compute_region_timeseries(features, rolling_window=15)

        # -------- å„ç§å¯è§†åŒ–è¾“å‡ºï¼Œå…¨éƒ¨ç›´æ¥å†™åœ¨ output_dir ä¸‹ --------

        # 1) Index check å›¾åƒï¼ˆæœ€ä¸å¯¹ç§°å¸§ï¼‰
        if self._debug_frame is not None and self._debug_landmarks is not None:
            if self.verbose:
                print(
                    f"  â†’ ä¿å­˜ index_check å›¾åƒï¼ˆæœ€ä¸å¯¹ç§°å¸§: frame#{self._debug_frame_abs_index}, "
                    f"score={self._debug_asym_score:.4f}ï¼‰..."
                )
            index_check_path = os.path.join(output_dir, f"{base_filename}_index_check.png")
            self.save_index_check_image(
                self._debug_frame,
                self._debug_landmarks,
                index_check_path
            )

        # 2) Overlay çƒ­åŠ›å›¾ï¼ˆç”¨ |Î”y| åšä¸å¯¹ç§°ç¨‹åº¦ï¼‰
        if self._debug_frame is not None and self._debug_landmarks is not None and self._debug_pair_absdy is not None:
            if self.verbose:
                print("  â†’ ä¿å­˜ overlay çƒ­åŠ›å›¾...")
            overlay_path = os.path.join(output_dir, f"{base_filename}_overlay.png")
            self.save_overlay_asymmetry_heatmap(
                self._debug_frame,
                self._debug_landmarks,
                self._debug_pair_absdy,
                overlay_path
            )

        # 3) å¯¹ç§°æ€§çƒ­åŠ›å›¾ï¼ˆPearson æŸ±çŠ¶å›¾ + ç©ºé—´åˆ†å¸ƒ + ç»Ÿè®¡æ‘˜è¦ï¼‰
        if self.verbose:
            print("  â†’ ä¿å­˜ symmetry çƒ­åŠ›å›¾...")
        heatmap_path = os.path.join(output_dir, f"{base_filename}_symmetry_heatmap.png")
        self.visualize_symmetry_heatmap(
            features,
            title=f"{patient_id} - {action_name}",
            save_path=heatmap_path
        )

        # 4) åŒºåŸŸæ—¶é—´åºåˆ—å›¾ï¼ˆabs_diff / rolling_corrï¼‰
        if self.verbose:
            print("  â†’ ä¿å­˜ region æ—¶é—´åºåˆ—å›¾...")
        ts_base = os.path.join(output_dir, f"{base_filename}_timeseries.png")
        self.save_region_timeseries_plot(
            ts,
            fps=fps or 30.0,
            title=f"{patient_id} - {action_name}",
            save_path_base=ts_base
        )

        # 5) ä¿å­˜ç»Ÿè®¡ç»“æœ JSON
        if self.verbose:
            print("  â†’ ä¿å­˜ç»Ÿè®¡ç»“æœ JSON...")
        stats_data = {
            "video_info": {
                "video_path": video_path,
                "video_id": video_id,
                "patient_id": patient_id,
                "examination_id": examination_id,
                "action_name": action_name,
                "start_frame": start_frame,
                "end_frame": end_frame,
                "fps": fps,
            },
            "analysis_results": {
                "frame_count": features.frame_count,
                "n_features": self.n_features,
                "pearson_coefficients": features.pearson_coefficients.tolist(),
                "landmark_names": features.landmark_names,
                "overall_mean_pearson": float(np.nanmean(features.pearson_coefficients)),
                "overall_std_pearson": float(np.nanstd(features.pearson_coefficients)),
            },
            "most_asymmetric_frame": {
                "frame_index": self._debug_frame_abs_index,
                "asymmetry_score": self._debug_asym_score,
            } if self._debug_frame_abs_index is not None else None,
        }

        stats_path = os.path.join(output_dir, f"{base_filename}_stats.json")
        with open(stats_path, "w", encoding="utf-8") as f:
            json.dump(stats_data, f, ensure_ascii=False, indent=2)

        if self.verbose:
            print(f"  âœ“ ç»Ÿè®¡ç»“æœå·²ä¿å­˜: {stats_path}")
            print(f"\nâœ… è§†é¢‘åˆ†æå®Œæˆ: {base_filename}ï¼ˆè¾“å‡ºç›®å½•: {output_dir}ï¼‰")

        return {
            "video_path": video_path,
            "video_id": video_id,
            "patient_id": patient_id,
            "examination_id": examination_id,
            "action_name": action_name,
            "output_folder": output_dir,  # è¿™é‡Œä¹Ÿæ”¹æˆè¾“å‡ºä¸»ç›®å½•
            "status": "success",
            "mean_pearson": float(np.nanmean(features.pearson_coefficients)),
        }

    def batch_process_database(
            self,
            output_dir: str,
            limit: Optional[int] = None,
            action_filter: Optional[List[str]] = None,
            use_multiprocessing: bool = True,
            num_workers: Optional[int] = None,
    ) -> List[Dict]:
        """
        æ‰¹é‡å¤„ç†æ•°æ®åº“ä¸­çš„è§†é¢‘

        Args:
            output_dir: è¾“å‡ºç›®å½•
            limit: é™åˆ¶å¤„ç†æ•°é‡
            action_filter: åŠ¨ä½œåç§°è¿‡æ»¤åˆ—è¡¨
            use_multiprocessing: æ˜¯å¦ä½¿ç”¨å¤šè¿›ç¨‹
            num_workers: è¿›ç¨‹æ•°ï¼ˆNoneåˆ™è‡ªåŠ¨é€‰æ‹©ï¼‰

        Returns:
            ç»“æœåˆ—è¡¨
        """
        # ä»æ•°æ®åº“æŸ¥è¯¢è§†é¢‘
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        query = """
            SELECT
                v.video_id,
                v.examination_id,
                v.action_id,
                v.file_path,
                v.start_frame,
                v.end_frame,
                v.fps,
                at.action_name_en,
                e.patient_id
            FROM video_files v
            LEFT JOIN examinations e ON v.examination_id = e.examination_id
            LEFT JOIN action_types at ON v.action_id = at.action_id
            WHERE v.file_exists = 1
        """

        if action_filter:
            placeholders = ",".join(["?"] * len(action_filter))
            query += f" AND at.action_name_en IN ({placeholders})"
            cursor.execute(query, action_filter)
        else:
            cursor.execute(query)

        videos = cursor.fetchall()
        conn.close()

        if limit:
            videos = videos[:int(limit)]

        print(f"\n{'=' * 60}")
        print("æ‰¹é‡å¤„ç†æ¨¡å¼")
        print(f"æ€»è§†é¢‘æ•°: {len(videos)}")
        print(f"è¾“å‡ºç›®å½•: {output_dir}")
        print(f"å¤šè¿›ç¨‹: {use_multiprocessing}")
        print(f"{'=' * 60}\n")

        # å‡†å¤‡ä»»åŠ¡åˆ—è¡¨
        tasks = []
        for (video_id, exam_id, action_id, file_path,
             start_frame, end_frame, fps, action_name, patient_id) in videos:
            if not file_path or not os.path.exists(file_path):
                continue

            tasks.append({
                "db_path": self.db_path,
                "model_path": self.model_path,
                "video_id": int(video_id),
                "video_path": file_path,
                "action_name": action_name,
                "output_dir": output_dir,
                "start_frame": start_frame,
                "end_frame": end_frame,
                "fps": fps,
                "patient_id": patient_id,
                "examination_id": exam_id,
            })

        if not tasks:
            print("âš ï¸ æ²¡æœ‰å¯å¤„ç†çš„è§†é¢‘ä»»åŠ¡")
            return []

        # è‡ªåŠ¨ç¡®å®šè¿›ç¨‹æ•°
        if num_workers is None:
            cpu = os.cpu_count() or 8
            num_workers = min(8, cpu)

        results = []
        errors = []

        # å¤šè¿›ç¨‹å¤„ç†
        if use_multiprocessing and num_workers > 1:
            try:
                import multiprocessing as mp
                if mp.get_start_method(allow_none=True) is None:
                    mp.set_start_method("spawn", force=True)
            except RuntimeError:
                pass

            print(f"ğŸš€ ä½¿ç”¨å¤šè¿›ç¨‹: num_workers={num_workers}, tasks={len(tasks)}")

            with ProcessPoolExecutor(max_workers=num_workers) as executor:
                futs = [executor.submit(_worker_analyze_one, task) for task in tasks]
                total = len(futs)
                done = 0

                for fut in as_completed(futs):
                    done += 1
                    try:
                        ok, payload = fut.result()
                        if ok:
                            results.append(payload)
                        else:
                            errors.append(payload)
                    except Exception as e:
                        errors.append({"error": str(e)})

                    if done % 10 == 0 or done == total:
                        print(f"è¿›åº¦: {done}/{total} | æˆåŠŸ: {len(results)} | å¤±è´¥: {len(errors)}")

        else:
            # å•è¿›ç¨‹å¤„ç†
            print(f"ğŸ§µ å•è¿›ç¨‹é¡ºåºå¤„ç†: tasks={len(tasks)}")
            old_verbose = self.verbose
            self.verbose = True

            for i, task in enumerate(tasks, 1):
                print(f"[{i}/{len(tasks)}] {task['patient_id']} - {task['action_name']}")
                try:
                    r = self.analyze_single_video(
                        video_path=task["video_path"],
                        action_name=task["action_name"],
                        output_dir=task["output_dir"],
                        start_frame=task["start_frame"],
                        end_frame=task["end_frame"],
                        fps=task["fps"],
                        patient_id=task["patient_id"],
                        examination_id=task["examination_id"],
                        video_id=task["video_id"],
                    )
                    results.append(r)
                except Exception as e:
                    errors.append({
                        "video_id": task["video_id"],
                        "video_path": task["video_path"],
                        "error": str(e)
                    })
                    print(f"  âŒ é”™è¯¯: {e}")

            self.verbose = old_verbose

        # ä¿å­˜æ±‡æ€»ç»“æœ
        summary = {
            "success": results,
            "errors": errors,
            "total_tasks": len(tasks),
            "success_count": len(results),
            "error_count": len(errors),
        }

        summary_path = os.path.join(output_dir, "z_batch_summary.json")
        with open(summary_path, "w", encoding="utf-8") as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)

        print(f"\n{'=' * 60}")
        print("âœ… æ‰¹é‡å¤„ç†å®Œæˆ!")
        print(f"   æˆåŠŸå¤„ç†: {len(results)}/{len(tasks)}")
        print(f"   å¤±è´¥: {len(errors)}")
        print(f"   æ±‡æ€»ç»“æœ: {summary_path}")
        print(f"{'=' * 60}\n")

        return results

    def compare_actions(
            self,
            video_paths: Dict[str, str],
            patient_id: str,
            output_path: str
    ):
        """
        æ¯”è¾ƒåŒä¸€æ‚£è€…ä¸åŒåŠ¨ä½œçš„å¯¹ç§°æ€§

        Args:
            video_paths: {action_name: video_path} å­—å…¸
            patient_id: æ‚£è€…ID
            output_path: è¾“å‡ºè·¯å¾„
        """
        print(f"\n{'=' * 60}")
        print(f"åŠ¨ä½œå¯¹æ¯”åˆ†æ: {patient_id}")
        print(f"{'=' * 60}")

        features_dict = {}
        for action_name, video_path in video_paths.items():
            print(f"\nå¤„ç†åŠ¨ä½œ: {action_name}")
            left_coords, right_coords = self.extract_landmarks_from_video(video_path)

            if left_coords is not None and right_coords is not None:
                features = self.calculate_pearson_coefficients(left_coords, right_coords)
                features_dict[action_name] = features
            else:
                print(f"  âš ï¸ è·³è¿‡åŠ¨ä½œ {action_name}ï¼šæœªæ£€æµ‹åˆ°äººè„¸")

        if not features_dict:
            print("  âŒ æ²¡æœ‰æˆåŠŸå¤„ç†çš„åŠ¨ä½œ")
            return

        # ç»˜åˆ¶å¯¹æ¯”å›¾
        n_actions = len(features_dict)
        fig, axes = plt.subplots(1, n_actions, figsize=(6 * n_actions, 6))
        if n_actions == 1:
            axes = [axes]

        for idx, (action_name, features) in enumerate(features_dict.items()):
            ax = axes[idx]
            coeffs = features.pearson_coefficients

            # é¢œè‰²æ˜ å°„
            colors = []
            for coef in coeffs:
                if np.isnan(coef):
                    colors.append('gray')
                elif coef > PearsonThreshold.HIGH:
                    colors.append('darkblue')
                elif coef > PearsonThreshold.MEDIUM:
                    colors.append('lightblue')
                elif coef > PearsonThreshold.LOW:
                    colors.append('yellow')
                else:
                    colors.append('red')

            ax.barh(range(self.n_features), coeffs, color=colors)
            ax.set_yticks(range(self.n_features))
            ax.set_yticklabels(features.landmark_names, fontsize=8)
            ax.set_xlabel('Pearson Coefficient', fontsize=10)
            ax.set_title(
                f'{action_name}\nå¹³å‡: {np.nanmean(coeffs):.3f}',
                fontsize=11, fontweight='bold'
            )
            ax.axvline(x=0, color='black', linestyle='--', linewidth=0.8)
            ax.axvline(x=PearsonThreshold.HIGH, color='green', linestyle='--', linewidth=0.8, alpha=0.5)
            ax.set_xlim(-1, 1)
            ax.grid(axis='x', alpha=0.3)

        plt.suptitle(
            f'æ‚£è€… {patient_id} - ä¸åŒåŠ¨ä½œå¯¹ç§°æ€§å¯¹æ¯”',
            fontsize=14, fontweight='bold', y=0.98
        )
        plt.tight_layout()

        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close(fig)

        print(f"\nâœ“ å¯¹æ¯”å›¾å·²ä¿å­˜: {output_path}")


# ==================== Multiprocessing Worker ====================

def _worker_analyze_one(task: Dict):
    """
    å­è¿›ç¨‹workerå‡½æ•°

    Args:
        task: ä»»åŠ¡å­—å…¸

    Returns:
        (æˆåŠŸæ ‡å¿—, ç»“æœæ•°æ®)
    """
    try:
        analyzer = FacialSymmetryAnalyzer(
            db_path=task["db_path"],
            model_path=task["model_path"],
            verbose=False  # å­è¿›ç¨‹ä¸æ‰“å°è¯¦ç»†ä¿¡æ¯
        )

        res = analyzer.analyze_single_video(
            video_path=task["video_path"],
            action_name=task["action_name"],
            output_dir=task["output_dir"],
            start_frame=task["start_frame"],
            end_frame=task["end_frame"],
            fps=task["fps"],
            patient_id=task["patient_id"],
            examination_id=task["examination_id"],
            video_id=task.get("video_id"),
        )
        return True, res

    except Exception as e:
        return False, {
            "video_id": task.get("video_id"),
            "video_path": task.get("video_path"),
            "patient_id": task.get("patient_id"),
            "examination_id": task.get("examination_id"),
            "action_name": task.get("action_name"),
            "error": str(e),
        }


# ==================== Main ====================

def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    analyzer = FacialSymmetryAnalyzer(
        db_path='/facial_palsy/facialPalsy.db'
    )

    analyzer.batch_process_database(
        output_dir='/Users/cuijinglei/Documents/facial_palsy/HGFA/symmetry_analysis',
        limit=None,
        action_filter=None,
        use_multiprocessing=True,
        num_workers=8,
    )


if __name__ == '__main__':
    main()