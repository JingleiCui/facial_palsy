# -*- coding: utf-8 -*-
"""
Eyelid Angle (ELA) Based Blink Detector
åŸºäºçœ¼ç‘è§’åº¦çš„çœ¨çœ¼æ£€æµ‹ç³»ç»Ÿ

å‚è€ƒè®ºæ–‡: Blinking Beyond EAR: A Stable Eyelid Angle Metric
æ ¸å¿ƒåŠŸèƒ½:
1. ELAè®¡ç®— - åŸºäº3D landmarksçš„çœ¼ç‘è§’åº¦
2. çœ¨çœ¼æ£€æµ‹ - ä½¿ç”¨k-meansèšç±»
3. ç‰¹å¾æå– - closing/closed/reopening durationsç­‰
4. å¯è§†åŒ– - ELAæ—¶åºå›¾+çœ¨çœ¼é˜¶æ®µæ ‡æ³¨
"""

import os
import re
import json
import sqlite3
from pathlib import Path
from dataclasses import dataclass, asdict
from typing import List, Tuple, Dict, Optional

import numpy as np
import cv2

import matplotlib
matplotlib.use("Agg")  # å¤šè¿›ç¨‹ + æ— ç•Œé¢ç¯å¢ƒä¸‹å®‰å…¨ç»˜å›¾
import matplotlib.pyplot as plt

from scipy.ndimage import gaussian_filter1d
from scipy.signal import find_peaks
from sklearn.cluster import KMeans

import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision

from concurrent.futures import ProcessPoolExecutor, as_completed


# ==================== JSON åºåˆ—åŒ–è¾…åŠ©å‡½æ•° ====================

def convert_numpy_types(obj):
    """
    é€’å½’è½¬æ¢ numpy ç±»å‹ä¸º Python åŸç”Ÿç±»å‹ï¼Œç”¨äº JSON åºåˆ—åŒ–
    """
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [convert_numpy_types(item) for item in obj]
    else:
        return obj


matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'PingFang SC']
matplotlib.rcParams['axes.unicode_minus'] = False

# ==================== MediaPipe çœ¼ç‘Landmarkç´¢å¼• ====================

# å·¦çœ¼ä¸Šçœ¼ç‘çš„7ä¸ªç‚¹ï¼ˆä»å†…çœ¼è§’åˆ°å¤–çœ¼è§’ï¼‰
LEFT_EYE_UPPER = [398, 384, 385, 386, 387, 388, 466]

# å·¦çœ¼ä¸‹çœ¼ç‘çš„7ä¸ªç‚¹ï¼ˆä»å†…çœ¼è§’åˆ°å¤–çœ¼è§’ï¼‰
LEFT_EYE_LOWER = [382, 381, 380, 374, 373, 390, 249]

# å³çœ¼ä¸Šçœ¼ç‘çš„7ä¸ªç‚¹ï¼ˆä»å†…çœ¼è§’åˆ°å¤–çœ¼è§’ï¼‰
RIGHT_EYE_UPPER = [173, 157, 158, 159, 160, 161, 246]
# å³çœ¼ä¸‹çœ¼ç‘çš„7ä¸ªç‚¹ï¼ˆä»å†…çœ¼è§’åˆ°å¤–çœ¼è§’ï¼‰
RIGHT_EYE_LOWER = [155, 154, 153, 145, 144, 163, 7]

# çœ¼å†…çœ¦ç´¢å¼•ï¼ˆç”¨äºå½’ä¸€åŒ–ï¼‰
LEFT_INNER_CANTHUS = 362
RIGHT_INNER_CANTHUS = 133


# ==================== æ•°æ®ç»“æ„ ====================

@dataclass
class BlinkEvent:
    """å•æ¬¡çœ¨çœ¼äº‹ä»¶"""
    start_idx: int  # çœ¨çœ¼å¼€å§‹å¸§ç´¢å¼•
    end_idx: int  # çœ¨çœ¼ç»“æŸå¸§ç´¢å¼•
    min_idx: int  # ELAæœ€å°å€¼å¸§ç´¢å¼•

    # æ—¶é—´ç‰¹å¾
    closing_duration: float  # é—­çœ¼æŒç»­æ—¶é—´(ç§’)
    closed_duration: float  # é—­åˆæŒç»­æ—¶é—´(ç§’)
    reopening_duration: float  # ççœ¼æŒç»­æ—¶é—´(ç§’)

    # å¹…åº¦ç‰¹å¾
    amplitude: float  # ç›¸å¯¹å¹…åº¦
    ela_start: float  # èµ·å§‹ELA
    ela_min: float  # æœ€å°ELA
    ela_end: float  # ç»“æŸELA

    # é€Ÿåº¦ç‰¹å¾
    max_closing_velocity: float  # æœ€å¤§é—­çœ¼é€Ÿåº¦
    max_reopening_velocity: float  # æœ€å¤§ççœ¼é€Ÿåº¦
    amplitude_velocity_ratio: float  # å¹…åº¦/é€Ÿåº¦æ¯”

    # å…¶ä»–ç‰¹å¾
    previous_time: Optional[float] = None  # è·ä¸Šæ¬¡çœ¨çœ¼æ—¶é—´
    normal_area: Optional[float] = None  # å½’ä¸€åŒ–é¢ç§¯

    @property
    def duration(self) -> float:
        """è®¡ç®—çœ¨çœ¼æ€»æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰= closing + closed + reopening"""
        return self.closing_duration + self.closed_duration + self.reopening_duration


@dataclass
class ELASignal:
    """ELAä¿¡å·æ•°æ®"""
    raw: np.ndarray  # åŸå§‹ELAä¿¡å·
    filtered: np.ndarray  # æ»¤æ³¢åçš„ELAä¿¡å·
    derivative: np.ndarray  # å¯¼æ•°
    fps: float  # å¸§ç‡
    timestamps: np.ndarray  # æ—¶é—´æˆ³

    # å·¦å³çœ¼åˆ†åˆ«çš„ELA
    left_ela: Optional[np.ndarray] = None
    right_ela: Optional[np.ndarray] = None


# ==================== ELAè®¡ç®—æ ¸å¿ƒå‡½æ•° ====================

def normalize_z_coordinate(z_raw: float, transform_matrix: np.ndarray) -> float:
    """
    å½’ä¸€åŒ–Zåæ ‡ï¼ˆè®ºæ–‡å…¬å¼1ï¼‰

    Args:
        z_raw: MediaPipeåŸå§‹zåæ ‡
        transform_matrix: MediaPipeçš„å˜æ¢çŸ©é˜µ

    Returns:
        å½’ä¸€åŒ–åçš„zåæ ‡
    """
    if transform_matrix is not None and transform_matrix.shape[0] > 2:
        return 1.7 * z_raw * transform_matrix[2, 2]
    return z_raw


def fit_plane_to_landmarks(landmarks_3d: np.ndarray) -> np.ndarray:
    """
    å¯¹3D landmarksæ‹Ÿåˆå¹³é¢ï¼Œè¿”å›æ³•å‘é‡

    ä½¿ç”¨SVDæ–¹æ³•æ‹Ÿåˆå¹³é¢ï¼š
    1. ä¸­å¿ƒåŒ–æ•°æ®
    2. SVDåˆ†è§£
    3. æœ€å°å¥‡å¼‚å€¼å¯¹åº”çš„å‘é‡å³ä¸ºæ³•å‘é‡

    Args:
        landmarks_3d: [N, 3] Nä¸ª3D landmarks

    Returns:
        [3,] å•ä½æ³•å‘é‡
    """
    # ä¸­å¿ƒåŒ–
    centroid = np.mean(landmarks_3d, axis=0)
    centered = landmarks_3d - centroid

    # SVDåˆ†è§£
    U, S, Vt = np.linalg.svd(centered.T, full_matrices=False)

    # æ³•å‘é‡æ˜¯æœ€å°å¥‡å¼‚å€¼å¯¹åº”çš„å‘é‡
    normal = U[:, -1]

    # æ ‡å‡†åŒ–æ–¹å‘ï¼šä½¿ç”¨cross productåˆ¤æ–­
    # ç¡®ä¿æ³•å‘é‡æ–¹å‘ä¸€è‡´ï¼ˆä»å†…çœ¼è§’æŒ‡å‘å¤–çœ¼è§’ï¼‰
    if len(centered) > 1:
        direction_vec = centered[1] - centered[0]
        cross_prod = np.cross(direction_vec, normal)
        if np.dot(normal, cross_prod) < 0:
            normal = -normal

    return normal / (np.linalg.norm(normal) + 1e-8)


def calculate_ela_for_eye(
        upper_landmarks: np.ndarray,
        lower_landmarks: np.ndarray
) -> float:
    """
    è®¡ç®—å•çœ¼çš„ELAï¼ˆçœ¼ç‘è§’åº¦ï¼‰

    Args:
        upper_landmarks: [7, 3] ä¸Šçœ¼ç‘çš„7ä¸ª3Dç‚¹
        lower_landmarks: [7, 3] ä¸‹çœ¼ç‘çš„7ä¸ª3Dç‚¹

    Returns:
        ELAè§’åº¦ï¼ˆåº¦æ•°ï¼‰
    """
    # æ‹Ÿåˆä¸Šä¸‹çœ¼ç‘å¹³é¢
    normal_upper = fit_plane_to_landmarks(upper_landmarks)
    normal_lower = fit_plane_to_landmarks(lower_landmarks)

    # è®¡ç®—ä¸¤ä¸ªå¹³é¢æ³•å‘é‡çš„å¤¹è§’ï¼ˆè®ºæ–‡å…¬å¼2ï¼‰
    cos_angle = np.clip(np.dot(normal_upper, normal_lower), -1.0, 1.0)
    angle_rad = np.arccos(cos_angle)
    angle_deg = np.degrees(angle_rad)

    return angle_deg


def get_unit_length(landmarks, image_width: int, image_height: int) -> float:
    """
    è·å–å½’ä¸€åŒ–å•ä½é•¿åº¦ï¼ˆåŒä¾§çœ¼å†…çœ¦è·ç¦»ï¼‰

    Args:
        landmarks: MediaPipe 478ä¸ªlandmarks
        image_width: å›¾åƒå®½åº¦
        image_height: å›¾åƒé«˜åº¦

    Returns:
        å•ä½é•¿åº¦ï¼ˆåƒç´ ï¼‰
    """
    left_canthus = landmarks[LEFT_INNER_CANTHUS]
    right_canthus = landmarks[RIGHT_INNER_CANTHUS]

    left_x = left_canthus.x * image_width
    left_y = left_canthus.y * image_height
    right_x = right_canthus.x * image_width
    right_y = right_canthus.y * image_height

    distance = np.sqrt((right_x - left_x) ** 2 + (right_y - left_y) ** 2)
    return distance


def extract_3d_landmarks(
        landmarks,
        indices: List[int],
        image_width: int,
        image_height: int,
        aspect_ratio: float = 1.0
) -> np.ndarray:
    """
    æå–æŒ‡å®šç´¢å¼•çš„3D landmarks

    Args:
        landmarks: MediaPipeæ£€æµ‹åˆ°çš„478ä¸ªlandmarks
        indices: è¦æå–çš„landmarkç´¢å¼•åˆ—è¡¨
        image_width: å›¾åƒå®½åº¦
        image_height: å›¾åƒé«˜åº¦
        aspect_ratio: å›¾åƒå®½é«˜æ¯”

    Returns:
        [N, 3] 3Dåæ ‡æ•°ç»„
    """
    coords = []
    for idx in indices:
        lm = landmarks[idx]
        x = lm.x * image_width
        y = lm.y * image_height / aspect_ratio  # Yåæ ‡å½’ä¸€åŒ–
        z = lm.z * image_width  # Zåæ ‡ç¼©æ”¾ï¼ˆè®ºæ–‡çš„å¯å‘å¼æ–¹æ³•ï¼‰
        coords.append([x, y, z])

    return np.array(coords, dtype=np.float32)


def calculate_combined_ela(
        left_ela: float,
        right_ela: float,
        yaw_angle: float
) -> float:
    """
    ç»“åˆå·¦å³çœ¼ELAï¼Œè€ƒè™‘å¤´éƒ¨yawæ—‹è½¬ï¼ˆè®ºæ–‡å…¬å¼3ï¼‰

    ä½¿ç”¨sigmoidæƒé‡ï¼š
    - å¤´éƒ¨å·¦è½¬æ—¶ï¼Œå³çœ¼æƒé‡å¢åŠ 
    - å¤´éƒ¨å³è½¬æ—¶ï¼Œå·¦çœ¼æƒé‡å¢åŠ 

    Args:
        left_ela: å·¦çœ¼ELA
        right_ela: å³çœ¼ELA
        yaw_angle: å¤´éƒ¨yawè§’åº¦ï¼ˆå¼§åº¦ï¼‰

    Returns:
        ç»„åˆåçš„ELA
    """

    def sigmoid(x):
        return 1.0 / (1.0 + np.exp(-x))

    # è®ºæ–‡ä¸­çš„ç¼©æ”¾å› å­
    weight_left = sigmoid(-4 * yaw_angle)
    weight_right = sigmoid(4 * yaw_angle)

    combined = weight_left * left_ela + weight_right * right_ela
    return combined


# ==================== ELAä¿¡å·å¤„ç† ====================

def smooth_ela_signal(ela_raw: np.ndarray, fps: float) -> np.ndarray:
    """
    ä½¿ç”¨é«˜æ–¯æ»¤æ³¢å¹³æ»‘ELAä¿¡å·ï¼ˆè®ºæ–‡å…¬å¼4-5ï¼‰

    æ ‡å‡†å·®ä¸å¸§ç‡æˆæ­£æ¯”ï¼šÏƒ = FPS/30

    Args:
        ela_raw: åŸå§‹ELAä¿¡å·
        fps: è§†é¢‘å¸§ç‡

    Returns:
        å¹³æ»‘åçš„ELAä¿¡å·
    """
    sigma = fps / 30.0  # è®ºæ–‡çš„å…¬å¼
    ela_filtered = gaussian_filter1d(ela_raw, sigma=sigma)
    return ela_filtered


def compute_derivative(signal: np.ndarray) -> np.ndarray:
    """
    è®¡ç®—ä¿¡å·çš„å¯¼æ•°ï¼ˆä¸­å¿ƒå·®åˆ†ï¼‰

    Args:
        signal: è¾“å…¥ä¿¡å·

    Returns:
        å¯¼æ•°ä¿¡å·
    """
    derivative = np.zeros_like(signal)

    # ä¸­å¿ƒå·®åˆ†
    derivative[1:-1] = (signal[2:] - signal[:-2]) / 2.0

    # è¾¹ç•Œä½¿ç”¨å‰å‘/åå‘å·®åˆ†
    derivative[0] = signal[1] - signal[0]
    derivative[-1] = signal[-1] - signal[-2]

    return derivative


# ==================== çœ¨çœ¼æ£€æµ‹ ====================

def detect_blinks_kmeans(
        ela_filtered: np.ndarray,
        derivative: np.ndarray,
        fps: float,
        min_blink_duration: float = 0.05,  # æœ€å°çœ¨çœ¼æŒç»­æ—¶é—´(ç§’)
        max_blink_duration: float = 0.8  # æœ€å¤§çœ¨çœ¼æŒç»­æ—¶é—´(ç§’)
) -> List[BlinkEvent]:
    """
    ä½¿ç”¨k-meansèšç±»æ£€æµ‹çœ¨çœ¼äº‹ä»¶ï¼ˆè®ºæ–‡Section III-4ï¼‰

    æ­¥éª¤ï¼š
    1. å¯¹å¯¼æ•°çš„æå€¼ç‚¹è¿›è¡Œk-meansèšç±»ï¼ˆ2ç±»ï¼‰
    2. é…å¯¹ä¸‹é™æ²¿å’Œä¸Šå‡æ²¿
    3. æå–æ—¶é—´ç‰¹å¾

    Args:
        ela_filtered: å¹³æ»‘åçš„ELAä¿¡å·
        derivative: ELAå¯¼æ•°
        fps: å¸§ç‡
        min_blink_duration: æœ€å°çœ¨çœ¼æŒç»­æ—¶é—´
        max_blink_duration: æœ€å¤§çœ¨çœ¼æŒç»­æ—¶é—´

    Returns:
        æ£€æµ‹åˆ°çš„çœ¨çœ¼äº‹ä»¶åˆ—è¡¨
    """
    # 1. æ‰¾åˆ°å¯¼æ•°çš„æå€¼ç‚¹
    neg_peaks, _ = find_peaks(-derivative, height=0)  # è´Ÿå³°ï¼ˆä¸‹é™æ²¿ï¼‰
    pos_peaks, _ = find_peaks(derivative, height=0)  # æ­£å³°ï¼ˆä¸Šå‡æ²¿ï¼‰

    if len(neg_peaks) < 2 or len(pos_peaks) < 2:
        return []

    # 2. K-meansèšç±»ï¼ˆ2ç±»ï¼šå™ªå£° vs çœŸå®çœ¨çœ¼ï¼‰
    neg_values = -derivative[neg_peaks]
    pos_values = derivative[pos_peaks]

    # å¯¹è´Ÿå³°èšç±»
    if len(neg_peaks) >= 2:
        kmeans_neg = KMeans(n_clusters=2, random_state=42, n_init=10)
        labels_neg = kmeans_neg.fit_predict(neg_values.reshape(-1, 1))
        # é€‰æ‹©å¹…åº¦è¾ƒå¤§çš„ç±»ä½œä¸ºçœ¨çœ¼
        cluster_means = [neg_values[labels_neg == i].mean() for i in range(2)]
        blink_cluster_neg = np.argmax(cluster_means)
        blink_neg_peaks = neg_peaks[labels_neg == blink_cluster_neg]
    else:
        blink_neg_peaks = neg_peaks

    # å¯¹æ­£å³°èšç±»
    if len(pos_peaks) >= 2:
        kmeans_pos = KMeans(n_clusters=2, random_state=42, n_init=10)
        labels_pos = kmeans_pos.fit_predict(pos_values.reshape(-1, 1))
        cluster_means = [pos_values[labels_pos == i].mean() for i in range(2)]
        blink_cluster_pos = np.argmax(cluster_means)
        blink_pos_peaks = pos_peaks[labels_pos == blink_cluster_pos]
    else:
        blink_pos_peaks = pos_peaks

    # 3. é…å¯¹ä¸‹é™æ²¿å’Œä¸Šå‡æ²¿
    blinks = []
    for neg_idx in blink_neg_peaks:
        # æ‰¾åˆ°neg_idxä¹‹åæœ€è¿‘çš„pos_idx
        following_pos = blink_pos_peaks[blink_pos_peaks > neg_idx]
        if len(following_pos) == 0:
            continue

        pos_idx = following_pos[0]

        # æ£€æŸ¥çœ¨çœ¼æŒç»­æ—¶é—´
        duration = (pos_idx - neg_idx) / fps
        if duration < min_blink_duration or duration > max_blink_duration:
            continue

        # æ‰¾åˆ°æœ€å°ELAç‚¹
        min_idx = neg_idx + np.argmin(ela_filtered[neg_idx:pos_idx + 1])

        # æå–çœ¨çœ¼ç‰¹å¾
        blink = extract_blink_features(
            ela_filtered, derivative,
            neg_idx, min_idx, pos_idx, fps
        )

        if blink is not None:
            blinks.append(blink)

    # è®¡ç®—ç›¸é‚»çœ¨çœ¼çš„æ—¶é—´é—´éš”
    for i in range(1, len(blinks)):
        blinks[i].previous_time = (blinks[i].start_idx - blinks[i - 1].start_idx) / fps

    return blinks


def summarize_blink_sequence(
        ela_signal: "ELASignal",
        blinks: List["BlinkEvent"]
) -> Dict[str, float]:
    """
    å¯¹æ•´æ®µçœ¨çœ¼åºåˆ—åšä¸€ä¸ªå…¨å±€ç»Ÿè®¡ï¼Œæ–¹ä¾¿åç»­å†™å…¥ JSON / ç”»å›¾ã€‚

    è¿”å›å­—æ®µç¤ºä¾‹ï¼š
        {
            "num_blinks": 12,
            "duration_sec": 28.3,
            "blink_rate_per_minute": 25.4,
            "mean_duration": 0.18,
            "median_duration": 0.17,
            "max_duration": 0.32
        }
    """
    if ela_signal.timestamps is None or len(ela_signal.timestamps) == 0:
        return {
            "num_blinks": 0,
            "duration_sec": 0.0,
            "blink_rate_per_minute": 0.0,
            "mean_duration": 0.0,
            "median_duration": 0.0,
            "max_duration": 0.0,
        }

    num_blinks = len(blinks)
    t0 = float(ela_signal.timestamps[0])
    t1 = float(ela_signal.timestamps[-1])
    duration_sec = max(t1 - t0, 0.0)

    if duration_sec > 0 and num_blinks > 0:
        blink_rate_per_minute = num_blinks / duration_sec * 60.0
    else:
        blink_rate_per_minute = 0.0

    if num_blinks > 0:
        durations = np.array([b.duration for b in blinks], dtype=np.float32)
        mean_duration = float(np.mean(durations))
        median_duration = float(np.median(durations))
        max_duration = float(np.max(durations))
    else:
        mean_duration = median_duration = max_duration = 0.0

    return {
        "num_blinks": int(num_blinks),
        "duration_sec": float(duration_sec),
        "blink_rate_per_minute": float(blink_rate_per_minute),
        "mean_duration": float(mean_duration),
        "median_duration": float(median_duration),
        "max_duration": float(max_duration),
    }


def extract_blink_features(
        ela_filtered: np.ndarray,
        derivative: np.ndarray,
        start_idx: int,
        min_idx: int,
        end_idx: int,
        fps: float
) -> Optional[BlinkEvent]:
    """
    æå–å•æ¬¡çœ¨çœ¼çš„ç‰¹å¾ï¼ˆè®ºæ–‡Table Iï¼‰

    Args:
        ela_filtered: å¹³æ»‘åçš„ELAä¿¡å·
        derivative: å¯¼æ•°
        start_idx: çœ¨çœ¼å¼€å§‹ç´¢å¼•
        min_idx: ELAæœ€å°å€¼ç´¢å¼•
        end_idx: çœ¨çœ¼ç»“æŸç´¢å¼•
        fps: å¸§ç‡

    Returns:
        BlinkEventå¯¹è±¡ï¼Œå¤±è´¥è¿”å›None
    """
    if start_idx >= min_idx or min_idx >= end_idx:
        return None

    # æ‰©å±•æœç´¢èŒƒå›´ï¼Œæ‰¾åˆ°çœŸæ­£çš„èµ·ç‚¹å’Œç»ˆç‚¹
    # å‘å‰æ‰¾åˆ°æœ€è¿‘çš„å±€éƒ¨æœ€å¤§å€¼
    search_start = max(0, start_idx - int(0.5 * fps))  # å‘å‰æœç´¢0.5ç§’
    local_max_before = search_start + np.argmax(ela_filtered[search_start:start_idx + 1])

    # å‘åæ‰¾åˆ°æœ€è¿‘çš„å±€éƒ¨æœ€å¤§å€¼
    search_end = min(len(ela_filtered), end_idx + int(0.5 * fps))
    local_max_after = end_idx + np.argmax(ela_filtered[end_idx:search_end])

    # ä½¿ç”¨åˆ‡çº¿äº¤ç‚¹æ³•è®¡ç®—ç²¾ç¡®çš„æ—¶é—´è¾¹ç•Œï¼ˆè®ºæ–‡Fig. 3ï¼‰
    ela_start = ela_filtered[local_max_before]
    ela_min = ela_filtered[min_idx]
    ela_end = ela_filtered[local_max_after]

    # é—­çœ¼é˜¶æ®µï¼šä»startåˆ°min
    closing_phase = ela_filtered[local_max_before:min_idx + 1]
    max_closing_vel = np.max(-derivative[local_max_before:min_idx + 1])

    # ççœ¼é˜¶æ®µï¼šä»minåˆ°end
    reopening_phase = ela_filtered[min_idx:local_max_after + 1]
    max_reopening_vel = np.max(derivative[min_idx:local_max_after + 1])

    # ä½¿ç”¨åˆ‡çº¿äº¤ç‚¹æ³•è®¡ç®—æŒç»­æ—¶é—´
    # ç®€åŒ–ç‰ˆæœ¬ï¼šç›´æ¥ä½¿ç”¨å³°å€¼å¯¼æ•°ç‚¹
    t1 = local_max_before / fps
    t2 = min_idx / fps
    t3 = local_max_after / fps

    closing_duration = t2 - t1
    closed_duration = 0.05  # ç®€åŒ–ï¼šå‡è®¾é—­åˆæŒç»­æ—¶é—´å¾ˆçŸ­
    reopening_duration = t3 - t2

    # å¹…åº¦ç‰¹å¾
    amplitude = (ela_start - ela_min) / (ela_start + 1e-6)

    # å¹…åº¦/é€Ÿåº¦æ¯”ï¼ˆè®ºæ–‡Table Iï¼‰
    av_ratio = (ela_end - ela_min) / (max_reopening_vel + 1e-6)

    # å½’ä¸€åŒ–é¢ç§¯ï¼ˆè®ºæ–‡Table Iï¼‰
    area = np.sum(ela_end - reopening_phase)
    normal_area = area / ((ela_end - ela_min) * 2 * reopening_duration + 1e-6)

    return BlinkEvent(
        start_idx=local_max_before,
        end_idx=local_max_after,
        min_idx=min_idx,
        closing_duration=closing_duration,
        closed_duration=closed_duration,
        reopening_duration=reopening_duration,
        amplitude=amplitude,
        ela_start=ela_start,
        ela_min=ela_min,
        ela_end=ela_end,
        max_closing_velocity=max_closing_vel,
        max_reopening_velocity=max_reopening_vel,
        amplitude_velocity_ratio=av_ratio,
        normal_area=normal_area
    )


# ==================== è§†é¢‘å¤„ç† ====================

def process_video_ela(
        video_path: str,
        model_path: str,
        start_frame: int = 0,
        end_frame: Optional[int] = None
) -> Optional[ELASignal]:
    """
    å¤„ç†è§†é¢‘ï¼Œæå–ELAä¿¡å·

    Args:
        video_path: è§†é¢‘è·¯å¾„
        model_path: MediaPipeæ¨¡å‹è·¯å¾„
        start_frame: èµ·å§‹å¸§
        end_frame: ç»“æŸå¸§ï¼ˆNoneè¡¨ç¤ºå¤„ç†åˆ°è§†é¢‘æœ«å°¾ï¼‰

    Returns:
        ELASignalå¯¹è±¡ï¼Œå¤±è´¥è¿”å›None
    """
    # åˆå§‹åŒ–MediaPipe
    base_options = python.BaseOptions(model_asset_path=model_path)
    options = vision.FaceLandmarkerOptions(
        base_options=base_options,
        output_face_blendshapes=False,
        output_facial_transformation_matrixes=True,
        num_faces=1
    )
    detector = vision.FaceLandmarker.create_from_options(options)

    # æ‰“å¼€è§†é¢‘
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
        return None

    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    if end_frame is None:
        end_frame = total_frames

    # è·³è½¬åˆ°èµ·å§‹å¸§
    if start_frame > 0:
        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)

    print(f"ğŸ“¹ å¤„ç†è§†é¢‘: {os.path.basename(video_path)}")
    print(f"   å¸§ç‡: {fps:.2f} FPS")
    print(f"   åˆ†è¾¨ç‡: {width}x{height}")
    print(f"   å¤„ç†èŒƒå›´: {start_frame}-{end_frame}")

    left_elas = []
    right_elas = []
    combined_elas = []
    frame_idx = start_frame

    while frame_idx < end_frame:
        ret, frame = cap.read()
        if not ret:
            break

        # è½¬æ¢ä¸ºRGB
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)

        # æ£€æµ‹landmarks
        detection_result = detector.detect(mp_image)

        if detection_result.face_landmarks:
            landmarks = detection_result.face_landmarks[0]

            # æå–å·¦çœ¼ä¸Šä¸‹çœ¼ç‘3D landmarks
            left_upper_3d = extract_3d_landmarks(
                landmarks, LEFT_EYE_UPPER, width, height, height / width
            )
            left_lower_3d = extract_3d_landmarks(
                landmarks, LEFT_EYE_LOWER, width, height, height / width
            )

            # æå–å³çœ¼ä¸Šä¸‹çœ¼ç‘3D landmarks
            right_upper_3d = extract_3d_landmarks(
                landmarks, RIGHT_EYE_UPPER, width, height, height / width
            )
            right_lower_3d = extract_3d_landmarks(
                landmarks, RIGHT_EYE_LOWER, width, height, height / width
            )

            # è®¡ç®—å·¦å³çœ¼ELA
            left_ela = calculate_ela_for_eye(left_upper_3d, left_lower_3d)
            right_ela = calculate_ela_for_eye(right_upper_3d, right_lower_3d)

            # è·å–yawè§’åº¦ï¼ˆç®€åŒ–ï¼šå‡è®¾ä¸º0ï¼‰
            # å®é™…åº”è¯¥ä»detection_result.facial_transformation_matrixesæå–
            yaw_angle = 0.0

            # ç»„åˆELA
            combined_ela = calculate_combined_ela(left_ela, right_ela, yaw_angle)

            left_elas.append(left_ela)
            right_elas.append(right_ela)
            combined_elas.append(combined_ela)
        else:
            # æœªæ£€æµ‹åˆ°äººè„¸ï¼Œä½¿ç”¨å‰ä¸€å¸§çš„å€¼æˆ–NaN
            if len(combined_elas) > 0:
                left_elas.append(left_elas[-1])
                right_elas.append(right_elas[-1])
                combined_elas.append(combined_elas[-1])
            else:
                left_elas.append(np.nan)
                right_elas.append(np.nan)
                combined_elas.append(np.nan)

        frame_idx += 1

        if frame_idx % 100 == 0:
            print(f"   å¤„ç†è¿›åº¦: {frame_idx - start_frame}/{end_frame - start_frame}")

    cap.release()

    if len(combined_elas) == 0:
        print("âŒ æœªæ£€æµ‹åˆ°ä»»ä½•äººè„¸")
        return None

    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    raw_ela = np.array(combined_elas, dtype=np.float32)
    left_ela_array = np.array(left_elas, dtype=np.float32)
    right_ela_array = np.array(right_elas, dtype=np.float32)

    # å¤„ç†NaNå€¼ï¼ˆçº¿æ€§æ’å€¼ï¼‰
    if np.any(np.isnan(raw_ela)):
        valid_indices = ~np.isnan(raw_ela)
        if np.sum(valid_indices) > 1:
            raw_ela = np.interp(
                np.arange(len(raw_ela)),
                np.where(valid_indices)[0],
                raw_ela[valid_indices]
            )

    # å¹³æ»‘ä¿¡å·
    filtered_ela = smooth_ela_signal(raw_ela, fps)

    # è®¡ç®—å¯¼æ•°
    derivative = compute_derivative(filtered_ela)

    # æ—¶é—´æˆ³
    timestamps = np.arange(len(raw_ela)) / fps

    print(f"âœ… ELAä¿¡å·æå–å®Œæˆ: {len(raw_ela)} å¸§")

    return ELASignal(
        raw=raw_ela,
        filtered=filtered_ela,
        derivative=derivative,
        fps=fps,
        timestamps=timestamps,
        left_ela=left_ela_array,
        right_ela=right_ela_array
    )


# ==================== å¯è§†åŒ– ====================

def visualize_ela_with_blinks(
        ela_signal: ELASignal,
        blinks: List[BlinkEvent],
        output_path: str,
        title: str = "ELA Signal with Blink Detection"
):
    """
    å¯è§†åŒ–ELAä¿¡å·å’Œæ£€æµ‹åˆ°çš„çœ¨çœ¼äº‹ä»¶

    åˆ›å»º3ä¸ªå­å›¾ï¼š
    1. ELAåŸå§‹ä¿¡å· + æ»¤æ³¢ä¿¡å· + çœ¨çœ¼æ ‡æ³¨
    2. ELAå¯¼æ•° + çœ¨çœ¼è¾¹ç•Œ
    3. çœ¨çœ¼å„é˜¶æ®µè¯¦ç»†æ ‡æ³¨ï¼ˆæ”¾å¤§å›¾ï¼‰

    Args:
        ela_signal: ELAä¿¡å·
        blinks: æ£€æµ‹åˆ°çš„çœ¨çœ¼åˆ—è¡¨
        output_path: è¾“å‡ºå›¾åƒè·¯å¾„
        title: å›¾è¡¨æ ‡é¢˜
    """
    fig, axes = plt.subplots(3, 1, figsize=(16, 12))

    time = ela_signal.timestamps

    # ========== å­å›¾1: ELAä¿¡å· + çœ¨çœ¼æ ‡æ³¨ ==========
    ax1 = axes[0]

    # ç»˜åˆ¶åŸå§‹å’Œæ»¤æ³¢ä¿¡å·
    ax1.plot(time, ela_signal.raw, 'lightgray',
             linewidth=0.8, alpha=0.6, label='Raw ELA')
    ax1.plot(time, ela_signal.filtered, 'darkblue',
             linewidth=1.5, label='Filtered ELA')

    # æ ‡æ³¨æ¯ä¸ªçœ¨çœ¼äº‹ä»¶
    for i, blink in enumerate(blinks):
        start_time = time[blink.start_idx]
        end_time = time[blink.end_idx]
        min_time = time[blink.min_idx]

        # çœ¨çœ¼åŒºé—´èƒŒæ™¯
        ax1.axvspan(start_time, end_time, alpha=0.2, color='yellow')

        # æœ€å°ç‚¹
        ax1.plot(min_time, blink.ela_min, 'ro', markersize=6)

        # æ ‡æ³¨çœ¨çœ¼ç¼–å·
        ax1.text(min_time, blink.ela_min - 5, f'#{i + 1}',
                 ha='center', va='top', fontsize=8, color='red')

    ax1.set_xlabel('Time (s)', fontsize=11)
    ax1.set_ylabel('ELA (degrees)', fontsize=11)
    ax1.set_title(f'{title}\næ£€æµ‹åˆ° {len(blinks)} æ¬¡çœ¨çœ¼',
                  fontsize=13, fontweight='bold')
    ax1.legend(loc='upper right')
    ax1.grid(True, alpha=0.3)

    # ========== å­å›¾2: å¯¼æ•° + çœ¨çœ¼è¾¹ç•Œ ==========
    ax2 = axes[1]

    ax2.plot(time, ela_signal.derivative, 'green', linewidth=1.0)
    ax2.axhline(y=0, color='black', linestyle='--', linewidth=0.8, alpha=0.5)

    # æ ‡æ³¨çœ¨çœ¼çš„èµ·æ­¢ç‚¹
    for blink in blinks:
        start_time = time[blink.start_idx]
        end_time = time[blink.end_idx]

        # èµ·ç‚¹ï¼ˆæœ€å¤§è´Ÿå¯¼æ•°ï¼‰
        ax2.plot(time[blink.start_idx],
                 ela_signal.derivative[blink.start_idx],
                 'rv', markersize=8, label='Start' if blink == blinks[0] else '')

        # ç»ˆç‚¹ï¼ˆæœ€å¤§æ­£å¯¼æ•°ï¼‰
        ax2.plot(time[blink.end_idx],
                 ela_signal.derivative[blink.end_idx],
                 'r^', markersize=8, label='End' if blink == blinks[0] else '')

    ax2.set_xlabel('Time (s)', fontsize=11)
    ax2.set_ylabel('dELA/dt (deg/frame)', fontsize=11)
    ax2.set_title('ELA Derivative (ç”¨äºæ£€æµ‹çœ¨çœ¼è¾¹ç•Œ)', fontsize=12, fontweight='bold')
    ax2.legend(loc='upper right')
    ax2.grid(True, alpha=0.3)

    # ========== å­å›¾3: çœ¨çœ¼é˜¶æ®µè¯¦ç»†æ ‡æ³¨ï¼ˆé€‰æ‹©å‰å‡ ä¸ªçœ¨çœ¼æ”¾å¤§æ˜¾ç¤ºï¼‰ ==========
    ax3 = axes[2]

    # é€‰æ‹©å‰3ä¸ªçœ¨çœ¼äº‹ä»¶è¿›è¡Œè¯¦ç»†å±•ç¤º
    demo_blinks = blinks[:min(3, len(blinks))]

    for i, blink in enumerate(demo_blinks):
        # æ‰©å±•æ˜¾ç¤ºèŒƒå›´
        margin = int(0.3 * ela_signal.fps)  # å‰åå„0.3ç§’
        plot_start = max(0, blink.start_idx - margin)
        plot_end = min(len(time), blink.end_idx + margin)

        plot_time = time[plot_start:plot_end] - time[blink.start_idx]  # ç›¸å¯¹æ—¶é—´
        plot_ela = ela_signal.filtered[plot_start:plot_end]

        # åç§»ä»¥åˆ†ç¦»å¤šä¸ªçœ¨çœ¼
        offset = i * 15

        # ç»˜åˆ¶ä¿¡å·
        ax3.plot(plot_time, plot_ela + offset, linewidth=2,
                 label=f'Blink #{i + 1}')

        # æ ‡æ³¨ä¸‰ä¸ªé˜¶æ®µ
        t1 = time[blink.start_idx] - time[blink.start_idx]  # =0
        t2 = time[blink.min_idx] - time[blink.start_idx]
        t3 = time[blink.end_idx] - time[blink.start_idx]

        # é—­çœ¼é˜¶æ®µ
        ax3.axvspan(t1, t2, alpha=0.2, color='red')
        ax3.text((t1 + t2) / 2, blink.ela_start + offset + 2,
                 f'Closing\n{blink.closing_duration:.3f}s',
                 ha='center', va='bottom', fontsize=9, color='darkred')

        # ççœ¼é˜¶æ®µ
        ax3.axvspan(t2, t3, alpha=0.2, color='green')
        ax3.text((t2 + t3) / 2, blink.ela_end + offset + 2,
                 f'Reopening\n{blink.reopening_duration:.3f}s',
                 ha='center', va='bottom', fontsize=9, color='darkgreen')

        # å…³é”®ç‚¹æ ‡æ³¨
        ax3.plot(t1, blink.ela_start + offset, 'go', markersize=8)
        ax3.plot(t2, blink.ela_min + offset, 'ro', markersize=8)
        ax3.plot(t3, blink.ela_end + offset, 'go', markersize=8)

    ax3.set_xlabel('Relative Time (s)', fontsize=11)
    ax3.set_ylabel('ELA (degrees) + offset', fontsize=11)
    ax3.set_title('çœ¨çœ¼é˜¶æ®µè¯¦ç»†æ ‡æ³¨ (Closing â†’ Closed â†’ Reopening)',
                  fontsize=12, fontweight='bold')
    ax3.legend(loc='upper right')
    ax3.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close(fig)

    print(f"âœ… å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {output_path}")


def create_blink_summary_figure(
        blinks: List[BlinkEvent],
        fps: float,
        output_path: str
):
    """
    åˆ›å»ºçœ¨çœ¼ç‰¹å¾ç»Ÿè®¡æ±‡æ€»å›¾

    åŒ…å«ï¼š
    1. çœ¨çœ¼é¢‘ç‡ç›´æ–¹å›¾
    2. closing/closed/reopeningæŒç»­æ—¶é—´ç®±çº¿å›¾
    3. å¹…åº¦-é€Ÿåº¦æ•£ç‚¹å›¾

    Args:
        blinks: çœ¨çœ¼äº‹ä»¶åˆ—è¡¨
        fps: å¸§ç‡
        output_path: è¾“å‡ºè·¯å¾„
    """
    if len(blinks) == 0:
        return

    fig, axes = plt.subplots(2, 2, figsize=(14, 10))

    # ========== å­å›¾1: çœ¨çœ¼é¢‘ç‡ç›´æ–¹å›¾ ==========
    ax1 = axes[0, 0]
    if len(blinks) > 1:
        intervals = [b.previous_time for b in blinks[1:] if b.previous_time is not None]
        if intervals:
            ax1.hist(intervals, bins=20, color='steelblue', edgecolor='black', alpha=0.7)
            ax1.axvline(np.mean(intervals), color='red', linestyle='--',
                        linewidth=2, label=f'Mean: {np.mean(intervals):.2f}s')
            ax1.set_xlabel('Inter-Blink Interval (s)', fontsize=11)
            ax1.set_ylabel('Frequency', fontsize=11)
            ax1.set_title('çœ¨çœ¼é¢‘ç‡åˆ†å¸ƒ', fontsize=12, fontweight='bold')
            ax1.legend()
            ax1.grid(True, alpha=0.3)

    # ========== å­å›¾2: æŒç»­æ—¶é—´ç®±çº¿å›¾ ==========
    ax2 = axes[0, 1]

    closing_durs = [b.closing_duration * 1000 for b in blinks]  # è½¬æ¢ä¸ºms
    closed_durs = [b.closed_duration * 1000 for b in blinks]
    reopening_durs = [b.reopening_duration * 1000 for b in blinks]

    data_to_plot = [closing_durs, closed_durs, reopening_durs]
    labels = ['Closing', 'Closed', 'Reopening']

    bp = ax2.boxplot(data_to_plot, labels=labels, patch_artist=True,
                     boxprops=dict(facecolor='lightblue', alpha=0.7))
    ax2.set_ylabel('Duration (ms)', fontsize=11)
    ax2.set_title('çœ¨çœ¼å„é˜¶æ®µæŒç»­æ—¶é—´', fontsize=12, fontweight='bold')
    ax2.grid(True, alpha=0.3, axis='y')

    # ========== å­å›¾3: å¹…åº¦-é€Ÿåº¦æ•£ç‚¹å›¾ ==========
    ax3 = axes[1, 0]

    amplitudes = [b.amplitude for b in blinks]
    velocities = [b.max_reopening_velocity for b in blinks]

    ax3.scatter(amplitudes, velocities, c='coral', s=50, alpha=0.6, edgecolors='black')
    ax3.set_xlabel('Amplitude (relative)', fontsize=11)
    ax3.set_ylabel('Max Reopening Velocity (deg/frame)', fontsize=11)
    ax3.set_title('å¹…åº¦ vs é€Ÿåº¦', fontsize=12, fontweight='bold')
    ax3.grid(True, alpha=0.3)

    # ========== å­å›¾4: ç»Ÿè®¡è¡¨æ ¼ ==========
    ax4 = axes[1, 1]
    ax4.axis('off')

    # è®¡ç®—ç»Ÿè®¡é‡
    stats_data = [
        ['æŒ‡æ ‡', 'å‡å€¼', 'æ ‡å‡†å·®', 'Min', 'Max'],
        ['çœ¨çœ¼æ¬¡æ•°', f'{len(blinks)}', '-', '-', '-'],
        ['Closing (ms)', f'{np.mean(closing_durs):.1f}',
         f'{np.std(closing_durs):.1f}',
         f'{np.min(closing_durs):.1f}', f'{np.max(closing_durs):.1f}'],
        ['Closed (ms)', f'{np.mean(closed_durs):.1f}',
         f'{np.std(closed_durs):.1f}',
         f'{np.min(closed_durs):.1f}', f'{np.max(closed_durs):.1f}'],
        ['Reopening (ms)', f'{np.mean(reopening_durs):.1f}',
         f'{np.std(reopening_durs):.1f}',
         f'{np.min(reopening_durs):.1f}', f'{np.max(reopening_durs):.1f}'],
        ['Amplitude', f'{np.mean(amplitudes):.3f}',
         f'{np.std(amplitudes):.3f}',
         f'{np.min(amplitudes):.3f}', f'{np.max(amplitudes):.3f}'],
    ]

    table = ax4.table(cellText=stats_data, cellLoc='center',
                      loc='center', bbox=[0, 0, 1, 1])
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 2)

    # è®¾ç½®è¡¨å¤´æ ·å¼
    for i in range(5):
        cell = table[(0, i)]
        cell.set_facecolor('#4CAF50')
        cell.set_text_props(weight='bold', color='white')

    ax4.set_title('çœ¨çœ¼ç‰¹å¾ç»Ÿè®¡', fontsize=12, fontweight='bold', pad=20)

    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close(fig)

    print(f"âœ… ç‰¹å¾ç»Ÿè®¡å›¾å·²ä¿å­˜: {output_path}")


# ==================== ä¸»å¤„ç†å‡½æ•° ====================

def _safe_prefix(
        examination_id: Optional[int],
        action_name: Optional[str]
) -> str:
    """
    æŠŠ exam_id / action_name æ‹¼æˆä¸€ä¸ªå®‰å…¨çš„å‰ç¼€ï¼Œç”¨æ¥å‘½å PNG/JSON æ–‡ä»¶ã€‚
    """
    parts = []
    if examination_id is not None:
        parts.append(f"{examination_id}")
    if action_name:
        parts.append(action_name)

    raw = "_".join(parts) if parts else "UNKNOWN"
    raw = raw.replace(" ", "_")
    return re.sub(r"[^0-9A-Za-z_\-]+", "", raw)


def analyze_video_blinks(
        video_path: str,
        model_path: str,
        output_dir: str,
        patient_id: str = "UNKNOWN",
        action_name: str = "UnknownAction",
        examination_id: Optional[int] = None,
        start_frame: int = 0,
        end_frame: Optional[int] = None,
        fps: Optional[float] = None,
) -> Optional[Dict]:
    """
    å•ä¸ªè§†é¢‘çš„çœ¨çœ¼åˆ†æå…¥å£ï¼š
      1. è°ƒç”¨ process_video_ela æå– ELA ä¿¡å·ï¼›
      2. ç”¨ KMeans åšçœ¨çœ¼æ£€æµ‹ï¼›
      3. è®¡ç®—ç»Ÿè®¡ç‰¹å¾ï¼›
      4. è¾“å‡ºä¸¤å¼ å›¾ + ä¸€ä¸ª JSON ç»“æœæ–‡ä»¶ï¼›
      5. è¿”å›ä¸€ä¸ª Python dictï¼Œä¾›æ‰¹å¤„ç†ç»Ÿè®¡ç”¨ã€‚

    æ³¨æ„ï¼š
      - start_frame / end_frame ç”¨äºåªåˆ†æå…³é”®åŠ¨ä½œæ—¶é—´æ®µï¼›
      - fps å¦‚æœä¼ å…¥ï¼Œåˆ™ç”¨äºç»Ÿè®¡ï¼ˆå¦åˆ™ç”¨è§†é¢‘é‡Œçš„ fpsï¼‰ã€‚
    """
    os.makedirs(output_dir, exist_ok=True)
    prefix = _safe_prefix(examination_id, action_name)

    print(f"\n[INFO] åˆ†æè§†é¢‘: {prefix}")
    print(f"       è·¯å¾„: {video_path}")
    print(f"       å¸§èŒƒå›´: [{start_frame}, {('end' if end_frame is None else end_frame)}]")

    # 1. æå– ELA ä¿¡å·
    ela_signal = process_video_ela(
        video_path=video_path,
        model_path=model_path,
        start_frame=start_frame,
        end_frame=end_frame
    )

    if ela_signal is None or ela_signal.filtered is None or len(ela_signal.filtered) == 0:
        print(f"[WARN] {prefix} - ELA ä¿¡å·ä¸ºç©ºï¼Œè·³è¿‡ã€‚")
        return None

    # å¦‚æœè°ƒç”¨è€…ç»™äº† fpsï¼Œåˆ™è¦†ç›–ï¼›å¦åˆ™ä½¿ç”¨è§†é¢‘ä¸­æ£€æµ‹åˆ°çš„ fps
    if fps is not None and fps > 0:
        ela_signal.fps = float(fps)

    # 2. çœ¨çœ¼æ£€æµ‹
    blinks = detect_blinks_kmeans(
        ela_filtered=ela_signal.filtered,
        derivative=ela_signal.derivative,
        fps=ela_signal.fps
    )

    # 3. ç»Ÿè®¡ç‰¹å¾
    stats = summarize_blink_sequence(ela_signal, blinks)

    # 4. å¯è§†åŒ–ï¼šELA + çœ¨çœ¼æ ‡è®°
    vis_path = os.path.join(output_dir, f"{prefix}_ela_blinks.png")
    try:
        visualize_ela_with_blinks(ela_signal, blinks, vis_path)
    except Exception as e:
        print(f"[WARN] {prefix} - ç»˜åˆ¶ ELA æ›²çº¿å›¾å¤±è´¥: {e}")

    # 5. å¯è§†åŒ–ï¼šçœ¨çœ¼æ€»ç»“å›¾ï¼ˆç›´æ–¹å›¾ / ç®±çº¿å›¾ç­‰ï¼‰
    summary_path = os.path.join(output_dir, f"{prefix}_blink_summary.png")
    try:
        create_blink_summary_figure(blinks, ela_signal.fps, summary_path)
    except Exception as e:
        print(f"[WARN] {prefix} - ç»˜åˆ¶æ€»ç»“å›¾å¤±è´¥: {e}")

    # 6. JSON ç»“æœ
    result = {
        "video_path": video_path,
        "examination_id": examination_id,
        "patient_id": patient_id,
        "action_name": action_name,
        "start_frame": int(start_frame),
        "end_frame": None if end_frame is None else int(end_frame),
        "fps": float(ela_signal.fps),
        "num_frames": int(len(ela_signal.filtered)),
        "num_blinks": int(stats["num_blinks"]),
        "duration_sec": float(stats["duration_sec"]),
        "blink_rate_per_minute": float(stats["blink_rate_per_minute"]),
        "blink_stats": stats,
        "blinks": [asdict(b) for b in blinks],
    }

    # è½¬æ¢æ‰€æœ‰ numpy ç±»å‹ä¸º Python åŸç”Ÿç±»å‹
    result = convert_numpy_types(result)

    json_path = os.path.join(output_dir, f"{prefix}_blinks.json")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"[OK] {prefix} - çœ¨çœ¼æ•°: {stats['num_blinks']}, é¢‘ç‡: {stats['blink_rate_per_minute']:.2f} æ¬¡/åˆ†é’Ÿ")
    print(f"     JSON: {json_path}")
    print(f"     å›¾åƒ: {vis_path}")
    print(f"           {summary_path}")

    return result


def load_videos_from_database(
        db_path: str,
        action_filter: Optional[List[str]] = None,
        limit: Optional[int] = None
) -> List[Dict]:
    """
    ä» facialPalsy.db ä¸­è¯»å–éœ€è¦åšçœ¨çœ¼åˆ†æçš„è§†é¢‘åˆ—è¡¨ã€‚

    å…³è”çš„è¡¨ï¼š
        - video_files       (è§†é¢‘è·¯å¾„ã€å¸§èŒƒå›´ã€fps ç­‰)
        - examinations      (patient_id)
        - action_types      (action_name_en)

    å‚æ•°:
        action_filter: åªå¤„ç†æŸäº›åŠ¨ä½œï¼Œä¾‹å¦‚ ["SpontaneousEyeBlink", "VoluntaryEyeBlink"]
        limit        : ä»…å–å‰ N ä¸ªæ ·æœ¬ï¼Œç”¨äºè°ƒè¯•

    è¿”å›:
        æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ª dictï¼ŒåŒ…å«ï¼š
            {
                "examination_id", "patient_id",
                "action_name", "file_path",
                "start_frame", "end_frame", "fps"
            }
    """
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    base_sql = """
        SELECT
            vf.examination_id,
            e.patient_id,
            at.action_name_en,
            vf.file_path,
            vf.start_frame,
            vf.end_frame,
            vf.fps
        FROM video_files AS vf
        LEFT JOIN examinations AS e ON vf.examination_id = e.examination_id
        LEFT JOIN action_types AS at ON vf.action_id = at.action_id
        WHERE vf.file_exists = 1
    """

    params: List = []

    if action_filter:
        placeholders = ",".join("?" for _ in action_filter)
        base_sql += f" AND at.action_name_en IN ({placeholders})"
        params.extend(action_filter)

    base_sql += " ORDER BY vf.examination_id"

    cursor.execute(base_sql, params)
    rows = cursor.fetchall()
    conn.close()

    if limit is not None:
        rows = rows[:limit]

    videos: List[Dict] = []
    for (exam_id, patient_id, action_name,
         file_path, start_frame, end_frame, fps) in rows:

        videos.append({
            "examination_id": str(exam_id) if exam_id is not None else "exam_id",
            "patient_id": str(patient_id) if patient_id is not None else "UNKNOWN",
            "action_name": str(action_name) if action_name is not None else "UnknownAction",
            "file_path": file_path,
            "start_frame": 0 if start_frame is None else int(start_frame),
            "end_frame": None if end_frame is None else int(end_frame),
            "fps": None if fps is None else float(fps),
        })

    return videos


def _worker_process_one(args: Dict) -> Dict:
    """
    å¤šè¿›ç¨‹ workerï¼šå¤„ç†å•ä¸ªè§†é¢‘ï¼Œå¹¶åŒ…è£…å¼‚å¸¸ã€‚
    """
    try:
        result = analyze_video_blinks(
            video_path=args["file_path"],
            model_path=args["model_path"],
            output_dir=args["output_dir"],
            patient_id=args["patient_id"],
            action_name=args["action_name"],
            examination_id=args["examination_id"],
            start_frame=args["start_frame"],
            end_frame=args["end_frame"],
            fps=args["fps"],
        )
        return {
            "success": result is not None,
            "error": None,
            "meta": args,
            "result": result,
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "meta": args,
            "result": None,
        }


def batch_process_database(
        db_path: str,
        model_path: str,
        output_dir: str,
        action_filter: Optional[List[str]] = None,
        limit: Optional[int] = None,
        use_multiprocessing: bool = True,
        num_workers: Optional[int] = None,
):
    """
    ä»æ•°æ®åº“ä¸­æ‰¹é‡è¯»å–è§†é¢‘ï¼Œåšçœ¨çœ¼æ£€æµ‹ + å¯è§†åŒ–ã€‚

    å‚æ•°ï¼š
        db_path          : facialPalsy.db çš„è·¯å¾„
        model_path       : MediaPipe face_landmarker.task æ¨¡å‹è·¯å¾„
        output_dir       : æ‰€æœ‰ç»“æœï¼ˆjson + pngï¼‰çš„è¾“å‡ºç›®å½•
        action_filter    : æŒ‡å®šåªå¤„ç†å“ªäº›åŠ¨ä½œ
        limit            : ä»…å¤„ç†å‰ N ä¸ªæ ·æœ¬ï¼ˆè°ƒè¯•ç”¨ï¼‰
        use_multiprocessing: æ˜¯å¦å¯ç”¨å¤šè¿›ç¨‹
        num_workers      : è¿›ç¨‹æ•°ï¼ˆNone=è‡ªåŠ¨=CPU æ ¸æ•°ï¼‰
    """
    os.makedirs(output_dir, exist_ok=True)

    print("============================================================")
    print("æ‰¹é‡çœ¨çœ¼åˆ†æ - ä»æ•°æ®åº“åŠ è½½è§†é¢‘")
    print("============================================================")
    print(f"æ•°æ®åº“: {db_path}")
    print(f"æ¨¡å‹   : {model_path}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")

    if action_filter:
        print(f"åŠ¨ä½œè¿‡æ»¤: {action_filter}")
    if limit is not None:
        print(f"æ ·æœ¬ä¸Šé™: {limit}")

    videos = load_videos_from_database(db_path, action_filter=action_filter, limit=limit)
    if not videos:
        print("[WARN] æ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è§†é¢‘ã€‚")
        return

    print(f"[INFO] å…± {len(videos)} ä¸ªè§†é¢‘å¾…å¤„ç†ã€‚")

    # ç»™æ¯ä¸ª task å¡«å……æ¨¡å‹è·¯å¾„å’Œè¾“å‡ºç›®å½•
    tasks: List[Dict] = []
    for v in videos:
        one = dict(v)
        one["model_path"] = model_path
        one["output_dir"] = output_dir
        tasks.append(one)

    results_summary = []

    if use_multiprocessing:
        if num_workers is None or num_workers <= 0:
            # ä¸æŒ‡å®šçš„è¯ï¼Œé»˜è®¤ç”¨ CPU é€»è¾‘æ ¸æ•°
            try:
                import multiprocessing
                num_workers = multiprocessing.cpu_count()
            except Exception:
                num_workers = 4

        print(f"[INFO] å¯ç”¨å¤šè¿›ç¨‹ï¼Œè¿›ç¨‹æ•°: {num_workers}")

        with ProcessPoolExecutor(max_workers=num_workers) as executor:
            future_to_task = {
                executor.submit(_worker_process_one, t): t for t in tasks
            }

            for idx, future in enumerate(as_completed(future_to_task), start=1):
                t = future_to_task[future]
                meta = {
                    "examination_id": t["examination_id"],
                    "patient_id": t["patient_id"],
                    "action_name": t["action_name"],
                }
                try:
                    out = future.result()
                except Exception as e:
                    print(f"[ERROR] è§†é¢‘ {meta} å¤„ç†å¤±è´¥ï¼ˆfuture å¼‚å¸¸ï¼‰: {e}")
                    results_summary.append({
                        **meta,
                        "success": False,
                        "error": str(e),
                    })
                    continue

                if out["success"]:
                    r = out["result"]
                    print(f"[{idx}/{len(tasks)}] OK - {meta}")
                    results_summary.append({
                        **meta,
                        "success": True,
                        "num_blinks": r["num_blinks"],
                        "blink_rate_per_minute": r["blink_rate_per_minute"],
                    })
                else:
                    print(f"[{idx}/{len(tasks)}] FAIL - {meta} - {out['error']}")
                    results_summary.append({
                        **meta,
                        "success": False,
                        "error": out["error"],
                    })

    else:
        print("[INFO] ä½¿ç”¨å•è¿›ç¨‹é¡ºåºå¤„ç†ï¼ˆè°ƒè¯•æˆ–æ’æŸ¥é”™è¯¯æ—¶ä½¿ç”¨ï¼‰ã€‚")
        for idx, t in enumerate(tasks, start=1):
            meta = {
                "examination_id": t["examination_id"],
                "patient_id": t["patient_id"],
                "action_name": t["action_name"],
            }
            try:
                out = _worker_process_one(t)
            except Exception as e:
                print(f"[ERROR] è§†é¢‘ {meta} å¤„ç†å¤±è´¥ï¼ˆç›´æ¥å¼‚å¸¸ï¼‰: {e}")
                results_summary.append({
                    **meta,
                    "success": False,
                    "error": str(e),
                })
                continue

            if out["success"]:
                r = out["result"]
                print(f"[{idx}/{len(tasks)}] OK - {meta}")
                results_summary.append({
                    **meta,
                    "success": True,
                    "num_blinks": r["num_blinks"],
                    "blink_rate_per_minute": r["blink_rate_per_minute"],
                })
            else:
                print(f"[{idx}/{len(tasks)}] FAIL - {meta} - {out['error']}")
                results_summary.append({
                    **meta,
                    "success": False,
                    "error": out["error"],
                })

    # å†™ä¸€ä¸ªæ•´ä½“ summary
    summary_path = os.path.join(output_dir, "z_blink_batch_summary.json")
    with open(summary_path, "w", encoding="utf-8") as f:
        json.dump(results_summary, f, ensure_ascii=False, indent=2)

    print("============================================================")
    print(f"æ‰¹é‡çœ¨çœ¼åˆ†æå®Œæˆï¼Œsummary å†™å…¥: {summary_path}")
    print("============================================================")


if __name__ == "__main__":
    DB_PATH = "/Users/cuijinglei/PycharmProjects/medicalProject/facialPalsy/facialPalsy.db"
    MODEL_PATH = "/Users/cuijinglei/PycharmProjects/medicalProject/models/face_landmarker.task"
    OUTPUT_DIR = "/Users/cuijinglei/Documents/facialPalsy/HGFA/eyelid_blink_analysis"

    # åªåˆ†æçœ¨çœ¼ç›¸å…³åŠ¨ä½œï¼ˆå¯ä»¥æŒ‰éœ€ä¿®æ”¹æˆ–æ‰©å±•ï¼‰
    ACTION_FILTER = None

    LIMIT = None

    batch_process_database(
        db_path=DB_PATH,
        model_path=MODEL_PATH,
        output_dir=OUTPUT_DIR,
        action_filter=ACTION_FILTER,
        limit=LIMIT,
        use_multiprocessing=True,
        num_workers=8,
    )