# -*- coding: utf-8 -*-
"""
Eyelid Angle (ELA) Based Blink Detector
åŸºäºçœ¼ç‘è§’åº¦çš„çœ¨çœ¼æ£€æµ‹ç³»ç»Ÿ

å‚è€ƒè®ºæ–‡: Blinking Beyond EAR: A Stable Eyelid Angle Metric
æ ¸å¿ƒåŠŸèƒ½:
1. ELAè®¡ç®— - åŸºäº3D landmarksçš„çœ¼ç‘è§’åº¦
2. çœ¨çœ¼æ£€æµ‹ - ä½¿ç”¨k-meansèšç±»
3. ç‰¹å¾æå– - closing/closed/reopening durationsç­‰
4. å¯è§†åŒ– - ELAæ—¶åºå›¾+çœ¨çœ¼é˜¶æ®µæ ‡æ³¨
"""

import os
import re
import json
import sqlite3
from pathlib import Path
from dataclasses import dataclass, asdict
from typing import List, Tuple, Dict, Optional

import numpy as np
import cv2

import matplotlib
matplotlib.use("Agg")  # å¤šè¿›ç¨‹ + æ— ç•Œé¢ç¯å¢ƒä¸‹å®‰å…¨ç»˜å›¾
import matplotlib.pyplot as plt

from scipy.ndimage import gaussian_filter1d
from scipy.signal import find_peaks
from sklearn.cluster import KMeans

import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision

from concurrent.futures import ProcessPoolExecutor, as_completed


# ==================== JSON åºåˆ—åŒ–è¾…åŠ©å‡½æ•° ====================

def convert_numpy_types(obj):
    """
    é€’å½’è½¬æ¢ numpy ç±»å‹ä¸º Python åŸç”Ÿç±»å‹ï¼Œç”¨äº JSON åºåˆ—åŒ–
    """
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [convert_numpy_types(item) for item in obj]
    else:
        return obj



# ==================== Opennessï¼ˆçœ¼ç›å¼€åˆåº¦ï¼‰å‚æ•°ï¼ˆæ¨èï¼‰ ====================
# Openness è®¡ç®—ï¼šä¸Š/ä¸‹çœ¼ç‘â€œå‚ç›´è·ç¦»â€ / â€œçœ¼è£‚å®½åº¦â€ï¼Œå†åšä¸ªä½“è‡ªé€‚åº”å½’ä¸€åŒ–åˆ° 0~1
OPENNESS_SMOOTH_SIGMA_SEC = 0.02       # å¹³æ»‘çª—å£ï¼ˆç§’ï¼‰ï¼š20ms å·¦å³
OPENNESS_NORM_P_OPEN = 95             # è®¤ä¸ºâ€œæœ€çå¼€â€çš„åˆ†ä½æ•°
OPENNESS_NORM_P_CLOSED = 5            # è®¤ä¸ºâ€œæœ€é—­åˆâ€çš„åˆ†ä½æ•°

# çœ¨çœ¼æ£€æµ‹ï¼ˆåŸºäº closure = 1 - opennessï¼‰
BLINK_MIN_DURATION_SEC = 0.05
BLINK_MAX_DURATION_SEC = 0.80
BLINK_MIN_DISTANCE_SEC = 0.08         # ä¸¤æ¬¡çœ¨çœ¼æœ€å°é—´éš”ï¼ˆç§’ï¼‰
BLINK_PROMINENCE = 0.10               # å³°å€¼æ˜¾è‘—æ€§ï¼ˆè¶Šå¤§è¶Šä¸¥æ ¼ï¼‰
BLINK_CROSS_LEVEL = 0.15              # ç”¨äºæ‰¾ start/end çš„é˜ˆå€¼ï¼ˆclosureï¼‰
BLINK_CLOSED_LEVEL = 0.65             # åˆ¤æ–­â€œå®Œå…¨é—­åˆ/é—­åˆä¿æŒâ€çš„é˜ˆå€¼ï¼ˆclosureï¼‰

# å·¦å³çœ¼åŒæ­¥åˆ¤å®šï¼šä¸¤çœ¼çœ¨çœ¼æœ€å°ç‚¹ï¼ˆmin_idxï¼‰æ—¶é—´å·®é˜ˆå€¼
MAX_LR_PAIR_DELTA_SEC = 0.15

# ==================== MediaPipe FaceLandmarker ç¼“å­˜ï¼ˆæ¯è¿›ç¨‹ä¸€æ¬¡ï¼‰ ====================

_FACE_LANDMARKER_CACHE = {}
# VIDEO æ¨¡å¼ä¸‹ï¼Œdetect_for_video() è¦æ±‚ timestamp_ms åœ¨åŒä¸€ detector ç”Ÿå‘½å‘¨æœŸå†…ä¸¥æ ¼é€’å¢ã€‚
# ä¸ºäº†åœ¨ä¸€ä¸ªè¿›ç¨‹é‡Œå¤ç”¨ detectorï¼ˆåŠ é€Ÿï¼‰ä¸”è·¨è§†é¢‘ä¸æŠ¥é”™ï¼Œæˆ‘ä»¬ä¸ºæ¯ä¸ª model_path ç»´æŠ¤å…¨å±€æ—¶é—´æˆ³ã€‚
_FACE_LANDMARKER_LAST_TS_MS: Dict[str, int] = {}

def get_face_landmarker(model_path: str):
    """è·å– FaceLandmarkerï¼ˆVIDEO æ¨¡å¼ï¼‰ï¼Œå¹¶åšè¿›ç¨‹å†…ç¼“å­˜ã€‚"""
    global _FACE_LANDMARKER_CACHE
    if model_path in _FACE_LANDMARKER_CACHE:
        return _FACE_LANDMARKER_CACHE[model_path]

    base_options = python.BaseOptions(model_asset_path=model_path)
    options = vision.FaceLandmarkerOptions(
        base_options=base_options,
        running_mode=vision.RunningMode.VIDEO,
        num_faces=1,
        output_face_blendshapes=False,
        output_facial_transformation_matrixes=False,
    )
    detector = vision.FaceLandmarker.create_from_options(options)
    _FACE_LANDMARKER_CACHE[model_path] = detector
    return detector


def _interp_nan_1d(arr: np.ndarray) -> np.ndarray:
    """çº¿æ€§æ’å€¼å¡«å…… 1D æ•°ç»„ä¸­çš„ NaNã€‚"""
    arr = np.asarray(arr, dtype=np.float32)
    if arr.size == 0:
        return arr
    if not np.any(np.isnan(arr)):
        return arr
    x = np.arange(arr.size)
    mask = ~np.isnan(arr)
    if mask.sum() < 2:
        # å¤ªå°‘æœ‰æ•ˆç‚¹ï¼šå…¨éƒ¨ç”¨ 0
        return np.nan_to_num(arr, nan=0.0)
    arr2 = arr.copy()
    arr2[~mask] = np.interp(x[~mask], x[mask], arr[mask])
    return arr2


def _smooth_signal(arr: np.ndarray, fps: float, sigma_sec: float = OPENNESS_SMOOTH_SIGMA_SEC) -> np.ndarray:
    """æŒ‰â€œç§’â€å°ºåº¦åšé«˜æ–¯å¹³æ»‘ï¼ˆæ›´ç¬¦åˆä¸åŒ FPS çš„ä¸€è‡´æ€§ï¼‰ã€‚"""
    arr = np.asarray(arr, dtype=np.float32)
    if arr.size < 3:
        return arr
    sigma = max(0.5, float(sigma_sec) * float(fps))  # sigma=æ ·æœ¬æ•°
    return gaussian_filter1d(arr, sigma=sigma, mode="nearest")


def _normalize_openness_by_percentiles(raw: np.ndarray,
                                      p_open: float = OPENNESS_NORM_P_OPEN,
                                      p_closed: float = OPENNESS_NORM_P_CLOSED) -> np.ndarray:
    """æŠŠ openness ratio åšä¸ªä½“è‡ªé€‚åº”å½’ä¸€åŒ–åˆ° 0~1ã€‚"""
    raw = np.asarray(raw, dtype=np.float32)
    raw = _interp_nan_1d(raw)
    if raw.size == 0:
        return raw
    hi = float(np.nanpercentile(raw, p_open))
    lo = float(np.nanpercentile(raw, p_closed))
    denom = hi - lo
    if denom < 1e-6:
        # æç«¯æƒ…å†µï¼šå‡ ä¹ä¸å˜
        base = hi if abs(hi) > 1e-6 else 1.0
        norm = raw / base
    else:
        norm = (raw - lo) / denom
    return np.clip(norm, 0.0, 1.2).astype(np.float32)

matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'PingFang SC']
matplotlib.rcParams['axes.unicode_minus'] = False

# ==================== MediaPipe çœ¼ç‘Landmarkç´¢å¼• ====================

# å·¦çœ¼ä¸Šçœ¼ç‘çš„7ä¸ªç‚¹ï¼ˆä»å†…çœ¼è§’åˆ°å¤–çœ¼è§’ï¼‰
LEFT_EYE_UPPER = [398, 384, 385, 386, 387, 388, 466]

# å·¦çœ¼ä¸‹çœ¼ç‘çš„7ä¸ªç‚¹ï¼ˆä»å†…çœ¼è§’åˆ°å¤–çœ¼è§’ï¼‰
LEFT_EYE_LOWER = [382, 381, 380, 374, 373, 390, 249]

# å³çœ¼ä¸Šçœ¼ç‘çš„7ä¸ªç‚¹ï¼ˆä»å†…çœ¼è§’åˆ°å¤–çœ¼è§’ï¼‰
RIGHT_EYE_UPPER = [173, 157, 158, 159, 160, 161, 246]
# å³çœ¼ä¸‹çœ¼ç‘çš„7ä¸ªç‚¹ï¼ˆä»å†…çœ¼è§’åˆ°å¤–çœ¼è§’ï¼‰
RIGHT_EYE_LOWER = [155, 154, 153, 145, 144, 163, 7]

# çœ¼å†…çœ¦ç´¢å¼•ï¼ˆç”¨äºå½’ä¸€åŒ–ï¼‰
LEFT_INNER_CANTHUS = 362
RIGHT_INNER_CANTHUS = 133


# ==================== æ•°æ®ç»“æ„ ====================

@dataclass
class BlinkEvent:
    """å•æ¬¡çœ¨çœ¼äº‹ä»¶"""
    start_idx: int  # çœ¨çœ¼å¼€å§‹å¸§ç´¢å¼•
    end_idx: int  # çœ¨çœ¼ç»“æŸå¸§ç´¢å¼•
    min_idx: int  # ELAæœ€å°å€¼å¸§ç´¢å¼•

    # æ—¶é—´ç‰¹å¾
    closing_duration: float  # é—­çœ¼æŒç»­æ—¶é—´(ç§’)
    closed_duration: float  # é—­åˆæŒç»­æ—¶é—´(ç§’)
    reopening_duration: float  # ççœ¼æŒç»­æ—¶é—´(ç§’)

    # å¹…åº¦ç‰¹å¾
    amplitude: float  # ç›¸å¯¹å¹…åº¦
    ela_start: float  # èµ·å§‹ELA
    ela_min: float  # æœ€å°ELA
    ela_end: float  # ç»“æŸELA

    # é€Ÿåº¦ç‰¹å¾
    max_closing_velocity: float  # æœ€å¤§é—­çœ¼é€Ÿåº¦
    max_reopening_velocity: float  # æœ€å¤§ççœ¼é€Ÿåº¦
    amplitude_velocity_ratio: float  # å¹…åº¦/é€Ÿåº¦æ¯”

    # å…¶ä»–ç‰¹å¾
    previous_time: Optional[float] = None  # è·ä¸Šæ¬¡çœ¨çœ¼æ—¶é—´
    normal_area: Optional[float] = None  # å½’ä¸€åŒ–é¢ç§¯

    @property
    def duration(self) -> float:
        """è®¡ç®—çœ¨çœ¼æ€»æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰= closing + closed + reopening"""
        return self.closing_duration + self.closed_duration + self.reopening_duration


@dataclass
class ELASignal:
    """çœ¼éƒ¨æ—¶åºä¿¡å·æ•°æ®ï¼ˆæ¨èä½¿ç”¨ Opennessï¼šçœ¼ç›å¼€åˆåº¦ï¼‰

    - Opennessï¼š0~1ï¼Œæ•°å€¼è¶Šå¤§è¡¨ç¤ºè¶Šâ€œçå¼€â€ï¼Œè¶Šå°è¡¨ç¤ºè¶Šâ€œé—­åˆâ€
    - æœ¬æ–‡ä»¶ä¸ºäº†å…¼å®¹æ—§ä»£ç ï¼Œä»ä¿ç•™ left_ela/right_ela å­—æ®µï¼ˆåªæœ‰ compute_ela=True æ‰ä¼šç”Ÿæˆï¼‰
    """
    raw: np.ndarray  # ä¸»ä¿¡å·ï¼ˆé»˜è®¤=å·¦å³ Openness çš„å¹³å‡ï¼‰
    filtered: np.ndarray  # å¹³æ»‘åçš„ä¸»ä¿¡å·
    derivative: np.ndarray  # ä¸»ä¿¡å·å¯¼æ•°ï¼ˆæ¯å¸§å·®åˆ†ï¼‰
    fps: float  # å¸§ç‡
    timestamps: np.ndarray  # æ—¶é—´æˆ³ï¼ˆç§’ï¼‰

    # æ—§å­—æ®µï¼ˆå…¼å®¹ï¼‰ï¼šå·¦å³çœ¼åˆ†åˆ«çš„ ELAï¼ˆå¯é€‰ï¼‰
    left_ela: Optional[np.ndarray] = None
    right_ela: Optional[np.ndarray] = None

    # æ–°å¢ï¼šå·¦å³çœ¼ Opennessï¼ˆæ›´ç›´è§‚ã€æ›´ç¨³å®šï¼‰
    left_openness_raw: Optional[np.ndarray] = None   # åŸå§‹ ratioï¼ˆæœªå½’ä¸€åŒ–ï¼‰
    right_openness_raw: Optional[np.ndarray] = None
    left_openness: Optional[np.ndarray] = None       # 0~1ï¼ˆä¸ªä½“è‡ªé€‚åº”å½’ä¸€åŒ–ï¼‰
    right_openness: Optional[np.ndarray] = None


# ==================== ELAè®¡ç®—æ ¸å¿ƒå‡½æ•° ====================

def normalize_z_coordinate(z_raw: float, transform_matrix: np.ndarray) -> float:
    """
    å½’ä¸€åŒ–Zåæ ‡ï¼ˆè®ºæ–‡å…¬å¼1ï¼‰

    Args:
        z_raw: MediaPipeåŸå§‹zåæ ‡
        transform_matrix: MediaPipeçš„å˜æ¢çŸ©é˜µ

    Returns:
        å½’ä¸€åŒ–åçš„zåæ ‡
    """
    if transform_matrix is not None and transform_matrix.shape[0] > 2:
        return 1.7 * z_raw * transform_matrix[2, 2]
    return z_raw


def fit_plane_to_landmarks(landmarks_3d: np.ndarray) -> np.ndarray:
    """
    å¯¹3D landmarksæ‹Ÿåˆå¹³é¢ï¼Œè¿”å›æ³•å‘é‡

    ä½¿ç”¨SVDæ–¹æ³•æ‹Ÿåˆå¹³é¢ï¼š
    1. ä¸­å¿ƒåŒ–æ•°æ®
    2. SVDåˆ†è§£
    3. æœ€å°å¥‡å¼‚å€¼å¯¹åº”çš„å‘é‡å³ä¸ºæ³•å‘é‡

    Args:
        landmarks_3d: [N, 3] Nä¸ª3D landmarks

    Returns:
        [3,] å•ä½æ³•å‘é‡
    """
    # ä¸­å¿ƒåŒ–
    centroid = np.mean(landmarks_3d, axis=0)
    centered = landmarks_3d - centroid

    # SVDåˆ†è§£
    U, S, Vt = np.linalg.svd(centered.T, full_matrices=False)

    # æ³•å‘é‡æ˜¯æœ€å°å¥‡å¼‚å€¼å¯¹åº”çš„å‘é‡
    normal = U[:, -1]

    # æ ‡å‡†åŒ–æ–¹å‘ï¼šä½¿ç”¨cross productåˆ¤æ–­
    # ç¡®ä¿æ³•å‘é‡æ–¹å‘ä¸€è‡´ï¼ˆä»å†…çœ¼è§’æŒ‡å‘å¤–çœ¼è§’ï¼‰
    if len(centered) > 1:
        direction_vec = centered[1] - centered[0]
        cross_prod = np.cross(direction_vec, normal)
        if np.dot(normal, cross_prod) < 0:
            normal = -normal

    return normal / (np.linalg.norm(normal) + 1e-8)


def calculate_ela_for_eye(
        upper_landmarks: np.ndarray,
        lower_landmarks: np.ndarray
) -> float:
    """
    è®¡ç®—å•çœ¼çš„ELAï¼ˆçœ¼ç‘è§’åº¦ï¼‰

    Args:
        upper_landmarks: [7, 3] ä¸Šçœ¼ç‘çš„7ä¸ª3Dç‚¹
        lower_landmarks: [7, 3] ä¸‹çœ¼ç‘çš„7ä¸ª3Dç‚¹

    Returns:
        ELAè§’åº¦ï¼ˆåº¦æ•°ï¼‰
    """
    # æ‹Ÿåˆä¸Šä¸‹çœ¼ç‘å¹³é¢
    normal_upper = fit_plane_to_landmarks(upper_landmarks)
    normal_lower = fit_plane_to_landmarks(lower_landmarks)

    # è®¡ç®—ä¸¤ä¸ªå¹³é¢æ³•å‘é‡çš„å¤¹è§’ï¼ˆè®ºæ–‡å…¬å¼2ï¼‰
    cos_angle = np.clip(np.dot(normal_upper, normal_lower), -1.0, 1.0)
    angle_rad = np.arccos(cos_angle)
    angle_deg = np.degrees(angle_rad)

    return angle_deg


def get_unit_length(landmarks, image_width: int, image_height: int) -> float:
    """
    è·å–å½’ä¸€åŒ–å•ä½é•¿åº¦ï¼ˆåŒä¾§çœ¼å†…çœ¦è·ç¦»ï¼‰

    Args:
        landmarks: MediaPipe 478ä¸ªlandmarks
        image_width: å›¾åƒå®½åº¦
        image_height: å›¾åƒé«˜åº¦

    Returns:
        å•ä½é•¿åº¦ï¼ˆåƒç´ ï¼‰
    """
    left_canthus = landmarks[LEFT_INNER_CANTHUS]
    right_canthus = landmarks[RIGHT_INNER_CANTHUS]

    left_x = left_canthus.x * image_width
    left_y = left_canthus.y * image_height
    right_x = right_canthus.x * image_width
    right_y = right_canthus.y * image_height

    distance = np.sqrt((right_x - left_x) ** 2 + (right_y - left_y) ** 2)
    return distance


def extract_3d_landmarks(
        landmarks,
        indices: List[int],
        image_width: int,
        image_height: int,
        aspect_ratio: float = 1.0
) -> np.ndarray:
    """
    æå–æŒ‡å®šç´¢å¼•çš„3D landmarks

    Args:
        landmarks: MediaPipeæ£€æµ‹åˆ°çš„478ä¸ªlandmarks
        indices: è¦æå–çš„landmarkç´¢å¼•åˆ—è¡¨
        image_width: å›¾åƒå®½åº¦
        image_height: å›¾åƒé«˜åº¦
        aspect_ratio: å›¾åƒå®½é«˜æ¯”

    Returns:
        [N, 3] 3Dåæ ‡æ•°ç»„
    """
    coords = []
    for idx in indices:
        lm = landmarks[idx]
        x = lm.x * image_width
        y = lm.y * image_height / aspect_ratio  # Yåæ ‡å½’ä¸€åŒ–
        z = lm.z * image_width  # Zåæ ‡ç¼©æ”¾ï¼ˆè®ºæ–‡çš„å¯å‘å¼æ–¹æ³•ï¼‰
        coords.append([x, y, z])

    return np.array(coords, dtype=np.float32)


def extract_2d_landmarks(
        landmarks,
        indices: List[int],
        image_width: int,
        image_height: int,
        aspect_ratio: float = 1.0
) -> np.ndarray:
    """
    æå–æŒ‡å®šç´¢å¼•çš„2D landmarksï¼ˆåƒç´ åæ ‡ï¼‰

    Returns:
        [N, 2] 2Dåæ ‡æ•°ç»„
    """
    coords = []
    for idx in indices:
        lm = landmarks[idx]
        x = lm.x * image_width
        y = lm.y * image_height / aspect_ratio
        coords.append([x, y])
    return np.array(coords, dtype=np.float32)


def calculate_eye_openness_ratio(upper_xy: np.ndarray, lower_xy: np.ndarray) -> float:
    """è®¡ç®—å•çœ¼ Openness ratioï¼ˆæ›´ç›´è§‚çš„å¼€åˆåº¦ï¼‰ã€‚

    æ€è·¯ï¼ˆæ˜“è§£é‡Šï¼‰ï¼š
    - å–å¤šå¯¹â€œä¸Šçœ¼ç‘ç‚¹ - ä¸‹çœ¼ç‘ç‚¹â€çš„è·ç¦»ï¼Œæ±‚å¹³å‡ï¼šä»£è¡¨â€œçœ¼ç›ç«–å‘å¼ å¼€ç¨‹åº¦â€
    - å†é™¤ä»¥â€œçœ¼è£‚å®½åº¦â€ï¼ˆçœ¼è§’åˆ°çœ¼è§’çš„è·ç¦»ï¼Œè¿‘ä¼¼ç”¨çœ¼ç‘ç‚¹åºåˆ—ä¸¤ç«¯è·ç¦»ï¼‰ï¼šåšå°ºåº¦å½’ä¸€åŒ–

    è¿”å›ï¼š
        openness_ratioï¼ˆæœªå½’ä¸€åŒ–åˆ° 0~1ï¼Œéšäºº/é•œå¤´ç•¥å˜ï¼Œä½†ç¨³å®šã€å¯æ¯”è¾ƒï¼‰
    """
    upper_xy = np.asarray(upper_xy, dtype=np.float32)
    lower_xy = np.asarray(lower_xy, dtype=np.float32)
    if upper_xy.shape != lower_xy.shape or upper_xy.ndim != 2 or upper_xy.shape[1] != 2:
        return float("nan")

    # å‚ç›´å¼ å¼€ï¼šå¤šå¯¹ä¸Š/ä¸‹ç‚¹çš„è·ç¦»å¹³å‡
    vertical = np.linalg.norm(upper_xy - lower_xy, axis=1)
    v_mean = float(np.mean(vertical))

    # çœ¼è£‚å®½åº¦ï¼šç”¨åºåˆ—ä¸¤ç«¯è¿‘ä¼¼ï¼ˆå†…å¤–çœ¼è§’æ–¹å‘ï¼‰
    w1 = float(np.linalg.norm(upper_xy[0] - upper_xy[-1]))
    w2 = float(np.linalg.norm(lower_xy[0] - lower_xy[-1]))
    width = 0.5 * (w1 + w2)
    if width < 1e-6:
        return float("nan")

    return v_mean / width


def calculate_combined_ela(
        left_ela: float,
        right_ela: float,
        yaw_angle: float
) -> float:
    """
    ç»“åˆå·¦å³çœ¼ELAï¼Œè€ƒè™‘å¤´éƒ¨yawæ—‹è½¬ï¼ˆè®ºæ–‡å…¬å¼3ï¼‰

    ä½¿ç”¨sigmoidæƒé‡ï¼š
    - å¤´éƒ¨å·¦è½¬æ—¶ï¼Œå³çœ¼æƒé‡å¢åŠ 
    - å¤´éƒ¨å³è½¬æ—¶ï¼Œå·¦çœ¼æƒé‡å¢åŠ 

    Args:
        left_ela: å·¦çœ¼ELA
        right_ela: å³çœ¼ELA
        yaw_angle: å¤´éƒ¨yawè§’åº¦ï¼ˆå¼§åº¦ï¼‰

    Returns:
        ç»„åˆåçš„ELA
    """

    def sigmoid(x):
        return 1.0 / (1.0 + np.exp(-x))

    # è®ºæ–‡ä¸­çš„ç¼©æ”¾å› å­
    weight_left = sigmoid(-4 * yaw_angle)
    weight_right = sigmoid(4 * yaw_angle)

    combined = weight_left * left_ela + weight_right * right_ela
    return combined


# ==================== ELAä¿¡å·å¤„ç† ====================

def smooth_ela_signal(ela_raw: np.ndarray, fps: float) -> np.ndarray:
    """
    ä½¿ç”¨é«˜æ–¯æ»¤æ³¢å¹³æ»‘ELAä¿¡å·ï¼ˆè®ºæ–‡å…¬å¼4-5ï¼‰

    æ ‡å‡†å·®ä¸å¸§ç‡æˆæ­£æ¯”ï¼šÏƒ = FPS/30

    Args:
        ela_raw: åŸå§‹ELAä¿¡å·
        fps: è§†é¢‘å¸§ç‡

    Returns:
        å¹³æ»‘åçš„ELAä¿¡å·
    """
    sigma = fps / 30.0  # è®ºæ–‡çš„å…¬å¼
    ela_filtered = gaussian_filter1d(ela_raw, sigma=sigma)
    return ela_filtered


def compute_derivative(signal: np.ndarray) -> np.ndarray:
    """
    è®¡ç®—ä¿¡å·çš„å¯¼æ•°ï¼ˆä¸­å¿ƒå·®åˆ†ï¼‰

    Args:
        signal: è¾“å…¥ä¿¡å·

    Returns:
        å¯¼æ•°ä¿¡å·
    """
    derivative = np.zeros_like(signal)

    # ä¸­å¿ƒå·®åˆ†
    derivative[1:-1] = (signal[2:] - signal[:-2]) / 2.0

    # è¾¹ç•Œä½¿ç”¨å‰å‘/åå‘å·®åˆ†
    derivative[0] = signal[1] - signal[0]
    derivative[-1] = signal[-1] - signal[-2]

    return derivative


# ==================== çœ¨çœ¼æ£€æµ‹ ====================

def detect_blinks_kmeans(
        ela_filtered: np.ndarray,
        derivative: np.ndarray,
        fps: float,
        min_blink_duration: float = 0.05,  # æœ€å°çœ¨çœ¼æŒç»­æ—¶é—´(ç§’)
        max_blink_duration: float = 0.8  # æœ€å¤§çœ¨çœ¼æŒç»­æ—¶é—´(ç§’)
) -> List[BlinkEvent]:
    """
    ä½¿ç”¨k-meansèšç±»æ£€æµ‹çœ¨çœ¼äº‹ä»¶ï¼ˆè®ºæ–‡Section III-4ï¼‰

    æ­¥éª¤ï¼š
    1. å¯¹å¯¼æ•°çš„æå€¼ç‚¹è¿›è¡Œk-meansèšç±»ï¼ˆ2ç±»ï¼‰
    2. é…å¯¹ä¸‹é™æ²¿å’Œä¸Šå‡æ²¿
    3. æå–æ—¶é—´ç‰¹å¾

    Args:
        ela_filtered: å¹³æ»‘åçš„ELAä¿¡å·
        derivative: ELAå¯¼æ•°
        fps: å¸§ç‡
        min_blink_duration: æœ€å°çœ¨çœ¼æŒç»­æ—¶é—´
        max_blink_duration: æœ€å¤§çœ¨çœ¼æŒç»­æ—¶é—´

    Returns:
        æ£€æµ‹åˆ°çš„çœ¨çœ¼äº‹ä»¶åˆ—è¡¨
    """
    # 1. æ‰¾åˆ°å¯¼æ•°çš„æå€¼ç‚¹
    neg_peaks, _ = find_peaks(-derivative, height=0)  # è´Ÿå³°ï¼ˆä¸‹é™æ²¿ï¼‰
    pos_peaks, _ = find_peaks(derivative, height=0)  # æ­£å³°ï¼ˆä¸Šå‡æ²¿ï¼‰

    if len(neg_peaks) < 2 or len(pos_peaks) < 2:
        return []

    # 2. K-meansèšç±»ï¼ˆ2ç±»ï¼šå™ªå£° vs çœŸå®çœ¨çœ¼ï¼‰
    neg_values = -derivative[neg_peaks]
    pos_values = derivative[pos_peaks]

    # å¯¹è´Ÿå³°èšç±»
    if len(neg_peaks) >= 2:
        kmeans_neg = KMeans(n_clusters=2, random_state=42, n_init=10)
        labels_neg = kmeans_neg.fit_predict(neg_values.reshape(-1, 1))
        # é€‰æ‹©å¹…åº¦è¾ƒå¤§çš„ç±»ä½œä¸ºçœ¨çœ¼
        cluster_means = [neg_values[labels_neg == i].mean() for i in range(2)]
        blink_cluster_neg = np.argmax(cluster_means)
        blink_neg_peaks = neg_peaks[labels_neg == blink_cluster_neg]
    else:
        blink_neg_peaks = neg_peaks

    # å¯¹æ­£å³°èšç±»
    if len(pos_peaks) >= 2:
        kmeans_pos = KMeans(n_clusters=2, random_state=42, n_init=10)
        labels_pos = kmeans_pos.fit_predict(pos_values.reshape(-1, 1))
        cluster_means = [pos_values[labels_pos == i].mean() for i in range(2)]
        blink_cluster_pos = np.argmax(cluster_means)
        blink_pos_peaks = pos_peaks[labels_pos == blink_cluster_pos]
    else:
        blink_pos_peaks = pos_peaks

    # 3. é…å¯¹ä¸‹é™æ²¿å’Œä¸Šå‡æ²¿
    blinks = []
    for neg_idx in blink_neg_peaks:
        # æ‰¾åˆ°neg_idxä¹‹åæœ€è¿‘çš„pos_idx
        following_pos = blink_pos_peaks[blink_pos_peaks > neg_idx]
        if len(following_pos) == 0:
            continue

        pos_idx = following_pos[0]

        # æ£€æŸ¥çœ¨çœ¼æŒç»­æ—¶é—´
        duration = (pos_idx - neg_idx) / fps
        if duration < min_blink_duration or duration > max_blink_duration:
            continue

        # æ‰¾åˆ°æœ€å°ELAç‚¹
        min_idx = neg_idx + np.argmin(ela_filtered[neg_idx:pos_idx + 1])

        # æå–çœ¨çœ¼ç‰¹å¾
        blink = extract_blink_features(
            ela_filtered, derivative,
            neg_idx, min_idx, pos_idx, fps
        )

        if blink is not None:
            blinks.append(blink)

    # è®¡ç®—ç›¸é‚»çœ¨çœ¼çš„æ—¶é—´é—´éš”
    for i in range(1, len(blinks)):
        blinks[i].previous_time = (blinks[i].start_idx - blinks[i - 1].start_idx) / fps

    return blinks


# ==================== Openness çœ¨çœ¼æ£€æµ‹ï¼ˆæ¨èï¼‰ ====================

def _blink_event_to_dict(blink: "BlinkEvent", eye: str) -> Dict:
    """æŠŠ BlinkEvent è½¬æˆ dictï¼Œå¹¶è¡¥ä¸Š duration + eye å­—æ®µï¼ˆæ›´å®Œæ•´ï¼‰ã€‚"""
    d = asdict(blink)
    d["duration"] = float(blink.duration)
    d["eye"] = eye
    # é¢å¤–è¡¥ä¸€ä¸ªæ›´ç›´è§‚çš„â€œé—­åˆå¹…åº¦ç™¾åˆ†æ¯”â€
    # amplitude = closure_peakï¼ˆ0~1ï¼‰ï¼Œè½¬æ¢æˆç™¾åˆ†æ¯”æ›´å¥½ç†è§£
    d["closure_amplitude_pct"] = float(blink.amplitude * 100.0)
    # åŒæ—¶è¡¥ä¸Šæœ€å° Opennessï¼ˆæ›´ç›´è§‚ï¼‰
    d["min_openness"] = float(blink.ela_min)  # è¿™é‡Œ ela_min å­˜çš„æ˜¯ openness_minï¼ˆè§ä¸‹é¢çš„æ„é€ ï¼‰
    return d


def detect_blinks_openness(
        openness: np.ndarray,
        fps: float,
        min_blink_duration: float = BLINK_MIN_DURATION_SEC,
        max_blink_duration: float = BLINK_MAX_DURATION_SEC,
        min_distance_sec: float = BLINK_MIN_DISTANCE_SEC,
        prominence: float = BLINK_PROMINENCE,
        cross_level: float = BLINK_CROSS_LEVEL,
        closed_level: float = BLINK_CLOSED_LEVEL,
) -> List["BlinkEvent"]:
    """
    åŸºäº Opennessï¼ˆ0~1ï¼‰çš„çœ¨çœ¼æ£€æµ‹ã€‚

    ç›´è§‚è§£é‡Šï¼š
    - openness è¶Šå° -> è¶Šé—­çœ¼
    - closure = 1 - openness è¶Šå¤§ -> è¶Šé—­çœ¼
    - æ‰¾ closure çš„å³°å€¼ï¼ˆå¯¹åº”çœ¨çœ¼æœ€é—­åˆçš„æ—¶åˆ»ï¼‰
    - å†ç”¨é˜ˆå€¼ï¼ˆcross_levelï¼‰å‘å·¦å³æ‰©å±•å¾—åˆ° start/end

    è¿”å›ï¼š
        BlinkEvent åˆ—è¡¨ï¼ˆå…¶ä¸­ï¼š
            - ela_start/ela_min/ela_end å®é™…å­˜çš„æ˜¯ openness_start / openness_min / openness_end
            - amplitude å­˜çš„æ˜¯ closure_peak = (1 - openness_min) ï¼ŒèŒƒå›´ 0~1
        ï¼‰
    """
    openness = np.asarray(openness, dtype=np.float32)
    if openness.size < 5:
        return []

    # å¹³æ»‘ä¸€ä¸‹å†æ£€æµ‹ï¼ˆé¿å…å™ªå£°å³°ï¼‰
    op_s = _smooth_signal(_interp_nan_1d(openness), fps)
    op_s = np.clip(op_s, 0.0, 1.2)

    closure = 1.0 - np.clip(op_s, 0.0, 1.0)  # 0~1
    distance = max(1, int(min_distance_sec * fps))

    peaks, props = find_peaks(closure, prominence=prominence, distance=distance)
    if peaks is None or len(peaks) == 0:
        return []

    # derivative è½¬æˆâ€œæ¯ç§’å˜åŒ–é‡â€ï¼Œæ›´å¥½è§£é‡Šé€Ÿåº¦
    d_op = compute_derivative(op_s) * float(fps)

    blinks: List[BlinkEvent] = []
    for pk in peaks:
        # ä»¥ cross_level æ‰¾ start/end
        if closure[pk] < cross_level:
            continue

        s = pk
        while s > 0 and closure[s] >= cross_level:
            s -= 1
        start_idx = max(0, s)

        e = pk
        n = closure.size
        while e < n - 1 and closure[e] >= cross_level:
            e += 1
        end_idx = min(n - 1, e)

        min_idx = int(pk)

        duration = (end_idx - start_idx) / float(fps)
        if duration < min_blink_duration or duration > max_blink_duration:
            continue

        # åˆ†é˜¶æ®µæ—¶é•¿
        closing_duration = (min_idx - start_idx) / float(fps)
        reopening_duration = (end_idx - min_idx) / float(fps)

        # é—­åˆä¿æŒï¼šclosure >= closed_level çš„ç´¯è®¡æ—¶é—´
        seg = closure[start_idx:end_idx + 1]
        closed_duration = float(np.sum(seg >= closed_level) / float(fps))

        # å…³é”®æ•°å€¼ï¼ˆæ›´ç›´è§‚éƒ½ç”¨ opennessï¼‰
        op_start = float(op_s[start_idx])
        op_min = float(op_s[min_idx])
        op_end = float(op_s[end_idx])

        amplitude = float(1.0 - np.clip(op_min, 0.0, 1.0))  # 0~1 çš„é—­åˆå¹…åº¦

        # é€Ÿåº¦ï¼šclosing ç”¨ -d_op æœ€å¤§å€¼ï¼Œreopening ç”¨ d_op æœ€å¤§å€¼
        max_closing_vel = float(np.max(-d_op[start_idx:min_idx + 1])) if min_idx > start_idx else 0.0
        max_reopening_vel = float(np.max(d_op[min_idx:end_idx + 1])) if end_idx > min_idx else 0.0

        # ä¸€ä¸ªç®€å•æ¯”å€¼ï¼šå¹…åº¦ / é€Ÿåº¦ï¼ˆåªç”¨äºç›¸å¯¹æ¯”è¾ƒï¼Œéå¿…é¡»ï¼‰
        av_ratio = float(amplitude / (max(max_closing_vel, max_reopening_vel, 1e-6)))

        # ç”¨â€œé—­åˆé¢ç§¯â€ï¼ˆclosure æ›²çº¿ä¸‹é¢ç§¯ï¼‰åšä¸€ä¸ªç›´è§‚å¼ºåº¦æŒ‡æ ‡
        normal_area = float(np.trapz(seg, dx=1.0 / float(fps)))

        blink = BlinkEvent(
            start_idx=int(start_idx),
            min_idx=int(min_idx),
            end_idx=int(end_idx),
            closing_duration=float(closing_duration),
            closed_duration=float(closed_duration),
            reopening_duration=float(reopening_duration),
            amplitude=float(amplitude),
            ela_start=float(op_start),
            ela_min=float(op_min),
            ela_end=float(op_end),
            max_closing_velocity=float(max_closing_vel),
            max_reopening_velocity=float(max_reopening_vel),
            amplitude_velocity_ratio=float(av_ratio),
            normal_area=float(normal_area),
        )
        blinks.append(blink)

    # æŒ‰æ—¶é—´æ’åº
    blinks.sort(key=lambda b: b.min_idx)
    return blinks


def pair_left_right_blinks(
        left_blinks: List["BlinkEvent"],
        right_blinks: List["BlinkEvent"],
        fps: float,
        max_delta_sec: float = MAX_LR_PAIR_DELTA_SEC,
) -> Dict:
    """æŠŠå·¦å³çœ¼çœ¨çœ¼æŒ‰â€œæœ€é—­åˆæ—¶åˆ»(min_idx)â€åšåŒæ­¥é…å¯¹ï¼ˆè´ªå¿ƒåŒ¹é…ï¼‰ã€‚"""
    if not left_blinks or not right_blinks:
        return {
            "pairs": [],
            "unmatched_left": list(range(len(left_blinks))),
            "unmatched_right": list(range(len(right_blinks))),
        }

    left_times = np.array([b.min_idx / float(fps) for b in left_blinks], dtype=np.float32)
    right_times = np.array([b.min_idx / float(fps) for b in right_blinks], dtype=np.float32)

    used_r = set()
    pairs = []
    unmatched_left = []

    for i, t in enumerate(left_times):
        # æ‰¾æœ€è¿‘çš„æœªä½¿ç”¨çš„ right
        diffs = np.abs(right_times - t)
        j = int(np.argmin(diffs))
        if j in used_r or float(diffs[j]) > float(max_delta_sec):
            unmatched_left.append(i)
            continue
        used_r.add(j)
        pairs.append({
            "left_index": int(i),
            "right_index": int(j),
            "delta_sec": float(right_times[j] - t),  # right - left
            "abs_delta_sec": float(abs(right_times[j] - t)),
        })

    unmatched_right = [j for j in range(len(right_blinks)) if j not in used_r]

    # åŒæ­¥ç»Ÿè®¡
    if pairs:
        abs_d = np.array([p["abs_delta_sec"] for p in pairs], dtype=np.float32)
        sync = {
            "paired_blinks": int(len(pairs)),
            "mean_abs_delta_ms": float(np.mean(abs_d) * 1000.0),
            "median_abs_delta_ms": float(np.median(abs_d) * 1000.0),
            "max_abs_delta_ms": float(np.max(abs_d) * 1000.0),
        }
    else:
        sync = {
            "paired_blinks": 0,
            "mean_abs_delta_ms": 0.0,
            "median_abs_delta_ms": 0.0,
            "max_abs_delta_ms": 0.0,
        }

    return {
        "pairs": pairs,
        "unmatched_left": unmatched_left,
        "unmatched_right": unmatched_right,
        "synchrony": sync,
    }


def summarize_blink_sequence(
        ela_signal: "ELASignal",
        blinks: List["BlinkEvent"]
) -> Dict[str, float]:
    """
    å¯¹æ•´æ®µçœ¨çœ¼åºåˆ—åšä¸€ä¸ªå…¨å±€ç»Ÿè®¡ï¼Œæ–¹ä¾¿åç»­å†™å…¥ JSON / ç”»å›¾ã€‚

    è¿”å›å­—æ®µç¤ºä¾‹ï¼š
        {
            "num_blinks": 12,
            "duration_sec": 28.3,
            "blink_rate_per_minute": 25.4,
            "mean_duration": 0.18,
            "median_duration": 0.17,
            "max_duration": 0.32
        }
    """
    if ela_signal.timestamps is None or len(ela_signal.timestamps) == 0:
        return {
            "num_blinks": 0,
            "duration_sec": 0.0,
            "blink_rate_per_minute": 0.0,
            "mean_duration": 0.0,
            "median_duration": 0.0,
            "max_duration": 0.0,
        }

    num_blinks = len(blinks)
    t0 = float(ela_signal.timestamps[0])
    t1 = float(ela_signal.timestamps[-1])
    duration_sec = max(t1 - t0, 0.0)

    if duration_sec > 0 and num_blinks > 0:
        blink_rate_per_minute = num_blinks / duration_sec * 60.0
    else:
        blink_rate_per_minute = 0.0

    if num_blinks > 0:
        durations = np.array([b.duration for b in blinks], dtype=np.float32)
        mean_duration = float(np.mean(durations))
        median_duration = float(np.median(durations))
        max_duration = float(np.max(durations))
    else:
        mean_duration = median_duration = max_duration = 0.0

    return {
        "num_blinks": int(num_blinks),
        "duration_sec": float(duration_sec),
        "blink_rate_per_minute": float(blink_rate_per_minute),
        "mean_duration": float(mean_duration),
        "median_duration": float(median_duration),
        "max_duration": float(max_duration),
    }


def extract_blink_features(
        ela_filtered: np.ndarray,
        derivative: np.ndarray,
        start_idx: int,
        min_idx: int,
        end_idx: int,
        fps: float
) -> Optional[BlinkEvent]:
    """
    æå–å•æ¬¡çœ¨çœ¼çš„ç‰¹å¾ï¼ˆè®ºæ–‡Table Iï¼‰

    Args:
        ela_filtered: å¹³æ»‘åçš„ELAä¿¡å·
        derivative: å¯¼æ•°
        start_idx: çœ¨çœ¼å¼€å§‹ç´¢å¼•
        min_idx: ELAæœ€å°å€¼ç´¢å¼•
        end_idx: çœ¨çœ¼ç»“æŸç´¢å¼•
        fps: å¸§ç‡

    Returns:
        BlinkEventå¯¹è±¡ï¼Œå¤±è´¥è¿”å›None
    """
    if start_idx >= min_idx or min_idx >= end_idx:
        return None

    # æ‰©å±•æœç´¢èŒƒå›´ï¼Œæ‰¾åˆ°çœŸæ­£çš„èµ·ç‚¹å’Œç»ˆç‚¹
    # å‘å‰æ‰¾åˆ°æœ€è¿‘çš„å±€éƒ¨æœ€å¤§å€¼
    search_start = max(0, start_idx - int(0.5 * fps))  # å‘å‰æœç´¢0.5ç§’
    local_max_before = search_start + np.argmax(ela_filtered[search_start:start_idx + 1])

    # å‘åæ‰¾åˆ°æœ€è¿‘çš„å±€éƒ¨æœ€å¤§å€¼
    search_end = min(len(ela_filtered), end_idx + int(0.5 * fps))
    local_max_after = end_idx + np.argmax(ela_filtered[end_idx:search_end])

    # ä½¿ç”¨åˆ‡çº¿äº¤ç‚¹æ³•è®¡ç®—ç²¾ç¡®çš„æ—¶é—´è¾¹ç•Œï¼ˆè®ºæ–‡Fig. 3ï¼‰
    ela_start = ela_filtered[local_max_before]
    ela_min = ela_filtered[min_idx]
    ela_end = ela_filtered[local_max_after]

    # é—­çœ¼é˜¶æ®µï¼šä»startåˆ°min
    closing_phase = ela_filtered[local_max_before:min_idx + 1]
    max_closing_vel = np.max(-derivative[local_max_before:min_idx + 1])

    # ççœ¼é˜¶æ®µï¼šä»minåˆ°end
    reopening_phase = ela_filtered[min_idx:local_max_after + 1]
    max_reopening_vel = np.max(derivative[min_idx:local_max_after + 1])

    # ä½¿ç”¨åˆ‡çº¿äº¤ç‚¹æ³•è®¡ç®—æŒç»­æ—¶é—´
    # ç®€åŒ–ç‰ˆæœ¬ï¼šç›´æ¥ä½¿ç”¨å³°å€¼å¯¼æ•°ç‚¹
    t1 = local_max_before / fps
    t2 = min_idx / fps
    t3 = local_max_after / fps

    closing_duration = t2 - t1
    closed_duration = 0.05  # ç®€åŒ–ï¼šå‡è®¾é—­åˆæŒç»­æ—¶é—´å¾ˆçŸ­
    reopening_duration = t3 - t2

    # å¹…åº¦ç‰¹å¾
    amplitude = (ela_start - ela_min) / (ela_start + 1e-6)

    # å¹…åº¦/é€Ÿåº¦æ¯”ï¼ˆè®ºæ–‡Table Iï¼‰
    av_ratio = (ela_end - ela_min) / (max_reopening_vel + 1e-6)

    # å½’ä¸€åŒ–é¢ç§¯ï¼ˆè®ºæ–‡Table Iï¼‰
    area = np.sum(ela_end - reopening_phase)
    normal_area = area / ((ela_end - ela_min) * 2 * reopening_duration + 1e-6)

    return BlinkEvent(
        start_idx=local_max_before,
        end_idx=local_max_after,
        min_idx=min_idx,
        closing_duration=closing_duration,
        closed_duration=closed_duration,
        reopening_duration=reopening_duration,
        amplitude=amplitude,
        ela_start=ela_start,
        ela_min=ela_min,
        ela_end=ela_end,
        max_closing_velocity=max_closing_vel,
        max_reopening_velocity=max_reopening_vel,
        amplitude_velocity_ratio=av_ratio,
        normal_area=normal_area
    )


# ==================== è§†é¢‘å¤„ç† ====================

def process_video_ela(
        video_path: str,
        model_path: str,
        start_frame: int = 0,
        end_frame: Optional[int] = None,
        compute_ela: bool = False,
) -> Optional[ELASignal]:
    """
    å¤„ç†è§†é¢‘ï¼Œæå–çœ¼éƒ¨æ—¶åºä¿¡å·ã€‚

    âœ… æ¨èé»˜è®¤ï¼šOpennessï¼ˆçœ¼ç›å¼€åˆåº¦ï¼‰â€”â€”æ›´ç›´è§‚ã€æ›´ç¨³å®šã€æ›´å®¹æ˜“è§£é‡Š
    - Openness_raw: (ä¸Š/ä¸‹çœ¼ç‘å¹³å‡è·ç¦») / (çœ¼è£‚å®½åº¦)
    - Openness: å¯¹ Openness_raw åšä¸ªä½“è‡ªé€‚åº”å½’ä¸€åŒ–åˆ° 0~1

    å¯é€‰ compute_ela=Trueï¼šåŒæ—¶è®¡ç®—è®ºæ–‡é‡Œçš„ ELAï¼ˆè§’åº¦ï¼‰ï¼Œç”¨äºå¯¹ç…§/è°ƒè¯•ï¼ˆæ›´æ…¢ï¼‰ã€‚

    Returns:
        ELASignal:
            - raw/filtered/derivative: é»˜è®¤ç”¨â€œå·¦å³ Openness å¹³å‡â€ä½œä¸ºä¸»ä¿¡å·
            - left_openness/right_openness: å·¦/å³çœ¼ Opennessï¼ˆ0~1ï¼‰
            - left_ela/right_ela: ä»… compute_ela=True æ‰æœ‰
    """
    if not os.path.exists(video_path):
        raise FileNotFoundError(f"è§†é¢‘ä¸å­˜åœ¨: {video_path}")

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise RuntimeError(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")

    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = float(cap.get(cv2.CAP_PROP_FPS) or 30.0)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    aspect_ratio = height / max(1, width)

    if end_frame is None:
        end_frame = total_frames
    end_frame = min(end_frame, total_frames)
    start_frame = max(0, start_frame)

    # è·³è½¬åˆ°èµ·å§‹å¸§
    if start_frame > 0:
        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)

    print(f"ğŸ“¹ å¤„ç†è§†é¢‘: {os.path.basename(video_path)}")
    print(f"   å¸§ç‡: {fps:.2f} FPS")
    print(f"   åˆ†è¾¨ç‡: {width}x{height}")
    print(f"   å¤„ç†èŒƒå›´: {start_frame}-{end_frame}")

    detector = get_face_landmarker(model_path)

    left_openness_raw_list = []
    right_openness_raw_list = []

    left_elas = []      # å¯é€‰
    right_elas = []     # å¯é€‰

    frame_idx = start_frame
    # VIDEO æ¨¡å¼è¦æ±‚ timestamp_ms å•è°ƒé€’å¢ï¼ˆåŒä¸€ä¸ª detector è´¯ç©¿å¤šæ®µè§†é¢‘æ—¶ä¹Ÿä¸€æ ·ï¼‰
    # ç”±äºæœ¬è„šæœ¬ä¼šåœ¨åŒä¸€è¿›ç¨‹å†…å¤ç”¨ detectorï¼ˆåŠ é€Ÿï¼‰ï¼Œå¦‚æœè·¨è§†é¢‘ timestamp é‡æ–°ä» 0 å¼€å§‹ï¼Œä¼šè§¦å‘ï¼š
    #   Input timestamp must be monotonically increasing.
    # æ‰€ä»¥è¿™é‡Œä¸ºæ¯ä¸ª model_path ç»´æŠ¤ä¸€ä¸ªå…¨å±€ base_ts_msï¼Œä¿è¯è·¨è§†é¢‘ä¹Ÿä¸¥æ ¼é€’å¢ã€‚
    global _FACE_LANDMARKER_LAST_TS_MS
    base_ts_ms = int(_FACE_LANDMARKER_LAST_TS_MS.get(model_path, -1)) + 1
    prev_ts_ms = base_ts_ms - 1
    frame_counter = 0  # ç›¸å¯¹å½“å‰è§†é¢‘çš„å¸§è®¡æ•°
    while frame_idx < end_frame:
        ret, frame = cap.read()
        if not ret:
            break

        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)

        ts_ms = base_ts_ms + int(round(frame_counter * 1000.0 / fps))
        if ts_ms <= prev_ts_ms:
            ts_ms = prev_ts_ms + 1
        prev_ts_ms = ts_ms
        detection_result = detector.detect_for_video(mp_image, ts_ms)

        if detection_result.face_landmarks:
            landmarks = detection_result.face_landmarks[0]

            # ---- Opennessï¼ˆ2Dï¼‰----
            left_upper_xy = extract_2d_landmarks(landmarks, LEFT_EYE_UPPER, width, height, aspect_ratio)
            left_lower_xy = extract_2d_landmarks(landmarks, LEFT_EYE_LOWER, width, height, aspect_ratio)
            right_upper_xy = extract_2d_landmarks(landmarks, RIGHT_EYE_UPPER, width, height, aspect_ratio)
            right_lower_xy = extract_2d_landmarks(landmarks, RIGHT_EYE_LOWER, width, height, aspect_ratio)

            left_open_raw = calculate_eye_openness_ratio(left_upper_xy, left_lower_xy)
            right_open_raw = calculate_eye_openness_ratio(right_upper_xy, right_lower_xy)

            left_openness_raw_list.append(left_open_raw)
            right_openness_raw_list.append(right_open_raw)

            # ---- å¯é€‰ï¼šELAï¼ˆ3Dï¼‰----
            if compute_ela:
                left_upper_3d = extract_3d_landmarks(landmarks, LEFT_EYE_UPPER, width, height, aspect_ratio)
                left_lower_3d = extract_3d_landmarks(landmarks, LEFT_EYE_LOWER, width, height, aspect_ratio)
                right_upper_3d = extract_3d_landmarks(landmarks, RIGHT_EYE_UPPER, width, height, aspect_ratio)
                right_lower_3d = extract_3d_landmarks(landmarks, RIGHT_EYE_LOWER, width, height, aspect_ratio)

                left_ela = calculate_ela_for_eye(left_upper_3d, left_lower_3d)
                right_ela = calculate_ela_for_eye(right_upper_3d, right_lower_3d)
                left_elas.append(left_ela)
                right_elas.append(right_ela)
            else:
                left_elas.append(np.nan)
                right_elas.append(np.nan)

        else:
            # æœªæ£€æµ‹åˆ°äººè„¸ï¼šæ²¿ç”¨ä¸Šä¸€å¸§ï¼ˆæ›´ç¨³ï¼‰ï¼Œæ²¡æœ‰ä¸Šä¸€å¸§å°± NaN
            if len(left_openness_raw_list) > 0:
                left_openness_raw_list.append(left_openness_raw_list[-1])
                right_openness_raw_list.append(right_openness_raw_list[-1])
                left_elas.append(left_elas[-1])
                right_elas.append(right_elas[-1])
            else:
                left_openness_raw_list.append(np.nan)
                right_openness_raw_list.append(np.nan)
                left_elas.append(np.nan)
                right_elas.append(np.nan)
        frame_counter += 1
        frame_idx += 1

    # æ›´æ–°è¯¥è¿›ç¨‹ä¸­æ­¤ detector çš„å…¨å±€æ—¶é—´æˆ³ï¼Œä¿è¯è·¨è§†é¢‘ç»§ç»­é€’å¢
    _FACE_LANDMARKER_LAST_TS_MS[model_path] = int(prev_ts_ms)

    cap.release()

    n = len(left_openness_raw_list)
    if n == 0:
        return None

    # ---- Openness åå¤„ç†ï¼šæ’å€¼ã€å¹³æ»‘ã€å½’ä¸€åŒ– ----
    left_raw = np.array(left_openness_raw_list, dtype=np.float32)
    right_raw = np.array(right_openness_raw_list, dtype=np.float32)

    left_raw = _interp_nan_1d(left_raw)
    right_raw = _interp_nan_1d(right_raw)

    left_raw_s = _smooth_signal(left_raw, fps)
    right_raw_s = _smooth_signal(right_raw, fps)

    left_open = _normalize_openness_by_percentiles(left_raw_s)
    right_open = _normalize_openness_by_percentiles(right_raw_s)

    # ä¸»ä¿¡å·ï¼šå·¦å³å¹³å‡ï¼ˆä½ ä¹Ÿå¯ä»¥åœ¨åç»­ç›´æ¥ç”¨ left_open/right_open åˆ†åˆ«æ£€æµ‹ï¼‰
    combined_open = 0.5 * (left_open + right_open)
    combined_open_s = _smooth_signal(combined_open, fps)

    derivative = compute_derivative(combined_open_s)

    timestamps = (np.arange(n, dtype=np.float32) + float(start_frame)) / float(fps)

    # å¯é€‰ï¼šELA è¾“å‡º
    left_ela_arr = np.array(left_elas, dtype=np.float32) if compute_ela else None
    right_ela_arr = np.array(right_elas, dtype=np.float32) if compute_ela else None

    return ELASignal(
        raw=combined_open.astype(np.float32),
        filtered=combined_open_s.astype(np.float32),
        derivative=derivative.astype(np.float32),
        fps=fps,
        timestamps=timestamps,
        left_ela=left_ela_arr,
        right_ela=right_ela_arr,
        left_openness_raw=left_raw,
        right_openness_raw=right_raw,
        left_openness=left_open,
        right_openness=right_open,
    )

# ==================== å¯è§†åŒ– ====================

def visualize_ela_with_blinks(
        ela_signal: ELASignal,
        blinks: List[BlinkEvent],
        output_path: str,
        title: str = "ELA Signal with Blink Detection"
):
    """
    å¯è§†åŒ–ELAä¿¡å·å’Œæ£€æµ‹åˆ°çš„çœ¨çœ¼äº‹ä»¶

    åˆ›å»º3ä¸ªå­å›¾ï¼š
    1. ELAåŸå§‹ä¿¡å· + æ»¤æ³¢ä¿¡å· + çœ¨çœ¼æ ‡æ³¨
    2. ELAå¯¼æ•° + çœ¨çœ¼è¾¹ç•Œ
    3. çœ¨çœ¼å„é˜¶æ®µè¯¦ç»†æ ‡æ³¨ï¼ˆæ”¾å¤§å›¾ï¼‰

    Args:
        ela_signal: ELAä¿¡å·
        blinks: æ£€æµ‹åˆ°çš„çœ¨çœ¼åˆ—è¡¨
        output_path: è¾“å‡ºå›¾åƒè·¯å¾„
        title: å›¾è¡¨æ ‡é¢˜
    """
    fig, axes = plt.subplots(3, 1, figsize=(16, 12))

    time = ela_signal.timestamps

    # ========== å­å›¾1: ELAä¿¡å· + çœ¨çœ¼æ ‡æ³¨ ==========
    ax1 = axes[0]

    # ç»˜åˆ¶åŸå§‹å’Œæ»¤æ³¢ä¿¡å·
    ax1.plot(time, ela_signal.raw, 'lightgray',
             linewidth=0.8, alpha=0.6, label='Raw ELA')
    ax1.plot(time, ela_signal.filtered, 'darkblue',
             linewidth=1.5, label='Filtered ELA')

    # æ ‡æ³¨æ¯ä¸ªçœ¨çœ¼äº‹ä»¶
    for i, blink in enumerate(blinks):
        start_time = time[blink.start_idx]
        end_time = time[blink.end_idx]
        min_time = time[blink.min_idx]

        # çœ¨çœ¼åŒºé—´èƒŒæ™¯
        ax1.axvspan(start_time, end_time, alpha=0.2, color='yellow')

        # æœ€å°ç‚¹
        ax1.plot(min_time, blink.ela_min, 'ro', markersize=6)

        # æ ‡æ³¨çœ¨çœ¼ç¼–å·
        ax1.text(min_time, blink.ela_min - 5, f'#{i + 1}',
                 ha='center', va='top', fontsize=8, color='red')

    ax1.set_xlabel('Time (s)', fontsize=11)
    ax1.set_ylabel('ELA (degrees)', fontsize=11)
    ax1.set_title(f'{title}\næ£€æµ‹åˆ° {len(blinks)} æ¬¡çœ¨çœ¼',
                  fontsize=13, fontweight='bold')
    ax1.legend(loc='upper right')
    ax1.grid(True, alpha=0.3)

    # ========== å­å›¾2: å¯¼æ•° + çœ¨çœ¼è¾¹ç•Œ ==========
    ax2 = axes[1]

    ax2.plot(time, ela_signal.derivative, 'green', linewidth=1.0)
    ax2.axhline(y=0, color='black', linestyle='--', linewidth=0.8, alpha=0.5)

    # æ ‡æ³¨çœ¨çœ¼çš„èµ·æ­¢ç‚¹
    for blink in blinks:
        start_time = time[blink.start_idx]
        end_time = time[blink.end_idx]

        # èµ·ç‚¹ï¼ˆæœ€å¤§è´Ÿå¯¼æ•°ï¼‰
        ax2.plot(time[blink.start_idx],
                 ela_signal.derivative[blink.start_idx],
                 'rv', markersize=8, label='Start' if blink == blinks[0] else '')

        # ç»ˆç‚¹ï¼ˆæœ€å¤§æ­£å¯¼æ•°ï¼‰
        ax2.plot(time[blink.end_idx],
                 ela_signal.derivative[blink.end_idx],
                 'r^', markersize=8, label='End' if blink == blinks[0] else '')

    ax2.set_xlabel('Time (s)', fontsize=11)
    ax2.set_ylabel('dELA/dt (deg/frame)', fontsize=11)
    ax2.set_title('ELA Derivative (ç”¨äºæ£€æµ‹çœ¨çœ¼è¾¹ç•Œ)', fontsize=12, fontweight='bold')
    ax2.legend(loc='upper right')
    ax2.grid(True, alpha=0.3)

    # ========== å­å›¾3: çœ¨çœ¼é˜¶æ®µè¯¦ç»†æ ‡æ³¨ï¼ˆé€‰æ‹©å‰å‡ ä¸ªçœ¨çœ¼æ”¾å¤§æ˜¾ç¤ºï¼‰ ==========
    ax3 = axes[2]

    # é€‰æ‹©å‰3ä¸ªçœ¨çœ¼äº‹ä»¶è¿›è¡Œè¯¦ç»†å±•ç¤º
    demo_blinks = blinks[:min(3, len(blinks))]

    for i, blink in enumerate(demo_blinks):
        # æ‰©å±•æ˜¾ç¤ºèŒƒå›´
        margin = int(0.3 * ela_signal.fps)  # å‰åå„0.3ç§’
        plot_start = max(0, blink.start_idx - margin)
        plot_end = min(len(time), blink.end_idx + margin)

        plot_time = time[plot_start:plot_end] - time[blink.start_idx]  # ç›¸å¯¹æ—¶é—´
        plot_ela = ela_signal.filtered[plot_start:plot_end]

        # åç§»ä»¥åˆ†ç¦»å¤šä¸ªçœ¨çœ¼
        offset = i * 15

        # ç»˜åˆ¶ä¿¡å·
        ax3.plot(plot_time, plot_ela + offset, linewidth=2,
                 label=f'Blink #{i + 1}')

        # æ ‡æ³¨ä¸‰ä¸ªé˜¶æ®µ
        t1 = time[blink.start_idx] - time[blink.start_idx]  # =0
        t2 = time[blink.min_idx] - time[blink.start_idx]
        t3 = time[blink.end_idx] - time[blink.start_idx]

        # é—­çœ¼é˜¶æ®µ
        ax3.axvspan(t1, t2, alpha=0.2, color='red')
        ax3.text((t1 + t2) / 2, blink.ela_start + offset + 2,
                 f'Closing\n{blink.closing_duration:.3f}s',
                 ha='center', va='bottom', fontsize=9, color='darkred')

        # ççœ¼é˜¶æ®µ
        ax3.axvspan(t2, t3, alpha=0.2, color='green')
        ax3.text((t2 + t3) / 2, blink.ela_end + offset + 2,
                 f'Reopening\n{blink.reopening_duration:.3f}s',
                 ha='center', va='bottom', fontsize=9, color='darkgreen')

        # å…³é”®ç‚¹æ ‡æ³¨
        ax3.plot(t1, blink.ela_start + offset, 'go', markersize=8)
        ax3.plot(t2, blink.ela_min + offset, 'ro', markersize=8)
        ax3.plot(t3, blink.ela_end + offset, 'go', markersize=8)

    ax3.set_xlabel('Relative Time (s)', fontsize=11)
    ax3.set_ylabel('ELA (degrees) + offset', fontsize=11)
    ax3.set_title('çœ¨çœ¼é˜¶æ®µè¯¦ç»†æ ‡æ³¨ (Closing â†’ Closed â†’ Reopening)',
                  fontsize=12, fontweight='bold')
    ax3.legend(loc='upper right')
    ax3.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close(fig)

    print(f"âœ… å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {output_path}")


def create_blink_summary_figure(
        blinks: List[BlinkEvent],
        fps: float,
        output_path: str
):
    """
    åˆ›å»ºçœ¨çœ¼ç‰¹å¾ç»Ÿè®¡æ±‡æ€»å›¾

    åŒ…å«ï¼š
    1. çœ¨çœ¼é¢‘ç‡ç›´æ–¹å›¾
    2. closing/closed/reopeningæŒç»­æ—¶é—´ç®±çº¿å›¾
    3. å¹…åº¦-é€Ÿåº¦æ•£ç‚¹å›¾

    Args:
        blinks: çœ¨çœ¼äº‹ä»¶åˆ—è¡¨
        fps: å¸§ç‡
        output_path: è¾“å‡ºè·¯å¾„
    """
    if len(blinks) == 0:
        return

    fig, axes = plt.subplots(2, 2, figsize=(14, 10))

    # ========== å­å›¾1: çœ¨çœ¼é¢‘ç‡ç›´æ–¹å›¾ ==========
    ax1 = axes[0, 0]
    if len(blinks) > 1:
        intervals = [b.previous_time for b in blinks[1:] if b.previous_time is not None]
        if intervals:
            ax1.hist(intervals, bins=20, color='steelblue', edgecolor='black', alpha=0.7)
            ax1.axvline(np.mean(intervals), color='red', linestyle='--',
                        linewidth=2, label=f'Mean: {np.mean(intervals):.2f}s')
            ax1.set_xlabel('Inter-Blink Interval (s)', fontsize=11)
            ax1.set_ylabel('Frequency', fontsize=11)
            ax1.set_title('çœ¨çœ¼é¢‘ç‡åˆ†å¸ƒ', fontsize=12, fontweight='bold')
            ax1.legend()
            ax1.grid(True, alpha=0.3)

    # ========== å­å›¾2: æŒç»­æ—¶é—´ç®±çº¿å›¾ ==========
    ax2 = axes[0, 1]

    closing_durs = [b.closing_duration * 1000 for b in blinks]  # è½¬æ¢ä¸ºms
    closed_durs = [b.closed_duration * 1000 for b in blinks]
    reopening_durs = [b.reopening_duration * 1000 for b in blinks]

    data_to_plot = [closing_durs, closed_durs, reopening_durs]
    labels = ['Closing', 'Closed', 'Reopening']

    bp = ax2.boxplot(data_to_plot, labels=labels, patch_artist=True,
                     boxprops=dict(facecolor='lightblue', alpha=0.7))
    ax2.set_ylabel('Duration (ms)', fontsize=11)
    ax2.set_title('çœ¨çœ¼å„é˜¶æ®µæŒç»­æ—¶é—´', fontsize=12, fontweight='bold')
    ax2.grid(True, alpha=0.3, axis='y')

    # ========== å­å›¾3: å¹…åº¦-é€Ÿåº¦æ•£ç‚¹å›¾ ==========
    ax3 = axes[1, 0]

    amplitudes = [b.amplitude for b in blinks]
    velocities = [b.max_reopening_velocity for b in blinks]

    ax3.scatter(amplitudes, velocities, c='coral', s=50, alpha=0.6, edgecolors='black')
    ax3.set_xlabel('Amplitude (relative)', fontsize=11)
    ax3.set_ylabel('Max Reopening Velocity (deg/frame)', fontsize=11)
    ax3.set_title('å¹…åº¦ vs é€Ÿåº¦', fontsize=12, fontweight='bold')
    ax3.grid(True, alpha=0.3)

    # ========== å­å›¾4: ç»Ÿè®¡è¡¨æ ¼ ==========
    ax4 = axes[1, 1]
    ax4.axis('off')

    # è®¡ç®—ç»Ÿè®¡é‡
    stats_data = [
        ['æŒ‡æ ‡', 'å‡å€¼', 'æ ‡å‡†å·®', 'Min', 'Max'],
        ['çœ¨çœ¼æ¬¡æ•°', f'{len(blinks)}', '-', '-', '-'],
        ['Closing (ms)', f'{np.mean(closing_durs):.1f}',
         f'{np.std(closing_durs):.1f}',
         f'{np.min(closing_durs):.1f}', f'{np.max(closing_durs):.1f}'],
        ['Closed (ms)', f'{np.mean(closed_durs):.1f}',
         f'{np.std(closed_durs):.1f}',
         f'{np.min(closed_durs):.1f}', f'{np.max(closed_durs):.1f}'],
        ['Reopening (ms)', f'{np.mean(reopening_durs):.1f}',
         f'{np.std(reopening_durs):.1f}',
         f'{np.min(reopening_durs):.1f}', f'{np.max(reopening_durs):.1f}'],
        ['Amplitude', f'{np.mean(amplitudes):.3f}',
         f'{np.std(amplitudes):.3f}',
         f'{np.min(amplitudes):.3f}', f'{np.max(amplitudes):.3f}'],
    ]

    table = ax4.table(cellText=stats_data, cellLoc='center',
                      loc='center', bbox=[0, 0, 1, 1])
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 2)

    # è®¾ç½®è¡¨å¤´æ ·å¼
    for i in range(5):
        cell = table[(0, i)]
        cell.set_facecolor('#4CAF50')
        cell.set_text_props(weight='bold', color='white')

    ax4.set_title('çœ¨çœ¼ç‰¹å¾ç»Ÿè®¡', fontsize=12, fontweight='bold', pad=20)

    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close(fig)

    print(f"âœ… ç‰¹å¾ç»Ÿè®¡å›¾å·²ä¿å­˜: {output_path}")


# ==================== ä¸»å¤„ç†å‡½æ•° ====================

def visualize_openness_lr_with_blinks(
        ela_signal: ELASignal,
        left_blinks: List["BlinkEvent"],
        right_blinks: List["BlinkEvent"],
        pair_info: Dict,
        output_path: str,
        title_prefix: str = "",
):
    """å¯è§†åŒ–å·¦å³çœ¼ Openness + æ£€æµ‹åˆ°çš„çœ¨çœ¼åŒºé—´ + åŒæ­¥æ—¶é—´å·®åˆ†å¸ƒã€‚"""
    if ela_signal.left_openness is None or ela_signal.right_openness is None:
        return

    t = ela_signal.timestamps
    left = np.asarray(ela_signal.left_openness, dtype=np.float32)
    right = np.asarray(ela_signal.right_openness, dtype=np.float32)

    fig, axes = plt.subplots(3, 1, figsize=(12, 10), sharex=True)

    def _plot_eye(ax, signal, blinks, eye_name: str):
        ax.plot(t, signal, linewidth=1.5, label=f"{eye_name} Openness")
        # çœ¨çœ¼åŒºé—´ï¼ˆstart-endï¼‰æ¶‚åº•è‰²ï¼Œmin ç‚¹æ‰“æ ‡
        for b in blinks:
            ts = t[b.start_idx]
            te = t[b.end_idx]
            tm = t[b.min_idx]
            ax.axvspan(ts, te, alpha=0.15)
            ax.scatter([tm], [signal[b.min_idx]], s=18)

        ax.set_ylim(-0.05, 1.1)
        ax.set_ylabel("Openness (0~1)")
        ax.grid(True, alpha=0.2)
        ax.legend(loc="upper right")

    _plot_eye(axes[0], left, left_blinks, "Left")
    _plot_eye(axes[1], right, right_blinks, "Right")

    # åŒæ­¥æ—¶é—´å·®ç›´æ–¹å›¾
    pairs = pair_info.get("pairs", [])
    if pairs:
        deltas = np.array([p["delta_sec"] for p in pairs], dtype=np.float32) * 1000.0
        axes[2].hist(deltas, bins=30)
        axes[2].set_ylabel("Count")
        axes[2].set_xlabel("Right - Left (ms)")
        axes[2].grid(True, alpha=0.2)

        sync = pair_info.get("synchrony", {})
        txt = (
            f"Paired: {sync.get('paired_blinks', 0)} | "
            f"Mean |Î”|: {sync.get('mean_abs_delta_ms', 0.0):.1f} ms | "
            f"Median |Î”|: {sync.get('median_abs_delta_ms', 0.0):.1f} ms"
        )
        axes[2].set_title(txt)
    else:
        axes[2].text(0.5, 0.5, "No paired blinks", ha="center", va="center")
        axes[2].set_axis_off()

    main_title = (title_prefix + " " if title_prefix else "") + "Eye Openness (Left/Right) + Blink Detection"
    fig.suptitle(main_title, fontsize=14)
    plt.tight_layout()
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    plt.savefig(output_path, dpi=200)
    plt.close(fig)


def create_openness_blink_summary_figure(
        left_blinks: List["BlinkEvent"],
        right_blinks: List["BlinkEvent"],
        pair_info: Dict,
        fps: float,
        output_path: str,
        title_prefix: str = "",
):
    """ç”Ÿæˆæ›´ç›´è§‚çš„æ±‡æ€»å›¾ï¼šå·¦å³çœ¼çœ¨çœ¼æ¬¡æ•°/é¢‘ç‡ã€æ—¶é•¿åˆ†å¸ƒã€é—­åˆå¹…åº¦åˆ†å¸ƒã€åŒæ­¥å·®ã€‚"""
    fig, axes = plt.subplots(2, 2, figsize=(12, 8))

    # 1) çœ¨çœ¼æ¬¡æ•° & é¢‘ç‡
    total_time_min = None
    # è¿™é‡Œç”¨â€œæœ€å¤§å¸§ç´¢å¼• / fpsâ€è¿‘ä¼¼æ—¶é•¿
    # å¦‚æœæ²¡æœ‰çœ¨çœ¼ï¼Œå°±æŒ‰ 1 åˆ†é’Ÿé¿å…é™¤é›¶ï¼ˆåªå½±å“æ˜¾ç¤ºï¼‰
    max_idx = 0
    for b in (left_blinks + right_blinks):
        max_idx = max(max_idx, b.end_idx)
    total_time_sec = max(1e-6, (max_idx / float(fps)))
    total_time_min = total_time_sec / 60.0

    l_cnt = len(left_blinks)
    r_cnt = len(right_blinks)
    axes[0, 0].bar(["Left", "Right"], [l_cnt, r_cnt])
    axes[0, 0].set_title("Blink Count")
    axes[0, 0].set_ylabel("Count")
    axes[0, 0].grid(True, axis="y", alpha=0.2)

    axes[0, 1].bar(["Left", "Right"], [l_cnt / total_time_min, r_cnt / total_time_min])
    axes[0, 1].set_title("Blink Rate (per minute)")
    axes[0, 1].set_ylabel("Blinks/min")
    axes[0, 1].grid(True, axis="y", alpha=0.2)

    # 2) æ—¶é•¿åˆ†å¸ƒ
    l_dur = [b.duration for b in left_blinks]
    r_dur = [b.duration for b in right_blinks]
    if l_dur or r_dur:
        if l_dur:
            axes[1, 0].hist(l_dur, bins=25, alpha=0.6, label="Left")
        if r_dur:
            axes[1, 0].hist(r_dur, bins=25, alpha=0.6, label="Right")
        axes[1, 0].set_title("Blink Duration (s)")
        axes[1, 0].set_xlabel("Seconds")
        axes[1, 0].set_ylabel("Count")
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.2)
    else:
        axes[1, 0].text(0.5, 0.5, "No blinks", ha="center", va="center")
        axes[1, 0].set_axis_off()

    # 3) é—­åˆå¹…åº¦åˆ†å¸ƒï¼ˆclosure_peakï¼‰
    l_amp = [b.amplitude for b in left_blinks]
    r_amp = [b.amplitude for b in right_blinks]
    if l_amp or r_amp:
        if l_amp:
            axes[1, 1].hist(np.array(l_amp) * 100.0, bins=25, alpha=0.6, label="Left")
        if r_amp:
            axes[1, 1].hist(np.array(r_amp) * 100.0, bins=25, alpha=0.6, label="Right")
        axes[1, 1].set_title("Closure Amplitude (%)")
        axes[1, 1].set_xlabel("% (higher = more closed)")
        axes[1, 1].set_ylabel("Count")
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.2)
    else:
        axes[1, 1].text(0.5, 0.5, "No blinks", ha="center", va="center")
        axes[1, 1].set_axis_off()

    title = (title_prefix + " " if title_prefix else "") + "Blink Summary (Openness)"
    fig.suptitle(title, fontsize=14)
    plt.tight_layout()
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    plt.savefig(output_path, dpi=200)
    plt.close(fig)

def _safe_prefix(
        examination_id: Optional[int],
        action_name: Optional[str]
) -> str:
    """
    æŠŠ exam_id / action_name æ‹¼æˆä¸€ä¸ªå®‰å…¨çš„å‰ç¼€ï¼Œç”¨æ¥å‘½å PNG/JSON æ–‡ä»¶ã€‚
    """
    parts = []
    if examination_id is not None:
        parts.append(f"{examination_id}")
    if action_name:
        parts.append(action_name)

    raw = "_".join(parts) if parts else "UNKNOWN"
    raw = raw.replace(" ", "_")
    return re.sub(r"[^0-9A-Za-z_\-]+", "", raw)


def analyze_video_blinks(
        video_path: str,
        model_path: str,
        output_dir: str,
        patient_id: str = "UNKNOWN",
        action_name: str = "UnknownAction",
        examination_id: Optional[int] = None,
        start_frame: int = 0,
        end_frame: Optional[int] = None,
        fps: Optional[float] = None,
) -> Optional[Dict]:
    """
    å•ä¸ªè§†é¢‘çš„çœ¨çœ¼åˆ†æå…¥å£ï¼ˆæ”¹ä¸ºæ›´ç›´è§‚çš„ Opennessï¼‰ï¼š

    1) æå–å·¦å³çœ¼ Opennessï¼ˆ0~1ï¼‰
    2) å·¦å³çœ¼åˆ†åˆ«åšçœ¨çœ¼æ£€æµ‹ï¼ˆåŸºäº closure = 1 - opennessï¼‰
    3) å·¦å³é…å¯¹ï¼Œå¾—åˆ°åŒæ­¥æ—¶é—´å·®
    4) è¾“å‡ºå›¾ + JSONï¼ˆå·¦å³çœ¼åˆ†åˆ«ç»Ÿè®¡ï¼‰

    æ³¨æ„ï¼š
    - å‚æ•° fps ä»…ä¿ç•™å…¼å®¹ï¼ˆå®é™…ä»¥è§†é¢‘æ–‡ä»¶è¯»å–åˆ°çš„ fps ä¸ºå‡†ï¼‰
    """
    if not os.path.exists(video_path):
        raise FileNotFoundError(f"è§†é¢‘ä¸å­˜åœ¨: {video_path}")

    os.makedirs(output_dir, exist_ok=True)

    # æ–‡ä»¶åå‰ç¼€
    prefix = _safe_prefix(examination_id, action_name)

    # ========== 1) æå– Openness ä¿¡å· ==========
    ela_signal = process_video_ela(
        video_path=video_path,
        model_path=model_path,
        start_frame=start_frame,
        end_frame=end_frame,
        compute_ela=False,
    )
    if ela_signal is None or ela_signal.left_openness is None or ela_signal.right_openness is None:
        return None

    fps_real = float(ela_signal.fps)

    # ========== 2) å·¦å³çœ¼åˆ†åˆ«æ£€æµ‹çœ¨çœ¼ ==========
    left_blinks = detect_blinks_openness(ela_signal.left_openness, fps_real)
    right_blinks = detect_blinks_openness(ela_signal.right_openness, fps_real)

    # ========== 3) å·¦å³é…å¯¹ï¼ˆåŒæ­¥ï¼‰ ==========
    pair_info = pair_left_right_blinks(left_blinks, right_blinks, fps_real)

    # ========== 4) ç»Ÿè®¡ ==========
    left_stats = summarize_blink_sequence(ela_signal, left_blinks)
    right_stats = summarize_blink_sequence(ela_signal, right_blinks)

    # å¹³å‡å€¼ä½œä¸ºæ•´ä½“å‚è€ƒ
    num_blinks_avg = int(round((len(left_blinks) + len(right_blinks)) / 2.0))
    blink_rate_avg = float((left_stats.get("blink_rate_per_minute", 0.0) + right_stats.get("blink_rate_per_minute", 0.0)) / 2.0)

    # ========== 5) å¯è§†åŒ– ==========
    openness_plot_path = os.path.join(output_dir, f"{prefix}_openness_lr.png")
    summary_plot_path = os.path.join(output_dir, f"{prefix}_blink_summary_openness.png")

    title_prefix = f"{patient_id} | {action_name}"
    visualize_openness_lr_with_blinks(
        ela_signal=ela_signal,
        left_blinks=left_blinks,
        right_blinks=right_blinks,
        pair_info=pair_info,
        output_path=openness_plot_path,
        title_prefix=title_prefix,
    )
    create_openness_blink_summary_figure(
        left_blinks=left_blinks,
        right_blinks=right_blinks,
        pair_info=pair_info,
        fps=fps_real,
        output_path=summary_plot_path,
        title_prefix=title_prefix,
    )

    # ========== 6) ç»„ç»‡è¾“å‡º JSON ==========
    result = {
        "patient_id": patient_id,
        "action_name": action_name,
        "examination_id": examination_id,
        "video_path": video_path,
        "start_frame": int(start_frame),
        "end_frame": int(end_frame) if end_frame is not None else None,
        "fps": float(fps_real),
        "signal_type": "openness",
        "num_blinks": int(num_blinks_avg),
        "blink_rate_per_minute": float(blink_rate_avg),

        "left": left_stats,
        "right": right_stats,
        "synchrony": pair_info.get("synchrony", {}),

        "pairs": pair_info.get("pairs", []),
        "unmatched_left": pair_info.get("unmatched_left", []),
        "unmatched_right": pair_info.get("unmatched_right", []),

        "left_blinks": [_blink_event_to_dict(b, "left") for b in left_blinks],
        "right_blinks": [_blink_event_to_dict(b, "right") for b in right_blinks],

        "plots": {
            "openness_lr": openness_plot_path,
            "summary": summary_plot_path,
        },
    }

    # ä¿å­˜ JSON
    json_path = os.path.join(output_dir, f"{prefix}_blink_result.json")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(convert_numpy_types(result), f, ensure_ascii=False, indent=2)

    return result

def load_videos_from_database(
        db_path: str,
        action_filter: Optional[List[str]] = None,
        limit: Optional[int] = None
) -> List[Dict]:
    """
    ä» facialPalsy.db ä¸­è¯»å–éœ€è¦åšçœ¨çœ¼åˆ†æçš„è§†é¢‘åˆ—è¡¨ã€‚

    å…³è”çš„è¡¨ï¼š
        - video_files       (è§†é¢‘è·¯å¾„ã€å¸§èŒƒå›´ã€fps ç­‰)
        - examinations      (patient_id)
        - action_types      (action_name_en)

    å‚æ•°:
        action_filter: åªå¤„ç†æŸäº›åŠ¨ä½œï¼Œä¾‹å¦‚ ["SpontaneousEyeBlink", "VoluntaryEyeBlink"]
        limit        : ä»…å–å‰ N ä¸ªæ ·æœ¬ï¼Œç”¨äºè°ƒè¯•

    è¿”å›:
        æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ª dictï¼ŒåŒ…å«ï¼š
            {
                "examination_id", "patient_id",
                "action_name", "file_path",
                "start_frame", "end_frame", "fps"
            }
    """
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    base_sql = """
        SELECT
            vf.examination_id,
            e.patient_id,
            at.action_name_en,
            vf.file_path,
            vf.start_frame,
            vf.end_frame,
            vf.fps
        FROM video_files AS vf
        LEFT JOIN examinations AS e ON vf.examination_id = e.examination_id
        LEFT JOIN action_types AS at ON vf.action_id = at.action_id
        WHERE vf.file_exists = 1
    """

    params: List = []

    if action_filter:
        placeholders = ",".join("?" for _ in action_filter)
        base_sql += f" AND at.action_name_en IN ({placeholders})"
        params.extend(action_filter)

    base_sql += " ORDER BY vf.examination_id"

    cursor.execute(base_sql, params)
    rows = cursor.fetchall()
    conn.close()

    if limit is not None:
        rows = rows[:limit]

    videos: List[Dict] = []
    for (exam_id, patient_id, action_name,
         file_path, start_frame, end_frame, fps) in rows:

        videos.append({
            "examination_id": str(exam_id) if exam_id is not None else "exam_id",
            "patient_id": str(patient_id) if patient_id is not None else "UNKNOWN",
            "action_name": str(action_name) if action_name is not None else "UnknownAction",
            "file_path": file_path,
            "start_frame": 0 if start_frame is None else int(start_frame),
            "end_frame": None if end_frame is None else int(end_frame),
            "fps": None if fps is None else float(fps),
        })

    return videos


def _worker_process_one(args: Dict) -> Dict:
    """
    å¤šè¿›ç¨‹ workerï¼šå¤„ç†å•ä¸ªè§†é¢‘ï¼Œå¹¶åŒ…è£…å¼‚å¸¸ã€‚
    """
    try:
        result = analyze_video_blinks(
            video_path=args["file_path"],
            model_path=args["model_path"],
            output_dir=args["output_dir"],
            patient_id=args["patient_id"],
            action_name=args["action_name"],
            examination_id=args["examination_id"],
            start_frame=args["start_frame"],
            end_frame=args["end_frame"],
            fps=args["fps"],
        )
        return {
            "success": result is not None,
            "error": None,
            "meta": args,
            "result": result,
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "meta": args,
            "result": None,
        }


def batch_process_database(
        db_path: str,
        model_path: str,
        output_dir: str,
        action_filter: Optional[List[str]] = None,
        limit: Optional[int] = None,
        use_multiprocessing: bool = True,
        num_workers: Optional[int] = None,
):
    """
    ä»æ•°æ®åº“ä¸­æ‰¹é‡è¯»å–è§†é¢‘ï¼Œåšçœ¨çœ¼æ£€æµ‹ + å¯è§†åŒ–ã€‚

    å‚æ•°ï¼š
        db_path          : facialPalsy.db çš„è·¯å¾„
        model_path       : MediaPipe face_landmarker.task æ¨¡å‹è·¯å¾„
        output_dir       : æ‰€æœ‰ç»“æœï¼ˆjson + pngï¼‰çš„è¾“å‡ºç›®å½•
        action_filter    : æŒ‡å®šåªå¤„ç†å“ªäº›åŠ¨ä½œ
        limit            : ä»…å¤„ç†å‰ N ä¸ªæ ·æœ¬ï¼ˆè°ƒè¯•ç”¨ï¼‰
        use_multiprocessing: æ˜¯å¦å¯ç”¨å¤šè¿›ç¨‹
        num_workers      : è¿›ç¨‹æ•°ï¼ˆNone=è‡ªåŠ¨=CPU æ ¸æ•°ï¼‰
    """
    os.makedirs(output_dir, exist_ok=True)

    print("============================================================")
    print("æ‰¹é‡çœ¨çœ¼åˆ†æ - ä»æ•°æ®åº“åŠ è½½è§†é¢‘")
    print("============================================================")
    print(f"æ•°æ®åº“: {db_path}")
    print(f"æ¨¡å‹   : {model_path}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")

    if action_filter:
        print(f"åŠ¨ä½œè¿‡æ»¤: {action_filter}")
    if limit is not None:
        print(f"æ ·æœ¬ä¸Šé™: {limit}")

    videos = load_videos_from_database(db_path, action_filter=action_filter, limit=limit)
    if not videos:
        print("[WARN] æ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è§†é¢‘ã€‚")
        return

    print(f"[INFO] å…± {len(videos)} ä¸ªè§†é¢‘å¾…å¤„ç†ã€‚")

    # ç»™æ¯ä¸ª task å¡«å……æ¨¡å‹è·¯å¾„å’Œè¾“å‡ºç›®å½•
    tasks: List[Dict] = []
    for v in videos:
        one = dict(v)
        one["model_path"] = model_path
        one["output_dir"] = output_dir
        tasks.append(one)

    results_summary = []

    if use_multiprocessing:
        if num_workers is None or num_workers <= 0:
            # ä¸æŒ‡å®šçš„è¯ï¼Œé»˜è®¤ç”¨ CPU é€»è¾‘æ ¸æ•°
            try:
                import multiprocessing
                num_workers = multiprocessing.cpu_count()
            except Exception:
                num_workers = 4

        print(f"[INFO] å¯ç”¨å¤šè¿›ç¨‹ï¼Œè¿›ç¨‹æ•°: {num_workers}")

        with ProcessPoolExecutor(max_workers=num_workers) as executor:
            future_to_task = {
                executor.submit(_worker_process_one, t): t for t in tasks
            }

            for idx, future in enumerate(as_completed(future_to_task), start=1):
                t = future_to_task[future]
                meta = {
                    "examination_id": t["examination_id"],
                    "patient_id": t["patient_id"],
                    "action_name": t["action_name"],
                }
                try:
                    out = future.result()
                except Exception as e:
                    print(f"[ERROR] è§†é¢‘ {meta} å¤„ç†å¤±è´¥ï¼ˆfuture å¼‚å¸¸ï¼‰: {e}")
                    results_summary.append({
                        **meta,
                        "success": False,
                        "error": str(e),
                    })
                    continue

                if out["success"]:
                    r = out["result"]
                    print(f"[{idx}/{len(tasks)}] OK - {meta}")
                    results_summary.append({
                        **meta,
                        "success": True,

                        # å…¼å®¹æ—§å­—æ®µï¼ˆæ•´ä½“å‚è€ƒï¼‰
                        "num_blinks": r.get("num_blinks", 0),
                        "blink_rate_per_minute": r.get("blink_rate_per_minute", 0.0),

                        # æ–°å¢ï¼šå·¦å³çœ¼åˆ†åˆ«
                        "num_blinks_left": r.get("left", {}).get("num_blinks", 0),
                        "num_blinks_right": r.get("right", {}).get("num_blinks", 0),
                        "blink_rate_left": r.get("left", {}).get("blink_rate_per_minute", 0.0),
                        "blink_rate_right": r.get("right", {}).get("blink_rate_per_minute", 0.0),

                        # æ–°å¢ï¼šåŒæ­¥
                        "paired_blinks": r.get("synchrony", {}).get("paired_blinks", 0),
                        "mean_abs_delta_ms": r.get("synchrony", {}).get("mean_abs_delta_ms", 0.0),
                    })
                else:
                    print(f"[{idx}/{len(tasks)}] FAIL - {meta} - {out['error']}")
                    results_summary.append({
                        **meta,
                        "success": False,
                        "error": out["error"],
                    })

    else:
        print("[INFO] ä½¿ç”¨å•è¿›ç¨‹é¡ºåºå¤„ç†ï¼ˆè°ƒè¯•æˆ–æ’æŸ¥é”™è¯¯æ—¶ä½¿ç”¨ï¼‰ã€‚")
        for idx, t in enumerate(tasks, start=1):
            meta = {
                "examination_id": t["examination_id"],
                "patient_id": t["patient_id"],
                "action_name": t["action_name"],
            }
            try:
                out = _worker_process_one(t)
            except Exception as e:
                print(f"[ERROR] è§†é¢‘ {meta} å¤„ç†å¤±è´¥ï¼ˆç›´æ¥å¼‚å¸¸ï¼‰: {e}")
                results_summary.append({
                    **meta,
                    "success": False,
                    "error": str(e),
                })
                continue

            if out["success"]:
                r = out["result"]
                print(f"[{idx}/{len(tasks)}] OK - {meta}")
                results_summary.append({
                        **meta,
                        "success": True,

                        # å…¼å®¹æ—§å­—æ®µï¼ˆæ•´ä½“å‚è€ƒï¼‰
                        "num_blinks": r.get("num_blinks", 0),
                        "blink_rate_per_minute": r.get("blink_rate_per_minute", 0.0),

                        # æ–°å¢ï¼šå·¦å³çœ¼åˆ†åˆ«
                        "num_blinks_left": r.get("left", {}).get("num_blinks", 0),
                        "num_blinks_right": r.get("right", {}).get("num_blinks", 0),
                        "blink_rate_left": r.get("left", {}).get("blink_rate_per_minute", 0.0),
                        "blink_rate_right": r.get("right", {}).get("blink_rate_per_minute", 0.0),

                        # æ–°å¢ï¼šåŒæ­¥
                        "paired_blinks": r.get("synchrony", {}).get("paired_blinks", 0),
                        "mean_abs_delta_ms": r.get("synchrony", {}).get("mean_abs_delta_ms", 0.0),
                    })
            else:
                print(f"[{idx}/{len(tasks)}] FAIL - {meta} - {out['error']}")
                results_summary.append({
                    **meta,
                    "success": False,
                    "error": out["error"],
                })

    # å†™ä¸€ä¸ªæ•´ä½“ summary
    summary_path = os.path.join(output_dir, "z_blink_batch_summary.json")
    with open(summary_path, "w", encoding="utf-8") as f:
        json.dump(results_summary, f, ensure_ascii=False, indent=2)

    print("============================================================")
    print(f"æ‰¹é‡çœ¨çœ¼åˆ†æå®Œæˆï¼Œsummary å†™å…¥: {summary_path}")
    print("============================================================")


if __name__ == "__main__":
    DB_PATH = "/Users/cuijinglei/PycharmProjects/medicalProject/facialPalsy/facialPalsy.db"
    MODEL_PATH = "/Users/cuijinglei/PycharmProjects/medicalProject/models/face_landmarker.task"
    OUTPUT_DIR = "/Users/cuijinglei/Documents/facialPalsy/HGFA/eyelid_blink_openness"

    # åªåˆ†æçœ¨çœ¼ç›¸å…³åŠ¨ä½œï¼ˆå¯ä»¥æŒ‰éœ€ä¿®æ”¹æˆ–æ‰©å±•ï¼‰
    ACTION_FILTER = None

    LIMIT = None

    batch_process_database(
        db_path=DB_PATH,
        model_path=MODEL_PATH,
        output_dir=OUTPUT_DIR,
        action_filter=ACTION_FILTER,
        limit=LIMIT,
        use_multiprocessing=True,
        num_workers=8,
    )